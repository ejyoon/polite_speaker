// webppl s2-bda-4pred.wppl --require webppl-json 1
// requires webppl package: webppl-json

var index = last(process.argv) // load index as last command line index

var foreach = function(lst, fn) {
    var foreach_ = function(i) {
        if (i < lst.length) {
            fn(lst[i]);
            foreach_(i + 1);
        }
    };
    foreach_(0);
};

var utterances = [
  "yes_terrible","yes_bad","yes_good","yes_amazing",
  "not_terrible","not_bad","not_good","not_amazing"
];

var negative_utterances = [
  "not_terrible","not_bad","not_good","not_amazing"
];

var states = [0, 1, 2, 3];

var statePrior = function(){
  return uniformDraw(states);
};

var isNegation = function(utt){
  return (utt.split("_")[0] == "not")
};

var round = function(x){
  return Math.round(x * 100) / 100
}

var weightBins = map(round, _.range(0,1, 0.025))
var phiWeights = repeat(weightBins.length, function(){1})

var goalWeightPrior = Infer({model: function(){
  return uniformDraw(weightBins)
}})

var nBins = weightBins.length;
var kernelWidth = nBins / 4;

var kernelFn = function(prevVal){
  var i = weightBins.indexOf(prevVal);
  var upper = (i + kernelWidth) > nBins ? nBins : i + kernelWidth;
  var lower = (i - kernelWidth) < 0 ? 0 : i - kernelWidth;
  return Categorical({vs: weightBins.slice(lower,upper),
                      ps: phiWeights.slice(lower,upper)})
}

// measured in Experiment 1
var literalSemantics = json.read('data/literal_semantics_3heart_raw.json');
var data = json.read('data/utterance_3heart_registered.json')

var litSemanticsPosteriorObj = _.fromPairs(map(function(u){
  return [u, _.fromPairs(map(function(s){
    var litParams = _.filter(literalSemantics, {state: s, utterance: u})[0]
    return [s, {a: litParams.posterior_b1, b: litParams.posterior_b2}]
  }, states))]
}, utterances))


var goals = _.uniq(_.map(data, "goal"));
var states = _.uniq(_.map(data, "true_state"));


var model = function(){

var litSemantics = _.fromPairs(map(function(u){
    return [u, _.fromPairs(map(function(s){
      var litParams = litSemanticsPosteriorObj[u][s];
      return [s, beta(litParams)]
    }, states))]
  }, utterances))

  var RSAparameters = {
    speakerOptimality: uniformDrift({a: 0, b: 20, width:2}),
    cost: uniformDrift({a: 1, b: 10, width:0.25})
  };

  var cost_yes = 1;
  var uttCosts = map(function(u) {
    return isNegation(u) ? Math.exp(-RSAparameters.cost) : Math.exp(-cost_yes)
  }, utterances)

  var utterancePrior = Infer({model: function(){
    return utterances[discrete(uttCosts)];
  }});

  var meaning = function(words, state){
    return flip(litSemantics[words][state]);
  };

  var listener0 = cache(function(utterance) {
    Infer({method: "enumerate"}, function(){
      var state = uniformDraw(states);
      var m = meaning(utterance, state);
      condition(m);
      return state;
    });
  }, 10000);

  var speaker1 = cache(function(state, phi) {
    Infer({method: "enumerate"}, function(){
      var utterance = sample(utterancePrior);

      var speakerOptimality = RSAparameters.speakerOptimality;

      var L0 = listener0(utterance);

      var epistemicUtility = L0.score(state);
      var socialUtility = expectation(L0, function(s){return s});

      var eUtility = phi*epistemicUtility;
      var sUtility = (1-phi)*socialUtility;

      var speakerUtility = eUtility+sUtility;

      factor(speakerOptimality*speakerUtility);

      return utterance;
    })
  }, 10000)

  var listener1 = cache(function(utterance) {
    Infer({method: "enumerate"}, function(){

      var phi = categorical ({vs: weightBins, ps: phiWeights})

      var state = uniformDraw(states);

      var S1 = speaker1(state, phi)
      observe(S1, utterance)

      return {
        state: state,
        phi: phi
      }
    })
  }, 10000)

  var speaker2 = cache(function(exptCondInfo) {
    Enumerate(function(){
      var state = exptCondInfo.state;

      var S1_phi = exptCondInfo.S1_phi;

      var selfpres_phi = exptCondInfo.selfpres_phi;
      var social_phi = exptCondInfo.social_phi;
      var informative_phi = exptCondInfo.informative_phi;

      var utterance = sample(utterancePrior);

      var L1 = listener1(utterance)
	  var L1_goal = marginalize(L1, "phi");
	  var L1_state = marginalize(L1, "state");

      var epistemicUtility = L1_state.score(state);
      var selfpresUtility = L1_goal.score(S1_phi);
      var socialUtility = expectation(L1_state, function(s){return s});


      var speakerMixedUtility = informative_phi*epistemicUtility +
                                selfpres_phi*selfpresUtility +
                                social_phi*socialUtility

// 	factor(RSAparameters.speakerOptimality * speakerMixedUtility); // triple mixture model
	
// 	factor(RSAparameters.speakerOptimality * (informative_phi*epistemicUtility + selfpres_phi*selfpresUtility)); // true informative + self pres
// 	factor(RSAparameters.speakerOptimality * (social_phi*socialUtility + selfpres_phi*selfpresUtility)); // true social + self pres
// 	factor(RSAparameters.speakerOptimality * (social_phi*socialUtility + informative_phi*epistemicUtility)); // true social + true informative

//	factor(RSAparameters.speakerOptimality * informative_phi*epistemicUtility); // true informative only
 	factor(RSAparameters.speakerOptimality * social_phi*socialUtility); // true social only
// 	factor(RSAparameters.speakerOptimality * selfpres_phi*selfpresUtility); // self-presentational only

      return utterance

    })
  }, 10000)

foreach(goals, function(goal) {

    var S1_phi = sample(goalWeightPrior, {driftKernel: kernelFn})

    var selfpres_phi = uniformDrift({a: 0, b: 1, width: 0.2})
    var informative_phi = uniformDrift({a: 0, b: 1, width: 0.2})
    var social_phi = uniformDrift({a: 0, b: 1, width: 0.2})

    var normalized_phis = normalize([selfpres_phi, informative_phi, social_phi])

foreach(states, function(state) {
      var utteranceData = _.filter(data, {true_state: state, goal: goal});

      var exptConditionInfo = {
        state: state,
        utterance: false,
        S1_phi: S1_phi,
        selfpres_phi: normalized_phis[0],
        informative_phi: normalized_phis[1],
        social_phi: social_phi
      };

      var RSApredictions = speaker2(exptConditionInfo);


      mapData({data: utteranceData}, function(d){
        observe(RSApredictions, d.utterance)
      });

      var postSupport = RSApredictions.support();

      foreach(postSupport, function(u){
      	query.add(["pP", goal, state, u], Math.exp(RSApredictions.score(u)))
      })

      var negEndorsement = sum(map(function(u){
        return Math.exp(RSApredictions.score(u))
      }, negative_utterances))

      	query.add(["pP", goal, state, "neg"], negEndorsement)
	})

//       	query.add(["phi_social", goal, "NA", "NA"], social_phi)

})

      query.add(["op", "NA", "NA", "NA"], RSAparameters.speakerOptimality)
      query.add(["c", "NA", "NA", "NA"], RSAparameters.cost)

	return query
}

// var numSamples = 80000;
// var method = "MCMC";
// var samples = numSamples;
// var burn = numSamples / 2;
// var posterior = Infer({model, method, samples, burn, verbose: true})
// var filename = 'bda-s2_trueSoc_3heart_foreach-mcmc'+
// numSamples+'_burn'+burn+'_chain'+index+'.json'
// 
// json.write(filename, posterior)
// 
// "output written to " + filename;

var totalIterations = 80000, lag =  0;
var samples = totalIterations, burn = totalIterations / 2;
var outfile = 'bda-s2_trueSoc_3heart_paramAdj-mcmc'+
samples+'_burn'+burn+'_lag'+lag+'_chain'+index+'.csv'
var outfile2 = 'bda-s2_trueSoc_3heart_paramAdj-mcmc'+
samples+'_burn'+burn+'_lag'+lag+'_chain'+index+'.json'

var posterior = Infer({
  model: model,
	method: "incrementalMH",
  samples: samples, burn: burn, lag: lag,
  verbose: T,
  verboseLag: totalIterations / 20,
	stream: {
		path: "results/" + outfile,
		header: ["type", "param", "property", "category", "val"]
	}
})

// json.write(outfile2, posterior)

"written to " + outfile;

