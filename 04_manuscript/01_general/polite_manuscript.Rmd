---
title             : "Polite speech emerges from competing social goals"
shorttitle        : "Modeling polite speech"

author: 
  - name          : "Erica J. Yoon"
    affiliation   : "1, *, †"
    corresponding : yes    # Define only one corresponding author
    address       : "450 Serra Mall, Bldg. 420, Rm. 290, Stanford, CA 94305"
    email         : "ejyoon@stanford.edu"
  - name          : "Michael Henry Tessler"
    affiliation   : "1, †"
  - name          : "Noah D. Goodman"
    affiliation   : "1"
  - name          : "Michael C. Frank"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Stanford University"
  - id            : "\\*"
    institution   : "Corresponding author"
  - id            : "\\†"
    institution   : "These authors contributed equally to this work."

author_note: |
  All authors designed research and wrote the paper; E.J.Y. and M.H.T. performed research and analyzed data. The authors declare no conflict of interest. This work was supported by NSERC PGS Doctoral scholarship PGSD3-454094-2014 to EJY, NSF Graduate Research Fellowship DGE-114747 to MHT, ONR grant N00014-13-1-0788 to NDG, and NSF grant BCS 1456077 to MCF.


abstract: |
  Language is a remarkably efficient tool for transmitting information. Yet human speakers make statements that are inefficient, imprecise, or even contrary to their own beliefs, all in the service of being polite. What rational machinery underlies polite language use? Here, we show that polite speech emerges from the competition of three communicative goals: to convey information, to be kind, and to present oneself in a good light. We formalize this goal tradeoff using a probabilistic model of utterance production, which predicts human utterance choices in socially-sensitive situations with high quantitative accuracy, and we show that our full model is superior to its variants with subsets of the three goals. This utility-theoretic approach to speech acts takes a step towards explaining the richness and subtlety of social language use.
  
keywords          : "politeness, computational modeling, communicative goals, pragmatics"
wordcount         : "X"

bibliography      : ["politeness.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes
mask              : no

class             : "man"
output            : papaja::apa6_pdf
---

\definecolor{Blue}{RGB}{10,100,200}
\definecolor{Red}{RGB}{255,0,0}

\newcommand{\red}[1]{{\textcolor{Red}{#1}}}
\newcommand{\mht}[1]{{\textcolor{Blue}{[mht: #1]}}}



```{r include_packages, include = FALSE}
# check to see if user has packages. otherwise, install them...
list.of.packages <- c("tidyverse", "brms", "BayesFactor",
                      "jsonlite", "magrittr", "ggthemes",
                      "forcats", "here")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

if (!require("papaja")) devtools::install_github("crsh/papaja")
if (!require("rwebppl")) devtools::install_github("mhtess/rwebppl")

knitr::opts_chunk$set(echo=FALSE, warning=FALSE, cache=T, message=FALSE, sanitize = T, out.width = "\\textwidth", fig.pos = "!h")
library(papaja)
library(tidyverse)
library(rwebppl)
library(jsonlite)
library(magrittr)
library(ggthemes)
library(forcats)
library(langcog)
library(here)
library(lme4)
library(brms)
library(BayesFactor)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}
hdi_upper <- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}
hdi_lower <- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
options("scipen"=10)   
```

```{r load_data}
# human data 
load(here("02_analysis/01_data/speaker_production.RData"))

# human data - negation
load(here("02_analysis/01_data/speaker_production_neg.RData"))

# model posterior predictives
load(here("03_model/01_posterior_predictives/03_output_processed/postpred_summary.RData"))

# model posterior predictives - negation
load(here("03_model/01_posterior_predictives/03_output_processed/postpred_neg_summary.RData"))

# put data and model predictions together
ms_utt <- rbind(ms_data, 
                ms_model) 

# put neg data and model predictions together
ms_neg <- rbind(ms_data_neg, 
                ms_model_neg) %>%
  mutate(goal = as.factor(goal))

```

We rarely say exactly what's on our mind.
Although “close the window!” could be an effective message, we dawdle by adding “can you please...?” 
or “would you mind...?” 
Rather than tell an uncomfortable truth, socially-aware speakers lie (“Your dress looks great!”) and prevaricate (“Your poem was so appropriate to the occasion”).
Such language use is puzzling for classical views of language as information transfer [@buhler1934; @jakobson1960; @shannon1948; @frank2012]. On the classical view, transfer ought to be efficient and accurate: Speakers are expected to choose succinct utterances to convey their beliefs  [@grice1975; @searle1975], and the information conveyed is ideally truthful to the extent of a speaker's knowledge. Polite speech violates these
basic expectations about the nature of communication: It is typically
inefficient and underinformative, and sometimes even outright false. Yet even young speakers spontaneously produce
requests in polite forms [@axia1985], and adults use politeness strategies while arguing  [@holtgraves1997], even though polite utterances may risk high-stakes misunderstandings [@bonnefon2011risk]. 

If politeness only gets in the way of effective information transfer, why be polite?
Clearly, there are social concerns, and most linguistic theories assume utterance choices are motivated by these concerns, couched as either polite maxims  [@leech1983], social norms [@ide1989], or aspects of a speaker and/or listener's identity, known as *face* [@goffman1967; @brown1987].
Face-based theories predict that when a speaker's intended meaning contains a threat to the listener's face or self-image (and potentially the speaker's face), her messages will be less direct, less efficient, and possibly untruthful.
Indeed, listeners readily assume speakers' intentions to be polite when interpreting utterances in face-threatening situations [@bonnefon2009].
How this socially-aware calculation unfolds, however, is not well understood.
When should a speaker decide to say something false ("Your poem was great!" based on an example from @bonnefon2009) rather than just be indirect (\emph{Some of the metaphors were tricky to understand.})?
How does a speaker's own self-image enter into the calculation?


We propose a utility-theoretic solution to the problem of polite language use by quantifying the tradeoff between
competing communicative goals.
In our model, speakers attempt to maximize utilities that represent their communicative goals:
informational utility---derived via classical, effective
information transmission; social utility---derived by being kind and
saving the listener's face; and self-presentational utility---the most novel component of our model, 
derived by appearing in a particular way to save the speaker's own face.
Speakers then produce an utterance on the basis of
its expected utility (including their cost to speak).
The lie that a poem was great provides social utility by making the writer feel good, but does not provide information about the true state of the world.
Further, if the writer suspects that the poem was in fact terrible, the speaker runs the risk of being seen as uncooperative.

We assume that speakers' utilities are weighed within a probabilistic model of pragmatic reasoning: the Rational Speech Act (RSA) framework [@frank2012; @goodman2016]. 
Speakers are modeled as agents who choose utterances by reasoning about their potential effects on a listener, while listeners infer the meaning of an utterance by reasoning about speakers and what goals could have led them to produce their utterances.
This class of models has been effective in understanding a wide variety of complex linguistic behaviors, including vagueness [@lassiter2017adjectival], hyperbole [@kao2014], and irony [@kao2015], among others. 
In this framework, language use builds on the idea that human social cognition can
be approximated via reasoning about others as rational agents who act to
maximize their subjective utility [@baker2009action], a hypothesis which has found support in a wide variety of work with both adults and children [e.g., @jara2016naive; @liu2017ten].

```{r model, fig.cap="Diagram of the model: The polite speaker observes the true state and determines her goal between three utilities (informational, social, and presentational), and produces an utterance."}
knitr::include_graphics("fig/model.png", dpi = 170)
```

RSA models are defined recursively such that speakers \(S\)  reason about
listeners  \(L\), and vice versa. We use a standard convention in indexing and say a pragmatic listener \(L_1\) reasons about what intended meaning
and goals would have led a speaker \(S_1\) to produce a particular
utterance. Then \(S_1\) reasons about a *literal listener*
\(L_0\), who is modeled as attending only to the literal meanings of words
(rather than their pragmatic implications), and hence grounds the
recursion (see Materials and Methods for definitions of $L_0$ and $S_1$).
The target of our current work is a model of a polite speaker \(S_2\)
who reasons about what to say to \(L_1\) by
considering informational, social, and self-presentational goals  (Figure \@ref(fig:model)).

We evaluate our model's ability to predict human utterance choices
in situations where polite language use is expected.
Imagine Bob recited a poem and asked Ann how good it was.
Ann (\(S_2\)) produces an utterance \(w\) based on the true state of the world \(s\) (i.e., the
rating, in her mind, truly deserved by Bob's poem) and a set of goal weights
\(\hat{\phi}\), that determines how much Ann prioritizes each of the three possible goals.
Ann's production decision is softmax, which interpolates between
maximizing and probability matching [via $\lambda_{S_2}$; @goodman2013]:

$$P_{S_2}(w | s, \hat{\phi}) \propto \exp(\lambda_{S_2} \cdot \mathop{\mathbb{E}}[U_{total}(w; s; \hat{\phi}; \phi_{S_1})])$$.

We posit that a speaker's utility contains three distinct components: informational, social, and presentational. The
total utility $U_{total}$ of an utterance is thus the weighted combination of the three utilities minus the utterance cost \(C(w)\):

$$U_{total}(w; s; \hat{\phi}; \phi_{S_1}) = \phi_{inf} \cdot U_{inf}(w; s) + \phi_{soc} \cdot U_{soc}(w) + \phi_{pres} \cdot U_{pres}(w; \phi_{S_1}) - C(w)$$.

We define *social utility* \(U_{soc}(w)\) as the expected subjective utility of the state \(V(s)\) implied to the
pragmatic listener by the utterance: \(U_{soc}(w) = \mathbb{E}_{P_{L_1}(s \mid w)}[V(s)]\).
The subjective utility function \(V(s)\) could vary by culture and context; we test our model when states are explicit ratings (e.g., on a 4-point scale) and we assume a positive linear value relationship between states and values \(V\) to model a listener's preference to be in a highly rated state (e.g., Bob would prefer to have written a poem deserving 4 points rather than 1 point).

At the same time, a speaker may desire to be epistemically helpful, modeled as standard *informational utility* (\(U_{inf}\)).
The informational utility indexes the utterance's *surprisal*, or amount of information the listener (\(L_1\)) would still not know about the state of the world \(s\) after hearing the speaker's utterance \(w\) (e.g., how likely is Bob to guess Ann's actual opinion of the poem): \(U_{inf}(w) = \ln(P_{L_1}(s | w))\).
Speakers who optimize for informational utility produce accurate and informative utterances while those who optimize for social utility produce utterances that make the listener feel good.

If a listener is uncertain how their particular speaker is weighing the competing goals to be honest vs. kind (informational vs. social utilities), he might try to infer the weighting (e.g., "was she just being nice?").
But a sophisticated speaker can produce utterances in order to appear *as if* she had certain goals in mind, for example making the listener think that the speaker was being both kind and informative ("she wanted me to know the truth but without hurting my feelings").
The extent to which the speaker *appears* to the listener to have a particular goal in mind (e.g., to be kind) is the utterance's *presentational utility* (\(U_{pres}\)).
The speaker gains presentational utility when her listener believes she
has particular goas, represented by a mixture weighting \(\phi_{S_1}\) between trying to be genuinely informative vs. kind.
Formally,

$$U_{pres}(w; \phi_{S_1}) = \ln(P_{L_1}(\phi_{S_1} \mid w)) = \ln \int_s P_{L_1}(s, \phi_{S_1} \mid w)$$.

To define this term, the speaker has a weighting of informational vs. social goals to convey ($\phi_{S_1}$) and must consider the beliefs of listener L1, who hears an utterance and jointly infers both the speaker’s utilities and the true state of the world: 

$$P_{L_1}(s, \hat{\phi} | w) \propto P_{S_1}(w | s, \hat{\phi}) \cdot P(s) \cdot p(\hat{\phi})$$.

This presentational utility is higher-order in that it can only be defined for a speaker thinking about a listener who evaluates a speaker (i.e., it can be defined for $S_2$, but not $S_1$).

Finally, more complex utterances incur a greater cost, $C(w)$ – capturing the general pressure towards economy in speech. 
In our work, utterances with negation (e.g., “not terrible”) are assumed to be slightly costlier than their equivalents with no negation (inferred from data; see Supplementary Information). 
 
Intuitively, if Bob’s performance was good, Ann’s utilities align toward a positive utterance. 
By saying “[Your poem] was amazing,” Ann is simultaneously being truthful, kind, and appearing both truthful and kind. 
If Bob’s performance was poor, however, Ann is in a bind: Ann could be kind and say "It was great", but at the cost of conveying the wrong information to Bob if he believes her to be truthful. 
If he does not, he might infer Ann is “just being nice”, but is uninformative.
Alternatively, she could say the truth (“It was bad”), but then Bob would think Ann didn’t care about him. 
What is a socially-aware speaker to do? Our model predicts that indirect speech – like “It wasn’t bad” – helps navigate Ann’s dilemma. 
Her statement is sufficiently vague to leave open the possibility that the poem was good, but her avoidance of the simpler and less costly “It was good” provides both an inference that the performance was mediocre and a signal that she cares about Bob’s feelings.

We made a direct, pre-registered test of our model by instantiating the example above in an online experiment (*N* = 202). 
Participants read scenarios in which we provided information on the speaker’s (Ann’s, in our example) feelings toward some performance or product (e.g., poem recital; *true state*), on a scale from zero to three hearts (e.g., one out of three hearts). 
For example, one trial read: “Imagine that Bob gave a poem recital, but he didn't know how good it was. Bob approached Ann, who knows a lot about poems, and asked "How was my poem?" 
We also manipulated the speaker’s *goal* across trials: to be *informative*  (“give accurate and informative feedback”); to be *kind* (“make the listener feel good”); or to be *both* informative and kind simultaneously. 
We hypothesized that each of the three goals will represent a tradeoff between the three utilities in our model (see Supplementary Information). 
In a single trial, each scenario was followed by a question asking for the most likely utterance by Ann. Participants selected one of eight possible utterances, by choosing between *It was* vs. *It wasn’t* and then among *terrible*, *bad*, *good*, and *amazing.* 

```{r data_bayes_factor}
load(file=here("03_model/03_other_stat/bayesfactor_state_goal_interaction.Rds"))
load(file=here("03_model/03_other_stat/bayesfactor_state_goal_main_effects.Rds"))
load(file=here("03_model/03_other_stat/bayesfactor_state_only.Rds"))

BF_full_vs_main <- model1bf1/model2bf1
BF_full_vs_one <- model1bf1/model3bf1
BF_main_vs_one <- model2bf1/model3bf1
```

```{r variance, echo=FALSE, fig.cap="Full distribution of human responses vs. model predictions. Error bars represent 95\\% confidence intervals for the data (vertical) and 95\\% highest density intervals for the model (horizontal)."}
ms_var <- ms_utt %>%
  filter(source == "data" | model == "full") %>%
  select(-model) %>%
  gather(var, value, ci_lower:prob, -source, -true_state) %>%
  unite(new, c(source, var)) %>%
  mutate(positivity = fct_recode(positivity, 
                               "It was ~" = "yes",
                               "It wasn't ~" = "not",
                               "It was ~" = "It was~",
                               "It wasn't ~" = "It wasn't~"
                               ),
         positivity = fct_relevel(positivity, "It was ~"),
         goal = fct_recode(goal, "kind" = "social")) %>%
  spread(new, value)

plot_var <- ggplot(ms_var,
       aes(x = model_prob, y = data_prob)) +
  aes(shape = factor(positivity)) +
  geom_point(aes(colour = factor(goal), fill = factor(goal)), size = 2) +
  scale_shape(solid = FALSE) +
  scale_shape_manual(name = "utterance type", values = c(21, 24))+
  theme_few()+
  geom_abline(intercept = 0, slope = 1, linetype = 3) +
  geom_errorbar(aes(ymin=data_ci_lower,ymax=data_ci_upper), alpha = 0.3) +
  geom_errorbarh(aes(xmin=model_ci_lower,xmax=model_ci_upper), alpha = 0.3) +
  xlab("Model posterior predictive") +
  ylab("Human proportion responses") +
  ylim(0,1) +
  xlim(0,1) +
  scale_y_continuous(breaks=c(0, 0.25, 0.5, 0.75, 1)) +
  scale_x_continuous(breaks=c(0, .25, 0.5, 0.75, 1)) +
  theme(axis.text.y = element_text(hjust = 0, angle = 0),
        axis.text.x = element_text(vjust = 0, angle = 0),
        legend.position = "bottom",
        legend.direction = "horizontal") +
  coord_fixed()+
  scale_colour_solarized(name = "goal") +
  scale_fill_solarized() +
  guides(fill=FALSE)

plot_var

ggsave("speaker_production_cor.png", plot = plot_var, width = 7, height = 4,
       path = here::here("02_analysis/03_figs"))

cor2_mainMod = with(ms_var, cor(data_prob, model_prob))^2

```

```{r brmstat}
load(here("03_model/03_other_stat/brms_polite.Rds"))

brm.tab <- as.data.frame(summary(brms_pol)$fixed) %>%
  select(Estimate, Est.Error, 'l-95% CI', 'u-95% CI') %>%
  rename(Mean = Estimate,
         "SD" = Est.Error,
         "95% CI-Lower" = 'l-95% CI',
         "95% CI-Upper" = 'u-95% CI'
         )

brm.tab$Predictor <- c("Intercept",
                      "True state",
                      "Goal: Informative",
                      "Goal: Kind",
                      "True state * Informative",
                      "True state * Kind"
                      )
rownames(brm.tab) <- NULL
brm.tab <- brm.tab[,c(5,1:4)]
```

Our primary behavioral hypothesis was that speakers describing bad states (e.g., Bob’s performance deserved 0 heart) with goals to be both informative and kind would produce more indirect, negative utterances (e.g., “It wasn’t terrible”). 
Such indirect speech acts serve to save the listener’s face while also conveying a vague estimate of the true state. 
This prediction was confirmed: a Bayesian mixed-effects model predicting negation as a function of true state and goal yielded an interaction such that a speaker with both goals to be informative and kind produced more negation in worse states compared to a speaker with only the goal to be informative (*M* = `r brm.tab$Mean[5]`, [`r brm.tab$"95% CI-Lower"[5]`, `r brm.tab$"95% CI-Upper"[5]`]) and goal to be kind (*M* = `r brm.tab$Mean[6]`, [`r brm.tab$"95% CI-Lower"[6]`, `r brm.tab$"95% CI-Upper"[6]`]). 
Rather than eschewing one of their goals to increase utility along a single dimension, participants chose utterances that jointly satisfied their conflicting goals by producing indirect, polite speech. 

```{r comparison, fig.width=11, fig.height=4, fig.cap="Comparison of predictions for proportion of utterances chosen by pragmatic speaker from possible model variants (left) and human data (rightmost) for average proportion of negation produced among all utterances, given true state of 0 heart (on a scale of 0 to 3) and speaker with both goals to be informative and kind. Gray dotted line indicates chance level at 12.5\\%."}
plot.comp <- ms_utt %>%  
  mutate(model = case_when(
    model == "NA" ~ "human data", 
    model == "inf" ~ "model: \ninformational \nonly", 
    model == "soc" ~ "model: \nsocial only", 
    model == "pres" ~ "model: \npresentational \nonly", 
    model == "inf_pres" ~ "model: \ninformational, \npresentational", 
    model == "inf_soc" ~ "model: \ninformational, \nsocial", 
    model == "soc_pres" ~ "model: \nsocial, \npresentational", 
    model == "full" ~ "model: \ninformational, \nsocial, \npresentational" 
  ),
  model = fct_relevel(model, "model: \ninformational \nonly", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformational, \nsocial", "model: \ninformational, \npresentational", "model: \ninformational, \nsocial, \npresentational")) %>%
  mutate(positivity = fct_recode(positivity,
                                 "it was ~" = "yes",
                                 "it wasn't ~" = "not",
                                 "it was ~" = "It was~",
                                 "it wasn't ~" = "It wasn't~"
                                 ),
         positivity = fct_relevel(positivity, "it was ~")) %>%
  filter(goal == "both", true_state == "0") %>%
  ggplot(., 
       aes(x=utterance, y=prob, fill=positivity, 
           # group = interaction(positive, source), linetype = forcats::fct_rev(positive),
           group = positivity,
           colour = positivity)) +
  geom_hline(yintercept=.125, lty=2, color="gray") +
  geom_line()+
  facet_grid(.~model) +
  xlab("utterance") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position="dodge") +
  ylim(0,.7)+
  scale_color_ptol(guide=FALSE) +
  # scale_color_solarized(guide=FALSE)+
  ggthemes::theme_few(base_size = 15)+
  ylab("proportion chosen") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        legend.position="bottom") +
  guides(color=guide_legend(title=NULL))

plot.comp

ggsave("model_comparisons.png", plot = plot.comp, width = 11, height = 4,
       path = here::here("02_analysis/03_figs"))

```

```{r comparisonVar}
ms_var_comp <- ms_utt %>%
  select(-ci_lower, -ci_upper) %>%
  mutate(model = case_when(
    model == "NA" ~ "data", 
    TRUE ~ as.character(model)
  )) %>%
  mutate(positivity = fct_recode(positivity, 
                               "It was ~" = "yes",
                               "It wasn't ~" = "not",
                               "It was ~" = "It was~",
                               "It wasn't ~" = "It wasn't~"
                               ),
         positivity = fct_relevel(positivity, "It was ~")) %>%
  select(-source) %>%
  spread(model, prob)

cor2_inf = with(ms_var_comp, cor(data, inf))^2
cor2_soc = with(ms_var_comp, cor(data, soc))^2
cor2_pres = with(ms_var_comp, cor(data, pres))^2
cor2_socpres = with(ms_var_comp, cor(data, soc_pres))^2
cor2_infsoc = with(ms_var_comp, cor(data, inf_soc))^2
cor2_infpres = with(ms_var_comp, cor(data, inf_pres))^2
cor2_infsocpres = with(ms_var_comp, cor(data, full))^2

```

```{r comparisonML}
ml_infsocpres <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_self5_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_infpres <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_self6_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_infsoc <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_actual2_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_socpres <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_self7_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_inf <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_trueInf_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_soc <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_trueSoc_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_pres <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_selfPres_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]

bf_full_vs_infpres <- mean(ml_infpres) - mean(ml_infsocpres)
bf_full_vs_infsoc <- mean(ml_infsoc) - mean(ml_infsocpres)
bf_full_vs_socpres <- mean(ml_socpres) - mean(ml_infsocpres)
bf_full_vs_inf <- mean(ml_inf) - mean(ml_infsocpres)
bf_full_vs_soc <- mean(ml_soc) - mean(ml_infsocpres)
bf_full_vs_pres <- mean(ml_pres) - mean(ml_infsocpres)

bf_list <- list(bf_full_vs_inf, bf_full_vs_soc, bf_full_vs_pres,  bf_full_vs_socpres, bf_full_vs_infsoc, bf_full_vs_infpres)
bf_list_rounded <- rapply(bf_list, function(x) round(x, digits=2))
bf_list_rounded_rev <- rev(append(bf_list_rounded, "--"))
```

```{r comparisonTable, results = 'asis'}
model_list = rev(c("model: \ninformational \nonly", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformational, \nsocial", "model: \ninformational, \npresentational", "model: \ninformational, \nsocial, \npresentational"))
variance_list = rev(c(cor2_inf, cor2_soc, cor2_pres, cor2_socpres, 
                           cor2_infsoc, cor2_infpres, cor2_infsocpres))

comp_tab <- data.frame("Model" = model_list, 
                       "Variance" = variance_list, 
                       "logBF" = bf_list_rounded_rev) %>%
  rename("Variance \nexplained" = "Variance",
         "log BF" = "logBF")

apa_table(comp_tab, caption = "Comparison of variance explained for each model variant and log Bayes Factors quantifying evidence in favor of alternative model in comparison.")
```

Next, to connect the behavioral data to our model, we inferred the parameters of the RSA model (e.g., the speaker’s utility weights in each goal condition; see Supplementary Information) via a Bayesian data analysis [@lee2014]. 
To approximate the semantics of the words as interpreted by the literal listener $L_0$, we obtained literal meaning judgments from an independent group of participants (*N*=51). 
Predictions from the full polite speaker model showed a very strong fit to participants’ utterance choices ($r^2$(96) = `r cor2_mainMod`; Figure \@ref(fig:variance)).

We also compared the predictions of our model to its variants containing subsets of the three utilities in the full model. Both the variance explained and the marginal likelihood of the observed data were the highest for the full model (Table \@ref(tab:comparisonTable)).
Only the full model captured the participants’ preference for negation in the condition in which the speaker had both goals to be informative and kind about truly bad states, as hypothesized (Figure \@ref(fig:comparison)). All three utilities – informational, social, and presentational – were required to fully explain participants’ utterance choices. The utility weights inferred for the full model (Table \@ref(tab:phi)) provide additional insight into how polite language use operates: our condition manipulation altered the balance between these weights, but all utilities played a role in all conditions.

Politeness is a puzzle for purely informational accounts of language use. Incorporating social motivations can provide an explanatory framework, but such intuitions have been resistant to formalization or precise testing. To overcome this issue, we created a utility-theoretic model of language use that captured the interplay between competing informational, social, and presentational goals. A preregistered experimental test of the model confirmed its ability to capture human judgments, unlike comparison models that used only a subset of the full utility structure. 

To precisely estimate choice behavior, our experiment abstracted away from natural interactions in a number of ways. Real speakers have access to a potentially infinite range of utterances to manage the tradeoffs in our experiment (“It’s hard to write a good poem”, “That metaphor in the second stanza was so relatable!”). 
Under our framework, each utterance will have strengths and weaknesses relative to the speaker’s goals, though computation in an unbounded model presents technical challenges [perhaps paralleling the difficulty human speakers feel in finding the right thing to say in a difficult situation; see @goodman2016].

For a socially-conscious speaker, managing listeners’ inferences is a fundamental task. 
Inspired by the theory of politeness as face management [@brown1987], our model takes a step towards understanding it.
Our work extends previous models of language beyond standard informational utilities to address social and self-presentational concerns. Previous theories of language use have not explained how informational versus social concerns trade off to inform the speaker’s utterance choices. Thus, this work represents a key theoretical advance exploring how informational cooperativity interacts with other social goals.
By considering utility-driven inferences in a social context [@baker2017rational; @hamlin2013mentalistic] where agents need to take into account concerns about both self and others, 
our approach here could give insights into a wide range of social behaviors beyond speech.

The model presented here relates to other work done in game-theoretic pragmatics. 
@vanRooy2003 uses a game-theoretic analysis of polite requests (“Could you possibly take me home?”) to argue the purpose of polite language is to align the preferences of interlocutors. 
Our notion of social utility $U_{soc}$ and presentational utility $U_{pres}$ is similar in that they motivate speakers to signal worlds that make the listener feel good. 
@vanRooy2003’s analysis, however, relies on the notion that polite language is costly (in a social way e.g., by reducing one’s social status or incurring social debt to one’s conversational partner) but it’s not clear how the polite behaviors explored in our experiments (not polite requests) would incur any cost to speaker or listener. 
Our model derives its predictions by construing the speaker utility as a collection of possible goals (here, epistemic, social, and presentational goals). The speech-acts themselves are not costly.
In @pinker2008's model, human communication is assumed to involve a mixture of cooperation *and* conflict: 
indirect speech then allows for plausible deniability that is in self-interest but goes against the interest of the addressee. 
In contrast, our work builds on existing classic theories of polite speech as primarily cooperative [@grice1975; @brown1987] rather than based on both cooperation and conflict.
We have shown that a separate notion of plausible deniability may not be needed, as indirect speech in our specific case comes from both a goal to be helpful and a desire to look good.
Our work is able to capture different linguistic nuances involved in this process of reasoning about different goals that speakers have. 

By experimenting with different utility weights and value functions, our model could provide a framework for understanding systematic cross-cultural differences in what counts as polite. 
For example, following @brown1987, cross-cultural differences in politeness could be a product of different weightings within the same utility structure. 
It is also possible, however, that culture affects the value function $V$ that maps states of the world onto subjective values for the listener (e.g., the mapping from states to utilities may be more complex than we have considered). 
Our formal modeling approach with systematic behavior measurements provides an avenue towards understanding the vast range of politeness practices found across languages.

Politeness is only one of the ways that language use deviates from pure information transfer. 
When we flirt, insult, boast, and empathize, we also balance being informative with goals to affect others’ feelings and present particular views of ourselves. 
Our work shows how social and self-presentational motives can be integrated with other concerns more generally, opening up the possibility for a broader theory of social language. 
Further, a formal account of politeness moves us closer to courteous computation – to computers that can communicate with tact.

# Acknowledgments

This work was supported by NSERC PGS Doctoral scholarship PGSD3-454094-2014 to EJY, NSF Graduate Research Fellowship DGE-114747 to MHT, ONR grant N00014-13-1-0788 to NDG, and NSF grant BCS 1456077 to MCF.

\newpage

# Methods

## Literal semantic task

We probed judgments of literal meanings of the target words assumed by our model and used in our main experiment. 
51 participants with IP addresses in the United States were recruited on Amazon’s Mechanical Turk. 
We used thirteen different context items in which a speaker evaluated a performance of some kind. 
For example, in one of the contexts, Ann saw a presentation, and Ann’s feelings toward the presentation (true state) were shown on a scale from zero to three hearts (e.g., two out of three hearts filled in red color; see Figure\ \@ref(fig:screenshot) for an example of the heart scale). 
The question of interest was "Do you think Ann thought the presentation was / wasn’t X?" and participants responded by choosing either “no” or “yes.” 
The target could be one of four possible words: *terrible*, *bad*, *good*, and *amazing*, giving rise to eight different possible utterances (with negation or no negation). 
Each participant read 32 scenarios, depicting every possible combination of states and utterances. 
The order of context items was randomized, and there were a maximum of four repeats of each context item per participant. 
For this and the speaker production experiment, we analyzed the data by collapsing across context items.
For each utterance-state pair, we computed the posterior distribution over the semantic weight (i.e., how consistent X utterance is with Y state) assuming a uniform prior over the weight (i.e., a standard Beta-Binomial model). 
Meanings of the words as judged by participants were as one would expect (Figure \ \@ref(fig:litsem)). 

```{r litsem, echo=FALSE, fig.width = 10, fig.height = 4, out.width = "\\textwidth", fig.pos = "!h", fig.cap = "Semantic measurement results. Proportion of acceptances of utterance types (shown in different colors) combined with target words (shown in different facets) given the true state represented on a scale of hearts. Error bars represent 95\\% confidence intervals."}
d <- read.csv(here("02_analysis/01_data/literal_semantics.csv")) %>%
  mutate(utterance = fct_relevel(utterance, "terrible", "bad", "good", "amazing"))

ms <- d %>%
  mutate(positivity = fct_recode(positivity,
                                "it was ~ " = "it was ___",
                                "it wasn't ~ " = "it wasn't ___"
                                ),
         positivity = fct_relevel(positivity, "it was ~ ")) %>%
  group_by(positivity, state, utterance, subid) %>%
  summarize(
            judgment = mean(judgment, na.rm=TRUE)
          ) %>%
  group_by(positivity, state, utterance) %>%
  multi_boot_standard(col = "judgment") %>%
  mutate(judgment = mean)

qplot(state, judgment, 
      colour = positivity,
      data=ms) + 
  geom_line(aes(group=positivity)) +
  facet_grid(.~utterance) +
  xlab("state (0=worst)") +
  ylab("proportion of\n acceptances") +
  geom_errorbar(aes(ymin=ci_lower,ymax=ci_upper,width=.1)) +
  theme_few(base_size = 16) +
  scale_color_ptol(name="")+
  # scale_color_solarized() +
  theme(legend.position = "bottom") +
  geom_hline(yintercept = .5, lty=2)

ggsave("literal_semantics.png", width = 7, height = 3,
       path = here::here("02_analysis/03_figs"))
```


## Speaker production task

```{r screenshot, fig.pos = "!h", fig.cap="Example of a trial in the speaker production task."}
knitr::include_graphics("fig/screenshot.png", dpi = 130)
```

202 participants with IP addresses in the United States were recruited on Amazon’s Mechanical Turk. As in the literal semantic task above, we used scenarios in which a person (e.g., Bob) gave some performance and asked for another person (e.g., Ann)’s opinion on the performance (Figure \ \@ref(fig:screenshot)). Additionally, we provided information on the speaker Ann’s goal – to make Bob feel good, or to give as accurate and informative feedback as possible, or both – and the true state – how Ann actually felt about Bob’s performance (e.g., two out of three hearts, on a scale from zero to three hearts; Figure\ \@ref(fig:screenshot)). 
Each participant read twelve scenarios, depicting every possible combination of the three goals and four states. 
The order of context items was randomized, and there were a maximum of two repeats of each context item per participant.
Each scenario was followed by a question that read, "If Ann wanted to make Bob feel good but not necessarily give informative feedback (or to give accurate and informative feedback but not necessarily make Bob feel good, or BOTH make Bob feel good AND give accurate and informative feedback), what would Ann be most likely to say?" 
Participants indicated their answer by choosing one of the options on the two dropdown menus, side-by-side, one for choosing between *It was* vs. *It wasn’t* and the other for choosing among *terrible*, *bad*, *good*, and *amazing.*

# Supplementary Information

## Data analysis
We used `r cite_r("politeness.bib")` for all our analyses.

## Full statistics on human data

```{r brmTab, results="asis"}
apa_table(brm.tab, caption= "Predictor mean estimates with standard deviation and 95% credible interval information for a Bayesian linear mixed-effects model predicting negation production based on true state and speaker goal (with both-goal as the reference level).")
```

We used Bayesian linear mixed-effects models [`brms` package in R; @R-brms] using crossed random effects of true state and goal with maximal random effects structure [@gelman2006data; @barr2013random].

## Model fitting and inferred parameters

```{r phi, results = 'asis'}
load(here("03_model/01_posterior_predictives/03_output_processed/phi_summary.RData"))
load(here("03_model/01_posterior_predictives/03_output_processed/other_param_summary.RData"))

phi_tab <- d_phi_s %>%
  mutate_at(vars(informative:social), as.numeric) %>%
  mutate_if(is.numeric, function(x) round(x, digits=2)) %>%
  ungroup() %>%
    mutate(model = case_when(
    model == "inf" ~ "ninformational only", 
    model == "soc" ~ "social only", 
    model == "pres" ~ "presentational only", 
    model == "InfPres" ~ "ninformational, presentational", 
    model == "InfSoc" ~ "ninformational, social", 
    model == "SocPres" ~ "social, presentational", 
    model == "Full" ~ "ninformational, social, presentational" 
  )) %>%
  select(model, goal, informative, social, Selfpres, s1)

colnames(phi_tab) <- c("Model", "goal", "$\\phi_{inf}$", "$\\phi_{soc}$", "$\\phi_{pres}$", "$\\phi_{S_1}$")

apa_table(phi_tab, escape=FALSE, caption = "Inferred phi parameters from all model variants with more than one utility.")
```

```{r otherParams, results='asis'}
other_tab <- d_other_s %>%
    mutate(model = case_when(
    model == "inf" ~ "ninformational only", 
    model == "soc" ~ "social only", 
    model == "pres" ~ "presentational only", 
    model == "inf_pres" ~ "ninformational, presentational", 
    model == "inf_soc" ~ "ninformational, social", 
    model == "soc_pres" ~ "social, presentational", 
    model == "full" ~ "ninformational, social, presentational" 
  )) %>%
  mutate(param = round(param, digits=2)) %>%
  spread(parameter, param)

colnames(other_tab) <- c("Model", "Cost of negation", "Speaker optimality")

apa_table(other_tab, escape=FALSE, caption = "Inferred negation cost and speaker optimality parameters for all model variants.")
```

In the speaker production task, participants were told the speakers’ intentions (e.g., wanted to make Bob feel good). 
We assume that the intention descriptions conveyed some mixture of weights $\phi_{epi}$, $\phi_{soc}$, $\phi_{pres}$, and $\phi_{S_1}$ that the speaker was using. 
We put uninformative priors on the unnormalized mixture weights ($\phi$ ~ $Uniform(0,1)$) separately for each goal condition ("wanted to be X"; *kind*, *informative*, or *both*).
In addition, the full model has two global parameters: the speaker's soft-max parameter $\lambda_{S_2}$ and soft-max paramater of the hypothetical speaker that the pragmatic listener reasons about $\lambda_{S_1}$.
$\lambda_{S_1}$ was 1, and $\lambda_{S_2}$ was inferred from the data: 
We put a prior that was consistent with those used for similar models in this model class: $\lambda_{S_2}$ ~ $Uniform(0,20)$.
Finally, we incorporate the literal semantics data into the RSA model by maintaining uncertainty about the semantic weight of utterance $w$ for state $s$, for each of the states and utterances, and assuming a Beta-Binomial linking function between these weights and the literal semantics data (see *Literal semantics task* above).
We infer the posterior distribution over all of the model parameters and generate model predictions based on this posterior distribution using Bayesian data analysis [@lee2014]. 
We ran 4 MCMC chains for 80,000 iterations, discarding the first 40,000 for burnin. 
The inferred values of weight mixtures for each model variant (with different $\phi$ components) and other parameters are shown in Table \@ref(tab:phi) and Table \@ref(tab:otherParams), respectively.

## Data Availability

Our model, preregistration of hypotheses, procedure, data, and analyses are available at \url{https://github.com/ejyoon/polite_speaker}. 

## Supplemental Figures

```{r utterance, echo=FALSE, out.width = "\\textwidth", fig.pos = "!h", fig.height=6, fig.cap="Experimental results (solid lines) and fitted predictions from the full model (dashed lines) for speaker production. Proportion of utterances chosen (utterance type – direct vs. indirect – in different colors and words shown on x-axis) given the true states (columns) and speaker goals (rows). Error bars represent 95\\% confidence intervals for the data and 95\\% highest density intervals for the model. Black dotted line represents the chance level."}
plot.utt <- ggplot(data=ms_utt %>%
                     filter(source == "data" | model == "full") %>%
                     mutate(positivity = fct_relevel(positivity, "not"),
                            true_state = fct_recode(true_state,
                                                    "0 heart" = "0", 
                                                    "1 heart" = "1", 
                                                    "2 hearts" = "2", 
                                                    "3 hearts" = "3" 
                                                    ),
                            goal = fct_recode(goal, "kind" = "social")), 
       aes(x=utterance, y=prob, group = interaction(positivity, source), colour = positivity, linetype = source)) +
  geom_line()+
  facet_grid(goal~true_state, labeller = labeller(goal = label_both)) +
  xlab("utterance") +
  ylab("proportion chosen") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position="dodge") +
  geom_hline(yintercept=.1, lty=2) +
  ylim(0,1)+
  scale_color_solarized(labels = c("It wasn't~","It was~"))+
  ggthemes::theme_few()+
  theme(axis.text.x = element_text(angle = 45, vjust=0.5),
        legend.position = "bottom") +
  guides(colour=guide_legend(title="utterance type")) +
  scale_linetype_discrete(labels = c("data", "model"))

plot.utt

ggsave("speaker_production_utt_wMod.png", plot = plot.utt, width = 7, height = 5,
       path = here::here("02_analysis/03_figs"))
```

```{r comparisonAll, echo=FALSE, out.width = "\\textwidth", fig.pos = "!h", fig.width=11, fig.height=7, fig.cap="Comparison of predictions for proportion of utterances chosen by pragmatic speaker from possible model variants (left) and human data (rightmost) for average proportion of negation produced among all utterances, given true state of 0 heart and speaker with a goal to be informative (top), kind (middle), or both (bottom). Gray dotted line indicates chance level at 12.5\\%."}
plot.comp.all <- ms_utt %>%  
  mutate(model = case_when(
    model == "NA" ~ "Human data", 
    model == "inf" ~ "model: \ninformational \nonly", 
    model == "soc" ~ "model: \nsocial only", 
    model == "pres" ~ "model: \npresentational \nonly", 
    model == "inf_pres" ~ "model: \ninformational, \npresentational", 
    model == "inf_soc" ~ "model: \ninformational, \nsocial", 
    model == "soc_pres" ~ "model: \nsocial, \npresentational", 
    model == "full" ~ "model: \ninformational, \nsocial, \npresentational" 
  ),
  model = fct_relevel(model, "model: \ninformational \nonly", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformational, \nsocial", "model: \ninformational, \npresentational", "model: \ninformational, \nsocial, \npresentational")) %>%
  mutate(positivity = fct_recode(positivity,
                                 "It was ~" = "yes",
                                 "It wasn't ~" = "not"),
         positivity = fct_relevel(positivity, "It wasn't ~"),
         goal = fct_recode(goal, "kind" = "social") 
         ) %>%
  filter(true_state == "0") %>%
  ggplot(., 
       aes(x=utterance, y=prob, fill=positivity, 
           # group = interaction(positive, source), linetype = forcats::fct_rev(positive),
           group = positivity,
           colour = positivity)) +
  geom_hline(yintercept=.125, lty=2, color="gray") +
  geom_line()+
  facet_grid(goal~model, labeller = labeller(goal = label_both)) +
  xlab("utterance") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position="dodge") +
  ylim(0,.7)+
  scale_color_solarized(guide=FALSE)+
  ggthemes::theme_few(base_size = 15)+
  ylab("proportion chosen") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        legend.position="bottom") +
  guides(color=guide_legend(title=NULL))

plot.comp.all

ggsave("model_comparisons_all.png", plot = plot.comp.all, width = 11, height = 4,
       path = here::here("02_analysis/03_figs"))

```

```{r negation, echo=FALSE, fig.width=11, fig.height=4, out.width = "\\textwidth", fig.pos = "!h", fig.cap="Experimental results (left) and fitted model predictions (right) for average proportion of negation produced among all utterances, given true states (x-axis) and goals (colors)."}
plot.neg <- ms_neg %>%  
  mutate(model = case_when(
    model == "NA" ~ "Human data", 
    model == "inf" ~ "model: \ninformational \nonly", 
    model == "soc" ~ "model: \nsocial only", 
    model == "pres" ~ "model: \npresentational \nonly", 
    model == "inf_pres" ~ "model: \ninformational, \npresentational", 
    model == "inf_soc" ~ "model: \ninformational, \nsocial", 
    model == "soc_pres" ~ "model: \nsocial, \npresentational", 
    model == "full" ~ "model: \ninformational, \nsocial, \npresentational" 
  ),
  model = fct_relevel(model, "model: \ninformational \nonly", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformational, \nsocial", "model: \ninformational, \npresentational", "model: \ninformational, \nsocial, \npresentational")) %>%
  ggplot(., 
       aes(x=true_state, y=prob, color = goal, group=goal)) +
  geom_line(stat="identity", position=position_dodge()) +
  xlab("true state") +
  ylab("proportion negation") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position=position_dodge(width=.05)) +
  theme_few(base_size = 15)+
  scale_color_solarized() +
  facet_grid(.~model) +
  theme(legend.position="bottom")

plot.neg

ggsave("speaker_production_neg_wMod.png", plot = plot.neg, width = 7, height = 3,
       path = here::here("02_analysis/03_figs"))
```

\newpage

# References
```{r create_r-references}
r_refs(file = "politeness.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

