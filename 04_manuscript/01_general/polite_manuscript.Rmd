---
title             : "Polite speech emerges from competing social goals"
shorttitle        : "Modeling polite speech"

author: 
  - name          : "Erica J. Yoon"
    affiliation   : "1, *, †"
    corresponding : yes    # Define only one corresponding author
    address       : "450 Serra Mall, Bldg. 420, Rm. 290, Stanford, CA 94305"
    email         : "ejyoon@stanford.edu"
  - name          : "Michael Henry Tessler"
    affiliation   : "1, †"
  - name          : "Noah D. Goodman"
    affiliation   : "1"
  - name          : "Michael C. Frank"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Stanford University"
  - id            : "\\*"
    institution   : "Corresponding author"
  - id            : "\\†"
    institution   : "These authors contributed equally to this work."

author_note: |
  All authors designed research and wrote the paper; E.J.Y. and M.H.T. performed research and analyzed data. The authors declare no conflict of interest. This work was supported by NSERC PGS Doctoral scholarship PGSD3-454094-2014 to EJY, NSF Graduate Research Fellowship DGE-114747 to MHT, ONR grant N00014-13-1-0788 to NDG, and NSF grant BCS 1456077 to MCF.


abstract: |
  Language is a remarkably efficient tool for transmitting information. Yet human speakers make statements that are inefficient, imprecise, or even contrary to their own beliefs, all in the service of being polite. What rational machinery underlies polite language use? Here, we show that polite speech emerges from the competition of three communicative goals: to convey information, to be kind, and to present oneself in a good light. We formalize this goal tradeoff using a probabilistic model of utterance production, which predicts human utterance choices in socially-sensitive situations with high quantitative accuracy, and we show that our full model is superior to its variants with subsets of the three goals. This utility-theoretic approach to speech acts takes a step towards explaining the richness and subtlety of social language use.
  
keywords          : "politeness, computational modeling, communicative goals, pragmatics"
wordcount         : "5500"

header-includes:
  - \usepackage{xcolor}
  - \usepackage[skip=1pt,font=scriptsize]{caption}
  - \usepackage{placeins}

bibliography      : ["politeness.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes
mask              : no

class             : "man"
output            : papaja::apa6_pdf
---

\definecolor{Blue}{RGB}{10,100,200}
\definecolor{Red}{RGB}{255,0,0}

\newcommand{\red}[1]{{\textcolor{Red}{#1}}}
\newcommand{\mht}[1]{{\textcolor{Blue}{[mht: #1]}}}



```{r include_packages, include = FALSE}
# check to see if user has packages. otherwise, install them...
list.of.packages <- c("tidyverse", "brms", "BayesFactor",
                      "jsonlite", "magrittr", "ggthemes",
                      "forcats", "here")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

if (!require("papaja")) devtools::install_github("crsh/papaja")
if (!require("rwebppl")) devtools::install_github("mhtess/rwebppl")

knitr::opts_chunk$set(echo=FALSE, warning=FALSE, cache=T, message=FALSE, sanitize = T, out.width = "\\textwidth", fig.pos = "!h")
library(papaja)
library(tidyverse)
library(rwebppl)
library(jsonlite)
library(magrittr)
library(ggthemes)
library(forcats)
library(langcog)
library(here)
library(lme4)
library(brms)
library(BayesFactor)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}
hdi_upper <- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}
hdi_lower <- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
options("scipen"=10)   
```

```{r load_data}
# human data 
load(here("02_analysis/01_data/speaker_production.RData"))

# human data - negation
load(here("02_analysis/01_data/speaker_production_neg.RData"))

# model posterior predictives
load(here("03_model/01_posterior_predictives/03_output_processed/postpred_summary.RData"))

# model posterior predictives - negation
load(here("03_model/01_posterior_predictives/03_output_processed/postpred_neg_summary.RData"))

# put data and model predictions together
ms_utt <- rbind(ms_data, 
                ms_model) 

# put neg data and model predictions together
ms_neg <- rbind(ms_data_neg, 
                ms_model_neg) %>%
  mutate(goal = as.factor(goal))

```

# Introduction

We don’t always say what's on our minds.
Although “close the window!” could be sufficient, 
we dawdle, adding “can you please...?” or “would you mind...?” 
Rather than tell an uncomfortable truth, socially-aware speakers exaggerate (“Your dress looks great!”) and prevaricate (“Your poem was so appropriate to the occasion”).
Such language use is puzzling for classical views of language as information transfer [@buhler1934; @jakobson1960; @shannon1948; @frank2012]. 
On the classical view, transfer ought to be efficient and accurate: 
Speakers are expected to choose succinct utterances to convey their beliefs [@grice1975; @searle1975], 
and the information conveyed is ideally truthful to the extent of a speaker's knowledge. 
Polite speech violates these basic expectations about the nature of communication: 
It is typically inefficient and underinformative, and sometimes even outright false. 
Yet even young speakers spontaneously produce requests in polite forms [@axia1985], and adults use politeness strategies pervasively -- even while arguing [@holtgraves1997], and
even though polite utterances may risk high-stakes misunderstandings [@bonnefon2011risk].

If politeness only gets in the way of effective information transfer, why be polite?
Clearly there are social concerns, and most linguistic theories assume speaker behavior is motivated by these concerns, 
couched as either polite maxims [@leech1983], social norms [@ide1989], or aspects of a speaker and/or listener's identity, known as *face* [@goffman1967; @brown1987].
Face-based theories predict that when a speaker's intended meaning contains a threat to the listener's face or self-image (and potentially the speaker's face), her messages will be less direct, less efficient, and possibly untruthful.
Indeed, when interpreting utterances in face-threatening situations, listeners readily assume that speakers intend to be polite [@bonnefon2009].
How this socially-aware calculation unfolds, however, is not well understood.
Adopting an example from @bonnefon2009, when should a speaker decide to say something false ("Your poem was great!" said of an actually-mediocre poem) rather than to tell the truth (“Your poem was bad”) or to be indirect (“Some of the metaphors were tricky to understand.”)?
How do the speaker’s goals enter into the calculation?

We propose a utility-theoretic solution to the problem of understanding polite language, in which speakers choose their utterance by attempting to maximize utilities that represent competing communicative goals.
Under the classic pragmatic view of language production, speakers want to be informative and convey accurate information as efficiently as possible [@grice1975; @goodman2016]; this desire for informative and efficient communication we call *informational utility*.
In addition, speakers may want to be kind and make the listener feel good (i.e., save the listener’s face), for example, by stating positive remarks about the listener.
We call this goal to be *prosocial utility*.

If a speaker wanted to be informative and kind, then she would ideally produce utterances that satisfy both goals. 
The nuances of reality, however, can make it difficult to satisfy both goals.
In particular, when the true state of the world is of low value to the listener (e.g., the listener’s poem was terrible), informational and prosocial goals pull in opposite directions. 
Informational utility could be maximized by stating the blunt truth (“your poem was terrible.”) but that would very likely hurt the listener’s feelings and threaten the listener’s self-image (low prosocial utility); 
prosocial utility could be maximized through a white lie (“your poem was amazing”), but it would be misleading (low informational utility). 
In such situations, it seems impossible to be both truthful and kind. A first contribution of our work here is to formalize the details of this tradeoff so that it can make contact with experimental data. 

A second contribution of our work is to develop and test a new theoretical proposal, namely, that speakers may use indirect speech to present themselves positively when they are caught by the conflict between truthfulness and kindness. We propose that speakers may navigate their way out of this conflict by signalling to the listener that they care about both  of the goals even though they are genuinely unable to fulfill them. We formalize this notion of *self-presentational utility* and show that it leads speakers to prefer more indirect speech, namely utterances that provide less information relative to their length than alternatives with a similar meaning. 

We look at indirect speech in this paper through negated adjectival phrases (e.g., “It wasn’t bad”). 
The relationship between negation and politeness is a topic of long-standing interest to linguists and psychologists [@stoffel1901intensives; @stern1931meaning; @bolinger1972degree; @horn1989natural].
Comprehending negation, as a logical operation, can be psychologically more complex than comprehending an unnegated assertion; negating assertions can result in difficulty in processing [@clark1972; see @nordmeyer2014 for an underlying pragmatic explanation] as well as failure to recognize or recall the asserted content [@macdonald1989; @lea2002]. 
Our interest in negation, however, is for its information-theoretic properties: Negating an assertion that has a specific meaning results in a meaning that is less precise and lower in informativity (e.g., negating “Alex has blue eyes” results in the statement that Alex has eyes that are some color other than blue”).
In our paradigm, we use negation as a way of turning a relatively direct statement (“It was terrible”) into an indirect statement (“It wasn’t terrible”) whose interpretation includes some possibilities that are consistent with or close to the unnegated statement  (i.e., the poem was not terrible, but it was still pretty bad). 

Multifactorial, verbal theories -- like previous proposals regarding politeness -- are very difficult to relate directly to behavioral data. Therefore, to test our hypotheses about the factors underlying the production of polite language (what we refer to as its utility structure), we take a model comparison approach. We do this by formalizing the trade-off between different combinations of speakers' utilities in a class of probabilistic models of language use (the Rational Speech Act (RSA) framework; @frank2012; @goodman2016), with a particular focus on models with and without the self-presentational utility. In this framework, speakers are modeled as agents who choose utterances by reasoning about their potential effects on a listener, while listeners infer the meaning of an utterance by reasoning about speakers and what goals could have led them to produce their utterances.
These models build on the idea that human social cognition can
be approximated via reasoning about others as rational agents who act to
maximize their subjective utility [@baker2009action], a hypothesis which has found support in a wide variety of work with both adults and children [e.g., @jara2016naive; @liu2017ten].
Indeed, this class of pragmatic language models has been productively applied to understand a wide variety of complex linguistic behaviors, including vagueness [@lassiter2017adjectival], hyperbole [@kao2014], and irony [@kao2015], among others. 

```{r model, out.width = "90%", fig.pos = "!h", fig.cap="Diagram of the model. Top: First-order polite speaker ($S_1$) produces an utterance by thinking about: (1) the true state of the world (i.e., how good a given performance was); (2) the reasoning of literal listener who updates his beliefs about the true state via the literal meanings of utterances (e.g., “not terrible” means approximately 1.5 heart out of 3 hearts) and their affective consequences for the listener; and (3) her goal of balancing informational and social utilities. Bottom: Second-order polite speaker ($S_2$) produces an utterance by thinking about (1) the true state; (2) the pragmatic listener who updates his beliefs about the true state and the first-order speaker $S_1$’s goal (via reasoning about the $S_1$ model); and (3) her goal of balancing informational, prosocial, and self-presentational utilities. Different utterances shown correspond to different weightings of the utility components."}
knitr::include_graphics("fig/model.png", dpi = 160)
```

# Model

RSA models are defined recursively such that speakers \(S\) reason about
listeners \(L\), and vice versa. We use a standard convention in indexing and say a pragmatic listener \(L_1\) reasons about what intended meaning
and goals would have led a speaker \(S_1\) to produce a particular
utterance. \(S_1\) reasons about a *literal listener*
\(L_0\), who is modeled as attending only to the literal meanings of words
(rather than their pragmatic implications), and hence grounds the
recursion (Figure \@ref(fig:model), top).
The target of our current work is a model of a polite speaker \(S_2\)
who reasons about what to say to \(L_1\) by
considering some combination of informational, social, and self-presentational goals (Figure \@ref(fig:model), bottom).

We evaluate our model's ability to predict human speaker production behavior 
in situations where polite language use is expected.
Our experimental context involves a speaker (“Ann”) responding to the request of their listener (“Bob”) to evaluate the listener’s (Bob’s) creative product.
For instance, Bob recited a poem and asked Ann how good it was.
Ann (\(S_2\)) produces an utterance \(w\) based on the true state of the world \(s\) (i.e., the
rating, in her mind, truly deserved by Bob's poem) and a set of goal weights
\(\boldsymbol{\omega}\), that determines how much Ann prioritizes each of the three possible goals, as well as a goal weight to convey to the listener \(\phi\); more details below).
Following standard practice in RSA models, Ann's production decision is softmax, which interpolates between choosing the maximum-utility utterance and probability matching [via speaker optimality parameter $\alpha$; @goodman2013]:

\begin{equation}
P_{S_2}(w | s, \boldsymbol{\omega}) \propto \exp(\alpha \cdot \mathop{\mathbb{E}}[U_{total}(w; s; \boldsymbol{\omega}; \phi)]). \label{eq:S2}
\end{equation}


We posit that a speaker's utility contains distinct components that represent three possible goals that speakers may entertain: informational, social, and presentational. These components were determined based on multiple iterations of preliminary experiments, after which we conducted the preregistered test of our specified model with the specific utilities that we report below.

We take the total utility $U_{total}$ of an utterance to be the weighted combination of the three utilities minus the utterance cost \(C(w)\), simply used to capture the general pressure towards economy in speech (e.g., longer utterances are more costly):


\begin{equation}
U_{total}(w; s; \boldsymbol{\omega}; \phi) = \omega_{inf} \cdot U_{inf}(w; s) + \omega_{soc} \cdot U_{soc}(w) + \omega_{pres} \cdot U_{pres}(w; \phi) - C(w). \label{eq:UTotal}
\end{equation}

First, a speaker may desire to be epistemically helpful, modeled as standard *informational utility* (\(U_{inf}\)).
The informational utility indexes the utterance's *surprisal*, or amount of information the listener (\(L_1\)) would still not know about the state of the world \(s\) after hearing the speaker's utterance \(w\) (e.g., how likely is Bob to guess Ann's actual opinion of the poem): \(U_{inf}(w) = \ln(P_{L_1}(s | w))\).

Speakers who optimize for informational utility produce accurate and informative utterances while those who optimize for social utility produce utterances that make the listener feel good.
We define *social utility* (\(U_{soc}\)) to be the expected subjective utility of the state \(V(s)\) implied to the
pragmatic listener by the utterance: \(U_{soc}(w) = \mathbb{E}_{P_{L_1}(s \mid w)}[V(s)]\).
The subjective utility function \(V(s)\) is the mapping from states of the world to subjective values, which likely varies by culture and context; we test our model when states are explicit ratings (e.g., numbers on a 4-point scale) and we assume the simplest positive linear relationship between states and values \(V\), where the subjective value is the numerical value of the state (i.e., the number of hearts). For example, Bob would prefer to have written a poem deserving 4 hearts rather than 1 heart and the strength of that preference is 4-to-1.

Listeners who are aware that speakers can be both kind and honest could try to infer the relative contribution of these two goals to the speaker’s behavior (e.g., by asking himself: "was Ann just being nice?").
Thus, we use a pragmatic listener model who has uncertainty about the speaker’s goal weight (relative contribution of niceness vs. informativeness) in addition to their uncertainty about the state of the world (number of hearts;  Eq. \ref{eq:L1}).
A speaker gains presentational utility when her listener believes she
has particular goals, represented by a mixture parameter \(\phi\) weighting the goals to be genuinely informative vs. kind.

A sophisticated speaker can then produce utterances in order to appear *as if* she had certain goals in mind, for example making the listener think that the speaker was being both kind and informative.
Such a *self-presentational* goal may be the result of a speaker trying to save their own face (*I want the listener to see that I’m a decent person*) and can result in different speaker behavior depending on the intended, communicated goal of the speaker (e.g., *I want the listener to think I’m being honest* vs. *nice* vs. *both*)^[In principle, one could define a listener \(L_2\) who reasons about this clever speaker and tries to uncover the goals that the speaker was trying to convey to them; we think such reasoning is reserved for very special relationships and is unlikely to manifest in the more basic acts of polite language use that we study here.].

The extent to which the speaker *projects* a particular goal to the listener (e.g., to be kind) is the utterance's *presentational utility* (\(U_{pres}\)).
Formally,

\begin{equation}
U_{pres}(w; \phi) = \ln(P_{L_1}(\phi \mid w)) = \ln \int_s P_{L_1}(s, \phi \mid w).
\end{equation}


\noindent The speaker projects a particular weighting of informational
vs. social goals (\(\phi\)) by considering the
beliefs of listener \(L_1\), who hears an utterance and jointly infers
the speaker's utilities and the true state of the world:

\begin{equation}
P_{L_1}(s, \phi | w) \propto P_{S_1}(w | s, \phi) \cdot P(s) \cdot P(\phi). \label{eq:L1}
\end{equation}

\noindent The presentational utility is the highest-order term of the model, defined only for a speaker thinking about a listener who evaluates a speaker
(i.e., defined for the second-order speaker \(S_2\), but not the first-order speaker \(S_1\)). 
Only the social and informational utilities are defined for the first-order \(S_1\) speaker (via reasoning about \(L_0\)); thus, \(S_1\)'s utility weightings can be represented by a single number, the mixture parameter \(\phi\).
Definitions for \(S_1\) and \(L_0\) otherwise mirror those of \(S_2\) and \(L_1\) and we use the same speaker optimality parameter for \(S_1\) as for \(S_2\) for simplicity; these sub-models are defined in the next section and appear in more detail in the Supplementary Materials. The complete model specification is shown in Figure \@ref(fig:bayesnet).

Within our experimental domain, we assume there are four possible states
of the world corresponding to the value placed on a particular referent
(e.g., the 1-to-4 numeric rating of the poem the speaker is commenting on), represented in terms of numbers of hearts (Figure \@ref(fig:model)):
\(S = {s_0,...,s_3}\). In the experiment, participants are told that the listener has no idea about the quality of the product; thus, both listener models \(L_1\) and \(L_0\) assume uniform priors P(s) over the four possible heart states. The pragmatic listener’s prior distribution over the first-order speaker’s utility weights \(P(\phi)\) encodes baseline assumptions about the relative informativeness vs. niceness listener’s expect, which plausibly varies by culture and context; for simplicity, we assume this distribution to be uniform over the unit interval (0, 1). The set of utterances for the speaker models S_2 and S_1 is \{*terrible*, *bad*, *good*, *amazing*, *not terrible*, *not bad*, *not good*, and *not amazing*\} and the cost of an utterance is its length in terms of number of words (i.e., utterances with negation are costlier than those without negation) scaled by a free parameter. We implemented this model using the probabilistic programming language WebPPL [@dippl] and a demo can be found at \url{http://forestdb.org/models/politeness.html}.


# Model predictions


```{r schematicPredictions}
load(here("02_analysis/01_data/s2_schematic_predictions_v2.RData"))

fig.marginal.utility.s2 <- rs.s2 %>%
  mutate(utility = case_when(
    phi_informative > 0.9 ~ "informational",
    phi_social > 0.9 ~ "social",
    phi_selfpres > 0.9 & phi_S1 == 0.25 ~ "presentational \n(both-goal)",
    phi_selfpres > 0.9 & phi_S1 == 0.05 ~ "presentational \n(social)",
    phi_selfpres > 0.9 & phi_S1 == 0.95 ~ "presentational \n(informative)",
    phi_informative == phi_social & phi_selfpres < 0.1 ~ "inf, soc",
    phi_informative == phi_selfpres & phi_social < 0.1  & phi_S1 == 0.25~ "inf, pres",
    phi_social == phi_selfpres & phi_informative < 0.1  & phi_S1 == 0.25~ "soc, pres",
    phi_informative == phi_social & phi_social == phi_selfpres  & phi_S1 == 0.25~ "inf, soc, pres",
    TRUE ~ "NA"
  )) %>%
  mutate(utility = fct_relevel(utility, "informational", "social", "presentational \n(informative)", "presentational \n(social)", "presentational \n(both-goal)", "inf, soc", "inf, pres", "soc, pres", "inf, soc, pres")) %>%
  filter(state == 0, utility != "NA") %>%
  filter(utility %in% c("informational", "social", "presentational \n(informative)", "presentational \n(social)", "presentational \n(both-goal)")) %>%
  # filter(state == 0, phi_S1 %in% c(0.05, 0.25, 0.5, 0.75, 0.95), phi_selfpres > 0.9) %>%
  select(-phi_social, -phi_selfpres, -phi_informative, -state, -phi_S1) %>%
  gather(utt, prob, -utility) %>%
  separate(utt, into = c("positive", "utterance")) %>%
  mutate(positive = factor(positive, levels = c("yes", "not"),
                           labels = c("it was ~", "it wasn't ~")),
         utterance = factor(utterance, levels = c("terrible", "bad", "good", "amazing"))) %>%
  group_by(utility, positive, utterance) %>%
  summarize(prob = mean(prob)) %>%
  ggplot(., aes( x = utterance, color = positive, y = prob, group = positive))+
  geom_line()+
  facet_wrap(~utility, nrow = 1)+
  scale_color_ptol() +
  theme_few(base_size = 14)+
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        strip.text.y = element_text(angle = 180),
        legend.title = element_blank(),
        legend.position = "bottom",
        # title = element_text(size = 8),
        # axis.title.y = element_text(size = 11)
        )+
  # scale_y_continuous(limits = c(0, 0.75), breaks = c(0, 0.75), position = "left")+
  # ggtitle("Self-presentational mixture (0 = fully social; 1 = fully informational)")+
  ylab(expression("Schematic " * S[2] * "'s production probability"))

rs.s2.tidy <- rs.s2 %>%
  gather(utt, prob, -state, -phi_S1, -phi_informative, -phi_social, -phi_selfpres) %>% 
  mutate(phi_selfpres_bin = as.numeric(as.character(cut(phi_selfpres, 
                                                        breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1), 
                                                        labels = c(0.1, 0.3, 0.5, 0.7, 0.9)))),
         phi_informative_bin = as.numeric(as.character(cut(phi_informative, 
                                                           breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1), 
                                                           labels = c(0.1, 0.3, 0.5, 0.7, 0.9)))),
         phi_social_bin = as.numeric(as.character(cut(phi_social, 
                                                      breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1), 
                                                      labels = c(0.1, 0.3, 0.5, 0.7, 0.9))))) %>%
  mutate( 
    goal = as.factor(case_when(
      phi_informative_bin == 0.9 & phi_social_bin == 0.1 & phi_selfpres_bin == 0.1 ~ "be truly informative",  
      phi_informative_bin == 0.1 & phi_social_bin == 0.9 & phi_selfpres_bin == 0.1 ~ "be truly social",
      # (phi_informative_bin == 0.5 | phi_informative_bin == 0.3 | phi_informative_bin == 0.7) & (phi_social_bin == 0.5 | phi_social_bin == 0.7 | phi_social_bin == 0.3) & phi_selfpres_bin == 0.1 ~ "be truly both",
      phi_informative_bin == 0.5 & phi_social_bin == 0.5 & phi_selfpres_bin == 0.1 & phi_S1 == 0.1  ~ "be truly both", 
      phi_informative_bin == 0.1 & phi_social_bin == 0.1 & (phi_selfpres_bin == 0.9 | phi_selfpres_bin == 0.7) & phi_S1 == 0.9  ~ "look informative", 
      phi_informative_bin == 0.1 & phi_social_bin == 0.1 & phi_selfpres_bin == 0.9 & phi_S1 == 0.1 ~ "look social", 
      phi_informative_bin == 0.1 & phi_social_bin == 0.1 & phi_selfpres_bin == 0.9 & (phi_S1 == 0.3) ~ "look both",
      TRUE ~ "NA"))) %>%
  mutate(goal = factor(goal, levels = c("be truly informative", "be truly social", "be truly both", "look informative","look social", "look both","NA")))

rs.s2.tidy2 <- rs.s2.tidy %>%
                   mutate(utt2 = utt) %>%
                   mutate(utt = fct_recode(utt, "not amazing" = "not_amazing", 
                                            "not terrible" = "not_terrible", 
                                            "not good" = "not_good", 
                                            "not bad" = "not_bad", 
                                            "amazing" = "yes_amazing", 
                                            "good" = "yes_good", 
                                            "bad" = "yes_bad", 
                                            "terrible" = "yes_terrible"),
                          utt = fct_relevel(utt, "terrible", "bad", "good", "amazing", "not terrible", "not bad", "not good", "not amazing")) %>%
                            
                   separate(utt2, c("positive", "word")) %>%
                   mutate(word = fct_relevel(word, "terrible", "bad", "good", "amazing")) %>%
                   mutate(positive = fct_relevel(positive, "yes")) %>%
                   mutate(positive = fct_recode(positive, "it was ~" = "yes", "it wasn't ~" = "not")) %>%
                   mutate(goal = case_when(phi_informative_bin == 0.9 ~ "informational", 
                                           phi_social_bin == 0.9 ~ "social",
                                           phi_selfpres_bin == 0.9 & phi_S1 == 0.05 ~ "presentational \n(social S1)",
                                           phi_selfpres_bin == 0.9 & phi_S1 == 0.25 ~ "presentational \n(both-goal S1)",
                                           phi_selfpres_bin == 0.9 & phi_S1 == 0.95 ~ "presentational \n(informative S1)")) %>%
                   mutate(goal = fct_relevel(goal, "informational", "social", "presentational \n(informative S1)", "presentational \n(social S1)", "presentational \n(both-goal S1)")) %>%
                   filter(!is.na(goal))
                   # filter(phi_informative_bin == 0.9)

fig.s2 <- ggplot(rs.s2.tidy2, 
                 aes ( x = state, y = utt, fill = prob))+
  geom_tile(colour = "grey95") + 
  scale_fill_gradient(low = "white", high = "orange")+
  facet_grid(positive ~ goal, switch="y", scales = "free_y")+
  guides(fill = F)+
  ylab("utterance") +
  xlab("true state") +
    theme_few(base_size = 14) +
  theme(
    # axis.text.x = element_text(angle = 45, hjust=1),
        # strip.text.x = element_text(angle = 180),
        strip.text.y = element_blank()
        )  
```


```{r comparison, fig.width=11, fig.height=4,  out.width = "\\textwidth", fig.pos = "!h", fig.cap="Comparison of predictions for proportion of utterances chosen by pragmatic speaker from possible model variants (left) and human data (rightmost) for average proportion of negation produced among all utterances, given true state of 0 heart (on a scale of 0 to 3) and speaker with both goals to be informative and kind. Gray dotted line indicates chance level at 12.5\\%."}
plot.comp <- ms_utt %>%  
  mutate(model = case_when(
    model == "NA" ~ "human data", 
    model == "inf" ~ "model: \ninformational \nonly", 
    model == "soc" ~ "model: \nsocial only", 
    model == "pres" ~ "model: \npresentational \nonly", 
    model == "inf_pres" ~ "model: \ninformational, \npresentational", 
    model == "inf_soc" ~ "model: \ninformational, \nsocial", 
    model == "soc_pres" ~ "model: \nsocial, \npresentational", 
    model == "full" ~ "model: \ninformational, \nsocial, \npresentational" 
  ),
  model = fct_relevel(model, "model: \ninformational \nonly", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformational, \nsocial", "model: \ninformational, \npresentational", "model: \ninformational, \nsocial, \npresentational")) %>%
  mutate(positivity = fct_recode(positivity,
                                 "it was ~" = "yes",
                                 "it wasn't ~" = "not",
                                 "it was ~" = "It was~",
                                 "it wasn't ~" = "It wasn't~"
                                 ),
         positivity = fct_relevel(positivity, "it was ~")) %>%
  filter(goal == "both", true_state == "0") %>%
  ggplot(., 
       aes(x=utterance, y=prob, fill=positivity, 
           # group = interaction(positive, source), linetype = forcats::fct_rev(positive),
           group = positivity,
           colour = positivity)) +
  geom_hline(yintercept=.125, lty=2, color="gray") +
  geom_line()+
  facet_grid(.~model) +
  xlab("utterance") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position="dodge") +
  ylim(0,.7)+
  scale_color_ptol(guide=FALSE) +
  # scale_color_solarized(guide=FALSE)+
  ggthemes::theme_few(base_size = 13)+
  ylab("proportion chosen") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        legend.position="bottom") +
  guides(color=guide_legend(title=NULL))

 plot.comp

ggsave("model_comparisons.png", plot = plot.comp, width = 11, height = 4,
       path = here::here("02_analysis/03_figs"))

```

```{r schematicPredictionsFig, fig.align="center", fig.pos = "!h", out.width = '80%', fig.cap="Model overview with schematic predictions. More saturated color indicates high probability (listener models) or high utility (speaker models). Top left: The literal listener $L_0$ posterior probability distribution over the true state (x-axis) given utterances (y-axis). Top right: Speaker $S_1$’s utility of utterances (y-axis) for different states (x-axis) given either the informational or social goal (facets); shown in color (orange indicates high utility and white indicates low utility). Informational utility tracks the literal meanings and varies by true state; social utility favors utterances than favor higher valued states.  Middle: Politeness-aware pragmatic listener $L_1$’s joint posterior distribution over the true state (x-axis) and $S_1$ utility weighting (y-axis; higher value indicates greater weight on informational utility) given utterances (facets). Bottom: $S_2$’s utility of utterances (y-axis) for different states (x-axis) and different goals (facets). Informational utility tracks the literal meanings and varies by true state; social utility favors utterances that signal high-valued states; three versions of self-presentational utility are shown, corresponding to whether the speaker wants to project informativeness, kindness, and a balance. Only the balanced self-presentational speaker shows a preference for indirect speech. The bottom right-most facet shows $S_2$’s utterance preferences when they want to balance between the three utilities (informational, social, and presentational to project informativeness and kindness)."}
knitr::include_graphics("fig/schematic.png", dpi = 100)
knitr::knit_hooks$set(plot = function(x, options)  {
  paste0(knitr::hook_plot_tex(x, options), "\n\\FloatBarrier\n")
})
```


The behavior of the model can be understood through increasing levels of recursive reasoning. To ground the recursion, we have the literal listener model\(L_0\): a simple Bayesian agent who updates their prior beliefs over world states P(s) (assumed to be uniform) with the truth-functional denotation of the utterance $w$: $P_{L_0}(s | w) \propto [\![ w ]\!] (s) * P(s)$ (i.e. the utterance’s literal meaning). We assume soft-semantic meanings, which we elicit empirically in a separate experiment (N = 51, see Supplementary Materials). For example, the utterance “good” is compatible with both the 2- and 3-heart states, “not terrible” is also compatible with states 2- and 3-, though also to some extent with the 1-heart state (Figure \ref{fig:schematicPredictionsFig}, top left). 

The first-order speaker $S_1$ chooses utterances given a utility function with two components defined in terms of the literal listener: informational and social utility. *Informational utility* (\(U_{inf}\)) is the amount of information about the world state conveyed to the literal listener $L_0$ by the utterance w; for example, the highest information utterance associated with the 2-heart state is “good”; the best way to describe the 0-heart state is “terrible” (Figure 2, top right; left facet). *Social utility* (\(U_{soc}\)) is the expected subjective utility of the world state inferred by the literal listener $L_0$ given the utterance w and does not depend on the true state.^[The independence between true state and social utility stems from the assumption of no shared beliefs between speaker and listener about the true state. This independence is a deliberate feature of our experimental setup, designed to best disambiguate the models proposed. In future work, it would be important to examine how shared beliefs about the true state and the speaker’s goals may influence the speaker’s utterance choice.] For instance, the highest social utility utterance is “amazing”, because it strongly implies that the listener is in the 3-heart state; negated negative utterances like “not bad” also have some degree of social utility, because they imply high heart states, albeit less directly (Figure \ref{fig:schematicPredictionsFig}, top right; right facet).. The speaker combines these utilities assuming some weighting $phi$ and subtracts the cost of the utterance (defined in terms of the length of the utterance) in order to arrive at an overall utility of an utterance for a state and a goal-weighting:
$U(w; s; \phi) = \phi \cdot \ln(P_{L_0}(s \mid w)) + (1 - \phi) \cdot \mathbb{E}_{P_{L_0}(s \mid w)}[V(s)] - C(w).$
The speaker then chooses utterances $w$ softmax rationally given the state s and his goal weight mixture \(\phi\).

The pragmatic listener model $L_1$ reasons jointly about both the true state of the world and the speaker’s goals (Fig. \ref{fig:schematicPredictionsFig}, middle). Upon hearing [Your poem was] “amazing”, the listener faces a tough credit-assignment problem: The poem could indeed be worthy of three hearts, but it is also possible that the speaker had strong social goals and then no inference about the quality of the poem is warranted. Hearing [Your poem] was “terrible”, the inference is much easier: the poem is probably truly terrible (i.e., worthy of zero hearts) and the speaker probably does not have social goals. Negation makes the interpreted meanings less precise and hence, inferences about goals are also fuzzier: “not amazing” can be seen as a way of saying that the poem was worthy of 0 or 1 hearts, which satisfies some amount of both social and informational goals. “Not bad” is less clear: the speaker could be being nice and the poem was actually worthy of 0- or 1-hearts (i.e., it was bad) or the speaker could be being honest (i.e., it was not bad) and the poem was worth 2-hearts. 

The second-order pragmatic speaker model ($S_2$) reasons about the pragmatic listener $L_1$ to decide which utterances to produce based on both the true state of the world and the speaker's goals (Figure \ref{fig:schematicPredictionsFig}, bottom). 
The informational and social utilities of the second-order speaker mirror those of the first-order speaker: Direct utterances are more informative than those involving negation and utterances that signal many hearts are more prosocial.^[The second-order speaker informational utilities take into account the listener’s pragmatic inferences about the speaker’s goals. This only really affects the utility of “not terrible”, which has higher information for the 1-heart state because the pragmatic listener strongly infers that the utterance was produced for social reasons. That is, for the second-order speaker, the utterance “not terrible” is loaded in a way that other utterances are not.]
The interesting novel behavior of this level of recursion comes from the different flavors of the self-presentational goal (Figure \ref{fig:schematicPredictionsFig}, bottom). 
When the second-order pragmatic speaker wants to *project* kindness (i.e., appear prosocial) they even more strongly display the preference for utterances that signal positive states (i.e., they are over-the-top positive).
When the speaker wants to project honesty and informativeness, they take the exact opposite strategy, producing utterances that cannot be explained by virtue of social utility: direct, negative utterances (e.g., “it was terrible”).
Finally, the speaker may present themselves in more subtle ways (e.g., intending to convey they are both kind and honest): This goal uniquely leads to the indirect, negative utterances (e.g., “not terrible”, “not bad”) having high utility. These utterances are literally incompatible with low-heart states, but are not highly informative; this unique combination is what gives rise to the subtle inference of a speaker who cares about both goals. 

# Experiment: Speaker production task

We made a direct test of our speaker production model and its performance in comparison to a range of alternative models, by instantiating our running example in an online experiment. We developed the preceding model iteratively on the basis of a sequence of similar experiments, but importantly, the current test was fully pre-registered and confirmatory. All data analytic models and our full model comparison approach were registered ahead of time to remove any opportunities for overfitting the behavioral data through changes to the model or the evaluation.

```{r screenshot,  out.width = "70%", fig.align="center", fig.pos = "!h", fig.cap="Example of a trial in the speaker production task."}
knitr::include_graphics("fig/screenshot.png", dpi = 130)
```

## Participants

202 participants with IP addresses in the United States were recruited on Amazon’s Mechanical Turk.

## Design and Methods

Participants read scenarios with information on the speaker's feelings toward some performance or product (e.g., a poem recital; *true state*), on a scale from zero to three hearts (e.g.,
one out of three hearts). For example, one trial read: *Imagine that Bob gave a poem recital, but he didn't know how good it was. Bob approached Ann, who knows a lot about poems, and asked* “How was my poem?” 
Additionally, we manipulated the speaker's goals across trials: to be *informative* (“give accurate and informative feedback”); to be *kind* (“make the listener feel good”); or to be *both* informative and kind simultaneously. Notably, we did not mention a self-presentational goal to participants; rather, we hypothesize this goal can arise spontaneously from a speaker’s inability to achieve the first-order goals of niceness and honesty (i.e., if a speaker wants to, but can’t, be both honest and nice, they would instead try to signal that they care about both goals). We hypothesized that
each of the three experimentally-induced goals (*informative*, *kind*, *both*) would induce a different tradeoff between the informational, prosocial, and self-presentational utilities in our model . In a single trial, each scenario was followed by a question asking for the most
likely produced utterance by Ann. Participants selected one of eight possible utterances, by choosing between *It was* vs. *It wasn’t* and then among *terrible*, *bad*, *good*, and *amazing.* 

Each participant read twelve scenarios, depicting every possible combination of the three goals and four states. 
The order of context items was randomized, and there were a maximum of two repeats of each context item per participant.
Each scenario was followed by a question that read, "If Ann wanted to make Bob feel good but not necessarily give informative feedback (or to give accurate and informative feedback but not necessarily make Bob feel good, or BOTH make Bob feel good AND give accurate and informative feedback), what would Ann be most likely to say?" 
Participants indicated their answer by choosing one of the options on the two dropdown menus, side-by-side, one for choosing between *It was* vs. *It wasn’t* and the other for choosing among *terrible*, *bad*, *good*, and *amazing.*

## Behavioral results

```{r data_bayes_factor}
load(file=here("03_model/03_other_stat/bayesfactor_state_goal_interaction.Rds"))
load(file=here("03_model/03_other_stat/bayesfactor_state_goal_main_effects.Rds"))
load(file=here("03_model/03_other_stat/bayesfactor_state_only.Rds"))

BF_full_vs_main <- model1bf1/model2bf1
BF_full_vs_one <- model1bf1/model3bf1
BF_main_vs_one <- model2bf1/model3bf1
```

```{r variance, echo=FALSE, out.width = "\\textwidth", fig.pos = "!h", fig.cap="Full distribution of human responses vs. model predictions. Error bars represent 95\\% confidence intervals for the data (vertical) and 95\\% highest density intervals for the model (horizontal)."}
ms_var <- ms_utt %>%
  filter(source == "data" | model == "full") %>%
  select(-model) %>%
  gather(var, value, ci_lower:prob, -source, -true_state) %>%
  unite(new, c(source, var)) %>%
  mutate(positivity = fct_recode(positivity, 
                               "It was ~" = "yes",
                               "It wasn't ~" = "not",
                               "It was ~" = "It was~",
                               "It wasn't ~" = "It wasn't~"
                               ),
         positivity = fct_relevel(positivity, "It was ~"),
         goal = fct_recode(goal, "kind" = "social")) %>%
  spread(new, value)

plot_var <- ggplot(ms_var,
       aes(x = model_prob, y = data_prob)) +
  aes(shape = factor(positivity)) +
  geom_point(aes(colour = factor(goal), fill = factor(goal)), size = 2) +
  scale_shape(solid = FALSE) +
  scale_shape_manual(name = "utterance type", values = c(21, 24))+
  theme_few()+
  geom_abline(intercept = 0, slope = 1, linetype = 3) +
  geom_errorbar(aes(ymin=data_ci_lower,ymax=data_ci_upper), alpha = 0.3) +
  geom_errorbarh(aes(xmin=model_ci_lower,xmax=model_ci_upper), alpha = 0.3) +
  xlab("model posterior predictive") +
  ylab("human proportion responses") +
  ylim(0,1) +
  xlim(0,1) +
  scale_y_continuous(breaks=c(0, 0.25, 0.5, 0.75, 1)) +
  scale_x_continuous(breaks=c(0, .25, 0.5, 0.75, 1)) +
  theme(axis.text.y = element_text(hjust = 0, angle = 0),
        axis.text.x = element_text(vjust = 0, angle = 0),
        legend.position = "bottom",
        legend.direction = "horizontal") +
  coord_fixed()+
  scale_colour_solarized(name = "goal") +
  scale_fill_solarized() +
  guides(fill=FALSE)

plot_var

ggsave("speaker_production_cor.png", plot = plot_var, width = 7, height = 4,
       path = here::here("02_analysis/03_figs"))

cor2_mainMod = with(ms_var, cor(data_prob, model_prob))^2

```

```{r brmstat}
load(here("03_model/03_other_stat/brms_polite.Rds"))

brm.tab <- as.data.frame(summary(brms_pol)$fixed) %>%
  select(Estimate, Est.Error, 'l-95% CI', 'u-95% CI') %>%
  rename(Mean = Estimate,
         "SD" = Est.Error,
         "95% CI-Lower" = 'l-95% CI',
         "95% CI-Upper" = 'u-95% CI'
         )

brm.tab$Predictor <- c("Intercept",
                      "True state",
                      "Goal: Informative",
                      "Goal: Kind",
                      "True state * Informative",
                      "True state * Kind"
                      )
rownames(brm.tab) <- NULL
brm.tab <- brm.tab[,c(5,1:4)]
```

Our primary behavioral hypothesis was that speakers describing bad states (e.g., poem deserving 0 hearts) with goals to be both informative and kind would produce more indirect, negative utterances (e.g., *It wasn't terrible*). Such indirect speech acts both save the listener's face and provide some information about the true state, and thus, are what a socially-conscious speaker would say (Figure \@ref(fig:schematicPredictionsFig), bottom).
This prediction was confirmed, as a Bayesian mixed-effects model predicts more negation as a function of true state and goal via an interaction: A speaker with both goals to be informative and kind produced more negation in worse states compared to a speaker with
only the goal to be informative (*M* = `r brm.tab$Mean[5]`, [`r brm.tab$"95% CI-Lower"[5]`, `r brm.tab$"95% CI-Upper"[5]`]) and goal to be kind (*M* = `r brm.tab$Mean[6]`, [`r brm.tab$"95% CI-Lower"[6]`, `r brm.tab$"95% CI-Upper"[6]`]). Rather than eschewing one of their goals to increase utility along a single dimension, participants chose utterances that jointly satisfied their
conflicting goals by producing indirect speech.

## Model results

```{r phi, results = 'asis'}
load(here("03_model/01_posterior_predictives/03_output_processed/phi_summary.RData"))
load(here("03_model/01_posterior_predictives/03_output_processed/other_param_summary.RData"))

phi_tab <- d_phi_s %>%
  mutate_at(vars(informative:social), as.numeric) %>%
  mutate_if(is.numeric, function(x) round(x, digits=2)) %>%
  mutate_at(vars(informative:social), 
            funs(dplyr::case_when(is.na(.) ~ "--",
                                  TRUE ~ as.character(.)))) %>%
  # mutate_if(is.numeric, function(x) ifelse(is.na(x), "--", x)) %>%
  ungroup() %>%
    mutate(model = case_when(
    model == "inf" ~ "informational only", 
    model == "soc" ~ "social only", 
    model == "pres" ~ "presentational only", 
    model == "InfPres" ~ "informational, presentational", 
    model == "InfSoc" ~ "informational, social", 
    model == "SocPres" ~ "social, presentational", 
    model == "Full" ~ "informational, social, presentational" 
  )) %>%
  select(model, goal, informative, social, Selfpres, s1)

colnames(phi_tab) <- c("model (utilities)", "goal", "$\\omega_{inf}$", "$\\omega_{soc}$", "$\\omega_{pres}$", "$\\phi$")

apa_table(phi_tab, escape=FALSE, caption = "Inferred goal weight ($\\omega_g$) and speaker-projected informativity-niceness weight ($\\phi$) parameters from all model variants with more than one utility.")
```

```{r bayesnet,  fig.pos = "!h", out.width="70%", fig.align="center", fig.cap="Graphical model representing our Bayesian data analytic approach for the full 3-component model (other models contain subsets of the parameters shown). $S_2$ represents the RSA speaker model defined by Eq. 1, which is used to predict the production responses $d^{prod}$ of each participant $i$, for each state $s$ (number of hearts), for each utterance $w$, in each goal condition $g$. The RSA speaker model takes as input the literal meaning variables $\\theta$, which additionally are used to predict the literal meaning judgments $d^{lit}$ assuming a Bernoulli linking function. Additionally, the RSA model takes the speaker’s goal weights $\\omega$ and intended presentational goal weight $\\phi$, which are inferred separately for each goal condition $g$. Finally, the RSA model uses two global free parameters: the cost of negation $c$ and the speaker’s rationality parameter $\\alpha$."}
knitr::include_graphics("fig/bayesnet.png", dpi = 160)
```

```{r comparisonVar}
ms_var_comp <- ms_utt %>%
  select(-ci_lower, -ci_upper) %>%
  mutate(model = case_when(
    model == "NA" ~ "data", 
    TRUE ~ as.character(model)
  )) %>%
  mutate(positivity = fct_recode(positivity, 
                               "It was ~" = "yes",
                               "It wasn't ~" = "not",
                               "It was ~" = "It was~",
                               "It wasn't ~" = "It wasn't~"
                               ),
         positivity = fct_relevel(positivity, "It was ~")) %>%
  select(-source) %>%
  spread(model, prob)

cor2_inf = with(ms_var_comp, cor(data, inf))^2
cor2_soc = with(ms_var_comp, cor(data, soc))^2
cor2_pres = with(ms_var_comp, cor(data, pres))^2
cor2_socpres = with(ms_var_comp, cor(data, soc_pres))^2
cor2_infsoc = with(ms_var_comp, cor(data, inf_soc))^2
cor2_infpres = with(ms_var_comp, cor(data, inf_pres))^2
cor2_infsocpres = with(ms_var_comp, cor(data, full))^2

```

```{r comparisonML}
ml_infsocpres <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_self5_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_infpres <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_self6_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_infsoc <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_actual2_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_socpres <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_self7_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_inf <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_trueInf_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_soc <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_trueSoc_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_pres <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_selfPres_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]

bf_full_vs_infpres <- mean(ml_infpres) - mean(ml_infsocpres)
bf_full_vs_infsoc <- mean(ml_infsoc) - mean(ml_infsocpres)
bf_full_vs_socpres <- mean(ml_socpres) - mean(ml_infsocpres)
bf_full_vs_inf <- mean(ml_inf) - mean(ml_infsocpres)
bf_full_vs_soc <- mean(ml_soc) - mean(ml_infsocpres)
bf_full_vs_pres <- mean(ml_pres) - mean(ml_infsocpres)

bf_list <- list(bf_full_vs_inf, bf_full_vs_soc, bf_full_vs_pres,  bf_full_vs_socpres, bf_full_vs_infsoc, bf_full_vs_infpres)
bf_list_rounded <- rapply(bf_list, function(x) round(x, digits=2))
bf_list_rounded_rev <- rev(append(bf_list_rounded, "--"))
```

```{r comparisonTable, results = 'asis'}
model_list = rev(c("informational \nonly", "social only", "presentational \nonly", "social, \npresentational", "informational, \nsocial", "informational, \npresentational", "informational, \nsocial, \npresentational"))
variance_list = rev(c(cor2_inf, cor2_soc, cor2_pres, cor2_socpres, 
                           cor2_infsoc, cor2_infpres, cor2_infsocpres))

comp_tab <- data.frame("model" = model_list, 
                       "variance" = variance_list, 
                       "logBF" = bf_list_rounded_rev) %>%
  rename("variance \nexplained" = "variance",
         "log BF" = "logBF")

apa_table(comp_tab, caption = "Comparison of variance explained for each model variant and log Bayes Factors quantifying evidence in favor of alternative model in comparison.")
```


We assume our experimental goal conditions (informative vs. kind vs. both) induce a set of weights over the utilities \(\boldsymbol{\omega}\) in participants’ utterance production model. In addition, the self-presentational utility is defined via a communicated social weight $\phi$ (i.e., the mixture of informative vs. social that the speaker is trying to project). The mapping from social situations into utility weights and communicated social weight is a complex mapping, which we do not attempt to model here; instead, we infer these parameters for each goal condition from the data. We additionally infer the literal meanings (i.e., the semantics) of the words as interpreted by the literal listener \(L_0\) with the additional constraint of the literal meaning judgments from an independent group of participants (See Supplementary Materials: Literal semantic task section). 
Finally, the RSA model has two global free parameters: the softmax speaker optimality and utterance cost of negation from the data (Figure \@ref(fig:bayesnet)). 
We implement this data analytic model for each of the alternative models and infer the parameters using Bayesian statistical inference [@lee2014].
We use uninformative priors over ranges consistent with the prior literature on RSA models: $\theta_{s,w}^{lit} \sim \text{Uniform}(0, 1)$, $\phi_g \sim \text{Uniform}(0, 1)$, $\boldsymbol{\omega}_g \sim \text{Dirichlet}(1,1,1)$, $\alpha \sim \text{Uniform}(0, 20)$, $c \sim \text{Uniform}(1, 10)$.
This analysis tells us which, if any, of these models can accomodate all of the patterns in the empirical data. 
The posterior predictions from the three-utility polite speaker model (informational, social, presentational) showed a very strong fit to participants' actual utterance choices ($r^2$(96) = `r cor2_mainMod`; Figure \@ref(fig:variance)).
Other models (e.g., informational + presentational), however, show comparably high correlations to the full data set; correlations can be inflated through the presence of many 0s (or 1s) in the data set, which our data contains since certain utterance choices are implausible given a particular state and goal condition.
<!-- each model is tasked with predicting the entire distribution of responses for each condition, there are many 0s in the data set which can inflate the correlations.  -->
<!-- owing to the fact that. Correlations can be inflated  -->
Thus, we compare model variants using a bonafide model comparison technique, Bayes Factors, which balance predictive accuracy with model complexity in quantifying the goodness of fit of a model.

Bayes Factors compare the likelihood of the data under each model, averaging over the prior distribution of the model parameters; by averaging over the prior distribution over parameters, Bayes Factors penalize models with extra flexibility because increasing the flexibility of the model to fit more data sets decreases the average fit of the model to a particular data set [@lee2014], capturing the intuition that a theory that can predict anything predicts nothing. 
That is, simply because a model has more parameters and can explain more of the variance in the data set does not entail that it will assign the highest marginal likelihood to the actual data.
Here, however, both the variance explained and marginal likelihood of the observed data were the highest for the full model: The full model was at least 5 x 10^4 times better at explaining the data than the next best model (Table \@ref(tab:comparisonTable)). 
Only the full model captured participants' preference for negation when the speaker wanted to be informative and kind about truly bad states, as hypothesized (Figure \@ref(fig:comparison)).
In sum, the full set of informational, social, and presentational utilities were required to fully explain participants' utterance choices.

The utility weights inferred for the three-utility model (Table \@ref(tab:phi)) provide additional insight into how polite language use operates in our experimental context and possibly beyond:
*Being kind* ("social") requires not only weights on social and presentational utilities but equal weights on all three utilities, indicating that informativity is a part of language use
even when it is explicitly not the goal.
*Being informative* ("informative") pushes the weight on social utility ($\omega_{soc}$) close to zero, but the weight on *projecting kindness* ($\omega_{pres}$) stays high, suggesting that speakers are expected to manage their own face even when they are not considering others'.
*Kind and informative* ("both") speakers emphasize informativity slightly
more than kindness. 
In all cases, however, the presentational utilities have greatest weight, suggesting that managing the listener's inferences about oneself was integral to participants' decisions in the context of our communicative task.
Overall then, our condition manipulation altered the balance between these weights, 
but all utilities played a role in all conditions.

# Discussion

Politeness is puzzling from an information-theoretic perspective.
Incorporating social motivations into theories of language use adds a level of explanation, but so far such intuitions and observations have resisted both formalization and precise testing.
We presented a set of utility-theoretic models of language use that captured different proposals about the interplay between competing informational, social, and presentational goals. Our full model instantiated a novel theoretical proposal, namely that indirect speech is a response to the conflict between informational and social utilities that preserves speakers’ self-presentation.  Our confirmatory test of the comparison between these models then provided experimental evidence that the full model best fit participants’ judgments, even accounting for differences in model complexity.

The most substantial innovation in our full model is the formalization of a self-presentational utility, defined only for a speaker who reasons about a listener who reasons about a speaker. We hypothesized that a speaker who prioritizes presentational utility will tend to produce more indirect speech (negation in our experimental paradigm). Indeed, this is consistent with previous work showing that people prefer to use negation (“that’s not true” as opposed to “that’s false”) when prompted to speak more “politely” [@giora2005] and that utterances involving negation tend to be interpreted in a more mitigated and hedged manner compared to direct utterances [@colston1999]. It also may help explain the phenomenon of negative strengthening, where negation of a positive adjective can be interpreted in a rather negative manner [e.g., “He’s not brilliant” meaning “he is rather unintelligent”; @gotzner2018]. Our work builds on this previous work that shows a preference for negation by elucidating the goal-directed underpinnings of this behavior and possible contextual modulation of this preference. An interesting open question is whether other negation-related politeness phenomena [e.g., indirect questions such as “You couldn’t possibly tell me the time, could you?”; @brown1987] can be derived from the basic information-theoretic goals we formalize.

In order to conduct quantitative model comparisons, we needed to create an experiment with repeated trials and a restricted range of choices. Thus, we had to abstract away from the richness of natural interactions. These choices decrease the validity of our experiment. Despite these abstractions, we showed that behavior in the experiment reflected social and informational pressures described in previous theories of polite language, providing some face validity to the responses we collected. With a formal model in hand, it now will be possible to consider relaxing some of the experimental simplifications we put into place in future work.
Most importantly, human speakers have access to a potentially infinite set of utterances to select from in order to manage the politeness-related tradeoffs (e.g., *It's hard to write a good poem*, *That metaphor in the second stanza was so relatable!*). 
Each utterance will have strengths and weaknesses relative to the speaker's goals.  Computation in an unbounded model presents technical challenges [perhaps paralleling the difficulty human speakers feel in finding the right thing to say in a difficult situation; see @goodman2016], and addressing these challenges is an important future direction.

For a socially-conscious speaker, managing listeners' inferences is a fundamental task. Our work extends previous models of language beyond standard informational utilities to address social and self-presentational concerns. Further, our model builds upon the theory of politeness as face management [@brown1987] and takes a step towards understanding the complex set of social concerns involved in face management. This latter point illustrates a general feature of why explicit computational models provide value: only by formalizing the factors in @brown1987’s theory were we able to recognize that they were an insufficient description of the data we were collecting in previous versions of the current experiment. Those failures allowed us to explore models with a broader range of utilities, such as the one reported here.

Previous game-theoretic analyses of politeness have either required some social cost to an utterance [e.g., by reducing one's social status or incurring social debt to one's conversational partner; @vanRooy2003] or a separately-motivated notion of plausible deniability [@pinker2008].
The kind of utterance cost for the first type of account would necessarily involve higher-order reasoning about other agents, and may be able to be defined in terms of the more basic social and self-presentational goals we formalize here.
A separate notion of plausible deniability may not be needed to explain most politeness behavior, either.
Maintaining plausible deniability is in one's own self-interest (e.g., due to controversial viewpoints or covert deception) and goes against the interests of the addressee; some amount of utility dis-alignment is presumed by these accounts. Politeness behavior appears present even in the absence of obvious conflict, however: In fact, you might be even more motivated to be polite to someone whose utilities are more aligned with yours (e.g., a friend). In our work here, we show that such behaviors can in fact arise from purely cooperative goals [@brown1987], though in cases of genuine conflict, plausible deniability likely plays a more central role in communication.

Utility weights and value functions in our model could provide a framework for a quantitative understanding of systematic
cross-cultural differences in what counts as polite.
Cultures may place value on satisfying different communicative goals, and speakers in these cultures may pursue those goals more strongly than speakers from other cultures. For example, we found in our model that a speaker who wants to appear informative should speak more negatively than a truly informative speaker; one could imagine run-away effects where a group becomes overly critical from individuals’ desires to appear informative. Culture could also affect
the value function \(V\) that maps states of the world onto subjective
values for the listener.
For example, the mapping from states to utilities may
be nonlinear and involve reasoning about the future; a social utility that takes into account reasoning about the future could help explain why it can often be nice to be informative.
Our formal modeling approach, with systematic behavior measurements, provides an avenue towards understanding the vast range of politeness practices found across languages and contexts [@katz2005].

Politeness is only one of the ways language use deviates from purely informational transmission.
We flirt, insult, boast, and empathize by balancing informative transmissions with goals to affect others' feelings or present particular views of ourselves.
Our work shows how social and self-presentational motives can be integrated with informational concerns more generally, opening up the possibility for a broader theory of social
language.
A formal account of politeness may also move us closer to courteous computation -- to machines that can talk with tact.

\newpage


# Supplementary Materials

## Model details

The *literal listener* $L_0$ is a simple Bayesian agent that takes the utterance to be true:

$$P_{L_0}(s | w) \propto  \delta_{[\![ w ]\!] (s)} \cdot P(s).$$

\noindent where $\delta_{[\![ w ]\!] (s)}$ is the Kronecker delta function which uses to the truth-functional denotation of the utterance $[\![ w ]\!](s)$ to return a value of 1 if the utterance $w$ is true of the state $s$ and 0 otherwise. 
The literal meaning is used to update the literal listener's prior beliefs
over world states $P(s)$.

The *speaker* $S_1$ chooses utterances approximately optimally given a utility function, which can be decomposed into two components. 
First, informational utility ($U_{inf}$) is the amount of information a literal listener $L_0$ would still not know about world state $s$ after hearing a speaker's utterance $w$. 
Second, social utility ($U_{soc}$) is the expected subjective utility of the state inferred given the utterance $w$. 
The utility of an utterance subtracts the cost $c(w)$ from the weighted combination of the social and epistemic utilities. 

$$U(w; s; \phi) = \phi \cdot \ln(P_{L_0}(s \mid w)) + (1 - \phi) \cdot \mathbb{E}_{P_{L_0}(s \mid w)}[V(s)] - C(w).$$

\noindent The speaker then chooses utterances $w$ softmax-optimally given the state $s$ and his goal weight mixture $\phi$: 

$$P_{S_1}(w \mid s, \phi) \propto \mathrm{exp}(\alpha \cdot \mathbb{E}[U(w; s; \phi)]).$$

## Literal semantic task

We probed judgments of literal meanings of the target words assumed by our model and used in our main experiment. 

### Participants 

51 participants with IP addresses in the United States were recruited on Amazon’s Mechanical Turk. 

### Design and Methods

We used thirteen different context items in which a speaker evaluated a performance of some kind. 
For example, in one of the contexts, Ann saw a presentation, and Ann’s feelings toward the presentation (true state) were shown on a scale from zero to three hearts (e.g., two out of three hearts filled in red color; see Figure\ \@ref(fig:screenshot) for an example of the heart scale). 
The question of interest was "Do you think Ann thought the presentation was / wasn’t X?" and participants responded by choosing either “no” or “yes.” 
The target could be one of four possible words: *terrible*, *bad*, *good*, and *amazing*, giving rise to eight different possible utterances (with negation or no negation). 
Each participant read 32 scenarios, depicting every possible combination of states and utterances. 
The order of context items was randomized, and there were a maximum of four repeats of each context item per participant. 

### Behavioral results

We analyzed the data by collapsing across context items.
For each utterance-state pair, we computed the posterior distribution over the semantic weight (i.e., how consistent X utterance is with Y state) assuming a uniform prior over the weight (i.e., a standard Beta-Binomial model). 
Meanings of the words as judged by participants were as one would expect (Figure \ \@ref(fig:litsem)). 

```{r litsem, echo=FALSE, fig.width = 10, fig.height = 4, out.width = "\\textwidth", fig.pos = "!h", fig.cap = "Semantic measurement results. Proportion of acceptances of utterance types (shown in different colors) combined with target words (shown in different facets) given the true state represented on a scale of hearts. Error bars represent 95\\% confidence intervals."}
d <- read.csv(here("02_analysis/01_data/literal_semantics.csv")) %>%
  mutate(utterance = fct_relevel(utterance, "terrible", "bad", "good", "amazing"))

ms <- d %>%
  mutate(positivity = fct_recode(positivity,
                                "it was ~ " = "it was ___",
                                "it wasn't ~ " = "it wasn't ___"
                                ),
         positivity = fct_relevel(positivity, "it was ~ ")) %>%
  group_by(positivity, state, utterance, subid) %>%
  summarize(
            judgment = mean(judgment, na.rm=TRUE)
          ) %>%
  group_by(positivity, state, utterance) %>%
  multi_boot_standard(col = "judgment") %>%
  mutate(judgment = mean)

qplot(state, judgment, 
      colour = positivity,
      data=ms) + 
  geom_line(aes(group=positivity)) +
  facet_grid(.~utterance) +
  xlab("state (0=worst)") +
  ylab("proportion of\n acceptances") +
  geom_errorbar(aes(ymin=ci_lower,ymax=ci_upper,width=.1)) +
  theme_few(base_size = 16) +
  scale_color_ptol(name="")+
  # scale_color_solarized() +
  theme(legend.position = "bottom") +
  geom_hline(yintercept = .5, lty=2)

ggsave("literal_semantics.png", width = 7, height = 3,
       path = here::here("02_analysis/03_figs"))
```



```{r}
## Data analysis

# We used `r cite_r("politeness.bib")` for all our analyses.
```



## Full statistics on human data

```{r brmTab, results="asis"}
apa_table(brm.tab, caption= "Predictor mean estimates with standard deviation and 95% credible interval information for a Bayesian linear mixed-effects model predicting negation production based on true state and speaker goal (with both-goal as the reference level).")
```

We used Bayesian linear mixed-effects models [`brms` package in R; @R-brms] using crossed random effects of true state and goal with maximal random effects structure [@gelman2006data; @barr2013random]. The full statistics are shown in Table \@ref(tab:brmTab).

## Model fitting and inferred parameters

```{r otherParams, results='asis'}
other_tab <- d_other_s %>%
    mutate(model = case_when(
    model == "inf" ~ "ninformational only", 
    model == "soc" ~ "social only", 
    model == "pres" ~ "presentational only", 
    model == "inf_pres" ~ "ninformational, presentational", 
    model == "inf_soc" ~ "ninformational, social", 
    model == "soc_pres" ~ "social, presentational", 
    model == "full" ~ "ninformational, social, presentational" 
  )) %>%
  mutate(param = round(param, digits=2)) %>%
  spread(parameter, param)

colnames(other_tab) <- c("Model", "Cost of negation", "Speaker optimality")

apa_table(other_tab, escape=FALSE, caption = "Inferred negation cost and speaker optimality parameters for all model variants.")
```

Other than speaker goal mixture weights explained in the main text (shown in Table \@ref(tab:phi)), the full model has one global parameter: the speakers' (both $S_1$ and $S_2$) soft-max parameter, which we assume to be the same value $\alpha$ and infer from the data.
We put a prior that was consistent with those used for similar models in this model class: $\alpha$ ~ $Uniform(0,20)$.
Finally, we incorporate the literal semantics data into the RSA model by maintaining uncertainty about the semantic weight of utterance $w$ for state $s$, for each of the states and utterances, and assuming a Beta-Binomial linking function between these weights and the literal semantics data (see *Literal semantics task* above).
We infer the posterior distribution over all of the model parameters and generate model predictions based on this posterior distribution using Bayesian data analysis [@lee2014]. 
We ran 4 MCMC chains for 80,000 iterations, discarding the first 40,000 for burnin. 
The inferred values of parameters are shown in Table \@ref(tab:otherParams).

## Data Availability

Our model, preregistration of hypotheses, procedure, data, and analyses are available at \url{https://github.com/ejyoon/polite_speaker}. 

## Supplemental Figures

```{r utterance, echo=FALSE, out.width = "\\textwidth", fig.pos = "!h", fig.height=6, fig.cap="Experimental results (solid lines) and fitted predictions from the full model (dashed lines) for speaker production. Proportion of utterances chosen (utterance type – direct vs. indirect – in different colors and words shown on x-axis) given the true states (columns) and speaker goals (rows). Error bars represent 95\\% confidence intervals for the data and 95\\% highest density intervals for the model. Black dotted line represents the chance level."}
plot.utt <- ggplot(data=ms_utt %>%
                     filter(source == "data" | model == "full") %>%
  mutate(positivity = fct_recode(positivity, 
                               "It was ~" = "yes",
                               "It wasn't ~" = "not",
                               "It was ~" = "It was~",
                               "It wasn't ~" = "It wasn't~"
                               ),
         positivity = fct_relevel(positivity, "It was ~")) %>%
                     mutate(
                       # positivity = fct_relevel(positivity, "not"),
                            true_state = fct_recode(true_state,
                                                    "0 heart" = "0", 
                                                    "1 heart" = "1", 
                                                    "2 hearts" = "2", 
                                                    "3 hearts" = "3" 
                                                    ),
                            goal = fct_recode(goal, "kind" = "social")), 
       aes(x=utterance, y=prob, group = interaction(positivity, source), colour = positivity, linetype = source)) +
  geom_line()+
  facet_grid(goal~true_state, labeller = labeller(goal = label_both)) +
  xlab("utterance") +
  ylab("proportion chosen") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position="dodge") +
  geom_hline(yintercept=.1, lty=2) +
  ylim(0,1)+
  scale_color_ptol()+
  # scale_color_solarized(labels = c("It wasn't~","It was~"))+
  ggthemes::theme_few()+
  theme(axis.text.x = element_text(angle = 45, vjust=0.5),
        legend.position = "bottom") +
  guides(colour=guide_legend(title="utterance type")) +
  scale_linetype_discrete(labels = c("data", "model"))

plot.utt

ggsave("speaker_production_utt_wMod.png", plot = plot.utt, width = 7, height = 5,
       path = here::here("02_analysis/03_figs"))
```

```{r comparisonAll, echo=FALSE, out.width = "\\textwidth", fig.pos = "!h", fig.width=11, fig.height=7, fig.cap="Comparison of predictions for proportion of utterances chosen by pragmatic speaker from possible model variants (left) and human data (rightmost) for average proportion of negation produced among all utterances, given true state of 0 heart and speaker with a goal to be informative (top), kind (middle), or both (bottom). Gray dotted line indicates chance level at 12.5\\%. Error bars represent 95\\% confidence intervals for the data (rightmost) and 95\\% highest density intervals for the models (left)."}
plot.comp.all <- ms_utt %>%  
  mutate(model = case_when(
    model == "NA" ~ "Human data", 
    model == "inf" ~ "model: \ninformational \nonly", 
    model == "soc" ~ "model: \nsocial only", 
    model == "pres" ~ "model: \npresentational \nonly", 
    model == "inf_pres" ~ "model: \ninformational, \npresentational", 
    model == "inf_soc" ~ "model: \ninformational, \nsocial", 
    model == "soc_pres" ~ "model: \nsocial, \npresentational", 
    model == "full" ~ "model: \ninformational, \nsocial, \npresentational" 
  ),
  model = fct_relevel(model, "model: \ninformational \nonly", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformational, \nsocial", "model: \ninformational, \npresentational", "model: \ninformational, \nsocial, \npresentational")) %>%
  mutate(positivity = fct_recode(positivity, 
                               "It was ~" = "yes",
                               "It wasn't ~" = "not",
                               "It was ~" = "It was~",
                               "It wasn't ~" = "It wasn't~"
                               ),
         positivity = fct_relevel(positivity, "It was ~")) %>%
  mutate(
    # positivity = fct_recode(positivity,
    #                              "It was ~" = "yes",
    #                              "It wasn't ~" = "not"),
         # positivity = fct_relevel(positivity, "It wasn't ~"),
         goal = fct_recode(goal, "kind" = "social") 
         ) %>%
  filter(true_state == "0") %>%
  ggplot(., 
       aes(x=utterance, y=prob, fill=positivity, 
           # group = interaction(positive, source), linetype = forcats::fct_rev(positive),
           group = positivity,
           colour = positivity)) +
  geom_hline(yintercept=.125, lty=2, color="gray") +
  geom_line()+
  facet_grid(goal~model, labeller = labeller(goal = label_both)) +
  xlab("utterance") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position="dodge") +
  ylim(0,.7)+
  scale_color_ptol(guide=FALSE)+
  # scale_color_solarized(guide=FALSE)+
  ggthemes::theme_few(base_size = 15)+
  ylab("proportion chosen") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        legend.position="bottom") +
  guides(color=guide_legend(title=NULL))

plot.comp.all

ggsave("model_comparisons_all.png", plot = plot.comp.all, width = 11, height = 4,
       path = here::here("02_analysis/03_figs"))

```

```{r negation, echo=FALSE, fig.width=11, fig.height=4, out.width = "\\textwidth", fig.pos = "!h", fig.cap="Experimental results (left) and fitted model predictions (right) for average proportion of negation produced among all utterances, given true states (x-axis) and goals (colors)."}
plot.neg <- ms_neg %>%  
  mutate(model = case_when(
    model == "NA" ~ "Human data", 
    model == "inf" ~ "model: \ninformational \nonly", 
    model == "soc" ~ "model: \nsocial only", 
    model == "pres" ~ "model: \npresentational \nonly", 
    model == "inf_pres" ~ "model: \ninformational, \npresentational", 
    model == "inf_soc" ~ "model: \ninformational, \nsocial", 
    model == "soc_pres" ~ "model: \nsocial, \npresentational", 
    model == "full" ~ "model: \ninformational, \nsocial, \npresentational" 
  ),
  model = fct_relevel(model, "model: \ninformational \nonly", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformational, \nsocial", "model: \ninformational, \npresentational", "model: \ninformational, \nsocial, \npresentational")) %>%
  ggplot(., 
       aes(x=true_state, y=prob, color = goal, group=goal)) +
  geom_line(stat="identity", position=position_dodge()) +
  xlab("true state") +
  ylab("proportion negation") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position=position_dodge(width=.05)) +
  theme_few(base_size = 15)+
  scale_color_solarized() +
  facet_grid(.~model) +
  theme(legend.position="bottom")

plot.neg

ggsave("speaker_production_neg_wMod.png", plot = plot.neg, width = 7, height = 3,
       path = here::here("02_analysis/03_figs"))
```

\newpage



# References
```{r create_r-references}
r_refs(file = "politeness.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

