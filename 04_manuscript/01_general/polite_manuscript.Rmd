---
title             : "Polite speech emerges from competing pressures to be (and look) informative and kind"
shorttitle        : "Modeling polite speech"

author: 
  - name          : "Erica J. Yoon"
    affiliation   : "1,F"
    corresponding : yes    # Define only one corresponding author
    address       : "450 Serra Mall, Bldg. 420, Rm. 290, Stanford, CA 94305"
    email         : "ejyoon@stanford.edu"
  - name          : "Michael Henry Tessler"
    affiliation   : "1,F"
  - name          : "Noah D. Goodman"
    affiliation   : "1"
  - name          : "Michael C. Frank"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Stanford University"
  - id            : "F"
    institution   : "These authors contributed equally to this work."

author_note: |
  FIXME.

abstract: |
  Being polite, or conveying information in a false or indirect manner in deference to someone else's feelings, seemingly contradicts an important goal of a cooperative speaker: information transfer. In this work, we show that polite speech emerges from a set of competing goals: to be informative, to be kind and provide positive value to others, and to be self-presentational and *appear* helpful. We formalize this tradeoff between speaker's competing goals using a utility-theoretic model, and show the model is able to predict people's polite speech production judgments. Our extension of formal theories of language to account for speakers' social goals represents an advance in understanding of human speech.

  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["politeness.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes
mask              : no

class             : "man"
output            : papaja::apa6_pdf
---

\definecolor{Blue}{RGB}{10,100,200}
\definecolor{Red}{RGB}{255,0,0}

\newcommand{\red}[1]{{\textcolor{Red}{#1}}}
\newcommand{\mht}[1]{{\textcolor{Blue}{[mht: #1]}}}



```{r include_packages, include = FALSE}
# check to see if user has packages. otherwise, install them...
list.of.packages <- c("papaja", "tidyverse", "rwebppl",
                      "jsonlite", "magrittr", "ggthemes",
                      "forcats", "here")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

knitr::opts_chunk$set(echo=FALSE, warning=FALSE, cache=T, message=FALSE, sanitize = T)
library(papaja)
library(tidyverse)
# library(binom)
library(rwebppl)
library(jsonlite)
# library(coda)
library(magrittr)
library(ggthemes)
library(forcats)
library(langcog)
# library(gridExtra)
# library(grid)
library(here)
# library(RColorBrewer)
library(lme4)
library(brms)
# library(directlabels)
library(BayesFactor)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}
hdi_upper <- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}
hdi_lower <- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
options("scipen"=10)   
```

```{r load_data}
# human data 
load(here("02_analysis/01_data/speaker_production.RData"))

# human data - negation
load(here("02_analysis/01_data/speaker_production_neg.RData"))

# model posterior predictives
load(here("03_model/01_posterior_predictives/03_output_processed/postpred_summary.RData"))

# model posterior predictives - negation
load(here("03_model/01_posterior_predictives/03_output_processed/postpred_neg_summary.RData"))

# put data and model predictions together
ms_utt <- rbind(ms_data, 
                ms_model) 

# put neg data and model predictions together
ms_neg <- rbind(ms_data_neg, 
                ms_model_neg) %>%
  mutate(goal = as.factor(goal))

```

We don’t always say what we're thinking.
Although “close the window!” could be sufficient, we say “can you please...?” or “would you mind...?” 
Rather than telling an uncomfortable truth, we lie (“Your dress looks great!”) and prevaricate (“Your poem was so appropriate to the occasion”). 
Such utterances are puzzling for standard views of language use, which see communication as the transfer of information from a sender to a receiver [@buhler1934; @jakobson1960; @shannon1948; @frank2012]. 
Under information-based views, the transfer ought to be efficient and accurate: 
The speaker should choose a succinct utterance from which the listener can recover their intended meaning [@grice1975; @searle1975], 
and the information transferred should be accurate and truthful to the extent that the speaker knows or believes to be true. 
Polite speech – like the examples above – violates these basic expectations about the nature of communication: 
It is typically inefficient and underinformative, and sometimes even outright false. 
So why are we polite? 

Theories of politeness explain deviations from optimal information transfer in language by assuming that speakers take into account social, as well as informational, concerns. 
These concerns are sometimes expressed as sets of polite maxims [@leech1983] or social norms [@ide1989], 
but the most influential account of politeness relies on the notion of “face” to motivate deviations [@goffman1967; @brown1987]. 
On this theory, speakers seek to be liked, approved, and related to (“positive face”) as well as maintain both their and the listeners’ freedom to act (“negative face”). 
Both inefficient indirect speech and untruthful lies in communication are then the result of speakers’ strategic choices relative to possible face threats.

The face-based framework for polite language use provides an intuitive and appealing explanation of many types of polite speech, but theorizing at level of the abstract notions like "face" does not make quantitative predictions in any individual circumstance nor constrain how an artificial agent should go about making polite requests, conveying negative evaluations, or delivering bad news.
It is not obvious how to quantify a face threat in a given situation (e.g., how much of the listener’s positive face will be damaged by hearing “your poem was terrible”),
or how social and informational motivations will trade off in the mind of a speaker (given that the poem recital was terrible, should the speaker say that the listener’s poem was “okay,” “not bad,” or “marvelous”?). 
Further, the recursive nature of reasoning about face has not been formally addressed: 
Speakers may choose particular strategies not only to preserve the listener's face genuinely, but also to be *seen* as doing so, hence appearing to be considerate and socially apt and saving their own face. 

To address these challenges, we develop a utility-theoretic quantitative model for understanding polite speech, in a unified framework to quantify tradeoffs between different goals that a speaker may have. 
In our model, speakers attempt to maximize a set of competing utilities: 
an informational utility, derived via classical, effective information transmission; 
a social utility, derived by being kind and providing positive affect to others, thereby saving the listener's face; 
and a self-presentational utility, derived by appearing in a particular way to other agents and saving the speaker's own face. 
Speakers then can choose between different utterances on the basis of their expected utility. 
The lie that a poem "was good" provides social utility by making its writer feel good, but does not inform about the true state of the world. 

Informational, social, and self-presentational utilities are weighed within a Rational Speech Act (RSA) model. 
RSA models take a probabilistic approach to pragmatic reasoning in language [@frank2012; @goodman2016]: 
Speakers are modeled as agents who choose utterances by reasoning about their effects on a listener relative to their cost, 
while listeners are modeled as inferring interpretations by reasoning about speakers and their goals. 
This class of models has been effective in understanding a wide variety of complex linguistic behaviors, including vagueness [@lassiter2017adjectival], hyperbole [@kao2014], and irony [@kao2015], among others. 
More broadly, RSA models provide a instantiation for language of the idea that human social cognition can be approximated via reasoning about others as rational agents who act to maximize their subjective utility [@baker2009action], 
a hypothesis which has found support in a wide variety of work with both adults and children [e.g., @jara2016naive; @liu2017ten].

```{r model, fig.cap="Diagram of the model: The pragmatic speaker observes the true state and determines her goal between three utilities (informational, social, and presentational), and produces an utterance."}
knitr::include_graphics("fig/model.png", dpi = 170)
```

RSA models are defined recursively such that speakers reason about listeners, and vice versa. 
By convention the level of this recursion is indexed such that a pragmatic listener $L_1$ reasons about what intended meaning and goals would have led a speaker $S_1$ to produce a particular utterance. 
Then $S_1$ reasons about a “literal listener” $L_0$, modeled as attending only to the literal meanings of words (rather than their pragmatic implications), and hence grounds the recursion. 
The target of our current work is a model of a polite speaker $S_2$: 
$S_2$ reasons about what utterance to say to $L_1$ by considering the set of utilities described above: 
namely, whether an utterance results in $L_1$ gaining information, feeling positively, or judging $S_2$ to be either informative or kind (Figure \@ref(fig:model)). 

We evaluate our model by predicting human utterance choices in situations where polite language use is expected. 
Imagine Bob recited his poem and is ignorant of the quality of his poem recital; 
he asks Ann how well he did. 
Ann (the pragmatic speaker $S_2$) produces an utterance $w$ based on the true state of the world $s$ (i.e., the rating truly deserved by Bob’s recital) and a set of goal weights $\hat{\phi}$, 
each of which determines how much speaker Ann prioritizes a particular goal compared to other possible goals. 
Speaker Ann then chooses utterances depending on their expected utility, specifically as a softmax which interpolates between maximizing and probability matching [via the parameter $\lambda_{S_2}$; @goodman2013]:

$$P_{S_2}(w | s, \hat{\phi}) \propto \exp(\lambda_{S_2} \cdot \mathop{\mathbb{E}}[U_{total}(w; s; \hat{\phi})])$$.

What goals must the speaker consider to arrive at a polite utterance? 
We consider three utilities: informational, social, and presentational. 
The total utility of an utterance is the weighted combination of the three utilities minus the cost of the utterance $C(w)$, approximated by the length of the utterance:

$$U_{total}(w; s; \hat{\phi}) = \phi_{inf} \cdot U_{inf}(w; s) + \phi_{soc} \cdot U_{soc}(w; s) + \phi_{pres} \cdot U_{pres}(w; s) - C(w)$$.

The first utility term is a standard *informational utility* ($U_{inf}$), which represents the speaker’s desire to be epistemically helpful. 
The informational utility captures the amount of information a literal listener ($L_0$) would still not know about the world state after hearing the speaker’s utterance: $U_{inf}(w) = \ln(P_{L_1}(s | w))$.

For aspects of the world with affective consequences for the listener (e.g., Bob and his poem recital), we 
<!-- assume speakers produce utterances that make listeners feel like they are in a good state. -->
define the *social utility* ($U_{soc}$) as the value $V(s)$, or expected subjective utility, to the listener of the state inferred given the utterance: $U_{soc}(w) = \mathbb{E}_{P_{L_1}(s \mid w)}[V(s)]$.
This value captures the idea that listeners want to hear that they are in a good state of the world (e.g., Bob would prefer that his poem recital was good). 
We use a positive linear value function ($V$) to map states to subjective values: better ratings are more positively valued.

If listeners try to infer the goals that a speaker is entertaining (e.g., social vs. informational), speakers may choose utterances in order to convey that they had certain goals in mind. 
The third component, *presentational utility* ($U_{pres}$), captures the extent to which the speaker appears to the listener to have a particular goal in mind (e.g., to be kind). 
The speaker gains presentational utility when her listener believes she has certain goals -- that she is trying to be informative or kind. 
Formally, 

$$U_{pres}(w) = \ln(P_{L_1}(\phi_{S_1} \mid w)) = \ln \int_s P_{L_1}(s, \phi_{S_1} \mid w)$$.

The speaker considers the beliefs of listener $L_1$, who hears an utterance and jointly infers both the speaker’s utilities and the true state of the world: 

$$P_{L_1}(s, \hat{\phi} | w) \propto P_{S_1}(w | s, \hat{\phi}) \cdot P(s) \cdot p(\hat{\phi})$$.

This presentational utility, which is the most novel aspect of our model, is higher-order in that it can only be defined for a speaker thinking about a listener who evaluates a speaker. (That is, it can be defined for $S_2$, but not $S_1$.) 

Finally, utterances that are more complex incur a greater cost, $C(w)$ – capturing the general pressure towards economy in speech. 
In our work, utterances with negation (e.g., “not terrible”) are assumed to be slightly more costly than their equivalents with no negation (given by a parameter inferred from data; see Supplemental Materials). 

Intuitively, if Bob’s performance was good, Ann’s utilities align to lead her to say something positive. 
By saying “[Your poem] was amazing,” Ann is simultaneously being truthful, kind, and appearing both and truthful and kind.
If Bob’s performance was poor, however, Ann is in a bind: 
Ann could be kind and say "It was great", but she does so at the cost of conveying the wrong information to Bob (e.g., if he mistakenly infers Ann’s goal to be truthful and hence believes that his recital was actually good).
Worse yet, Bob could infer that Ann is “just being nice,” inferring her goal to be social, and discount her comment as uninformative. 
Alternatively, she could say the truth (“It was bad”), but then Bob would think Ann didn’t care about him. 
What is a socially-aware speaker to do? 
Our model predicts that indirect speech – like “It wasn’t bad” – helps navigate Ann’s dilemma. 
It conveys some true information (e.g., literally it was the worst it could have been) while being sufficiently open-ended to spare Bob’s feelings. 
Further, by incurring the slightly higher cost involved in producing another word, Bob could reason that Ann had reasons for not saying a simpler alternative like “It was good” and and that she must have taken his feelings into account in her utterance. 

We made a direct test of our model by instantiating the example above in an online experiment (*N* = 202; see our pre-registered model, hypothesis, and procedure at \url{https://github.com/ejyoon/polite_speaker}). 
Participants read scenarios in which we provided information about the speaker’s (Ann’s, in our example) feelings toward some performance or product (e.g., poem recital; *true state*), which were shown on a scale from zero to three hearts (e.g., one out of three hearts). 
We manipulated the speaker’s *goal* across trials: to be *informative*  (“give accurate and informative feedback”); to be *social* (“to make the listener feel good”); or to be *both* informative and social at the same time. 
We hypothesized that each of the three goals will represent a tradeoff between the three utilities in our model described above (their inferred values are available in the Supplementary Materials). 
In a single trial, each scenario was followed by a question that asked for the most likely utterance by Ann. Participants selected one of eight possible utterances, by choosing between *It was* vs. *It wasn’t* and then among *terrible*, *bad*, *good*, and *amazing.* 

```{r data_bayes_factor}
load(file=here("03_model/03_other_stat/bayesfactor_state_goal_interaction.Rds"))
load(file=here("03_model/03_other_stat/bayesfactor_state_goal_main_effects.Rds"))
load(file=here("03_model/03_other_stat/bayesfactor_state_only.Rds"))

BF_full_vs_main <- model1bf1/model2bf1
BF_full_vs_one <- model1bf1/model3bf1
BF_main_vs_one <- model2bf1/model3bf1
```

```{r variance, echo=FALSE, fig.cap="Full distribution of human responses vs. model predictions. Error bars represent 95\\% confidence intervals for the data (vertical) and 95% highest density intervals for the model (horizontal)."}
ms_var <- ms_utt %>%
  filter(source == "data" | model == "full") %>%
  select(-model) %>%
  gather(var, value, ci_lower:prob, -source, -true_state) %>%
  unite(new, c(source, var)) %>%
  spread(new, value) %>%
  mutate(positivity = fct_recode(positivity, 
                               "It was ~" = "yes",
                               "It wasn't ~" = "not"),
         positivity = fct_relevel(positivity, "It was ~"))

plot_var <- ggplot(ms_var,
       aes(x = model_prob, y = data_prob)) +
  aes(shape = factor(positivity)) +
  geom_point(aes(colour = factor(goal), fill = factor(goal)), size = 2) +
  scale_shape(solid = FALSE) +
  scale_shape_manual(name = "utterance type", values = c(21, 24))+
  theme_few()+
  geom_abline(intercept = 0, slope = 1, linetype = 3) +
  geom_errorbar(aes(ymin=data_ci_lower,ymax=data_ci_upper), alpha = 0.3) +
  geom_errorbarh(aes(xmin=model_ci_lower,xmax=model_ci_upper), alpha = 0.3) +
  xlab("Model posterior predictive") +
  ylab("Human proportion responses") +
  ylim(0,1) +
  xlim(0,1) +
  scale_y_continuous(breaks=c(0, 0.25, 0.5, 0.75, 1)) +
  scale_x_continuous(breaks=c(0, .25, 0.5, 0.75, 1)) +
  theme(axis.text.y = element_text(hjust = 0, angle = 0),
        axis.text.x = element_text(vjust = 0, angle = 0),
        legend.position = "bottom",
        legend.direction = "horizontal") +
  coord_fixed()+
  scale_colour_solarized(name = "goal") +
  scale_fill_solarized() +
  guides(fill=FALSE)

plot_var

ggsave("speaker_production_cor.png", plot = plot_var, width = 7, height = 4,
       path = here::here("02_analysis/03_figs"))

cor2_mainMod = with(ms_var, cor(data_prob, model_prob))^2

```

```{r brmstat}
load(here("03_model/03_other_stat/brms_polite.Rds"))

brm.tab <- as.data.frame(summary(brms_pol)$fixed) %>%
  select(Estimate, Est.Error, 'l-95% CI', 'u-95% CI') %>%
  rename(Mean = Estimate,
         "SD" = Est.Error,
         "95% CI-Lower" = 'l-95% CI',
         "95% CI-Upper" = 'u-95% CI'
         )

brm.tab$Predictor <- c("Intercept",
                      "True state",
                      "Goal: Informative",
                      "Goal: Social",
                      "True state * Informative",
                      "True state * Social"
                      )
rownames(brm.tab) <- NULL
brm.tab <- brm.tab[,c(5,1:4)]
```

Our primary behavioral hypothesis was that speakers who found themselves describing bad states (e.g., Bob’s performance was bad) and who had goals to be both informative and social would produce more indirect, negative utterances (e.g., “It wasn’t terrible”). 
Such indirect speech acts serve to save the listener’s face while also conveying a vague estimate of the true state. 
This prediction was confirmed: a Bayesian mixed-effects model predicting negation as a function of true state and goal yielded an interaction such that a speaker with both informational and social goals produced more negation in worse states compared to a speaker with only the informational goal (*M* = `r brm.tab$Mean[5]`, [`r brm.tab$"95% CI-Lower"[5]`, `r brm.tab$"95% CI-Upper"[5]`]) and social goal (*M* = `r brm.tab$Mean[6]`, [`r brm.tab$"95% CI-Lower"[6]`, `r brm.tab$"95% CI-Upper"[6]`]). 

To connect these behavioral data more directly to our model, we separately obtained literal meaning judgments about the utterances and incorporated them into our model's predictions. Using an independent sample of *N*=51 participants, we measured judgments of how well different utterances apply to each of the levels on the heart scale (e.g., to what extent is “terrible” true of 2 out of 3 hearts?). 
These measurements were used in the Bayesian data analysis to approximate the semantics of the words as interpreted by the literal listener agent $L_0$ (see Supplementary Materials for literal semantic results). 
Then we used a Bayesian analytic technique [@lee2014] to infer the parameters of the model (e.g., the speaker's utility weights in each goal condition; see Supplementary Materials for inferred parameters).

```{r comparison, fig.width=11, fig.height=4, fig.cap="Comparison of predictions for proportion of utterances chosen by pragmatic speaker from possible model variants (left) and human data (rightmost) for average proportion of negation produced among all utterances, given true state of 0 heart (on a scale of 0 to 3) and speaker with both goals. Gray dotted line indicates chance level at 12.5\\%."}
plot.comp <- ms_utt %>%  
  mutate(model = case_when(
    model == "NA" ~ "Human data", 
    model == "inf" ~ "model: \ninformative only", 
    model == "soc" ~ "model: \nsocial only", 
    model == "pres" ~ "model: \npresentational \nonly", 
    model == "inf_pres" ~ "model: \ninformative, \npresentational", 
    model == "inf_soc" ~ "model: \ninformative, \nsocial", 
    model == "soc_pres" ~ "model: \nsocial, \npresentational", 
    model == "full" ~ "model: \ninformative, \nsocial, \npresentational" 
  ),
  model = fct_relevel(model, "model: \ninformative only", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformative, \nsocial", "model: \ninformative, \npresentational", "model: \ninformative, \nsocial, \npresentational")) %>%
  mutate(positivity = fct_recode(positivity,
                                 "It was ~" = "yes",
                                 "It wasn't ~" = "not"),
         positivity = fct_relevel(positivity, "It wasn't ~")) %>%
  filter(goal == "both", true_state == "0") %>%
  ggplot(., 
       aes(x=utterance, y=prob, fill=positivity, 
           # group = interaction(positive, source), linetype = forcats::fct_rev(positive),
           group = positivity,
           colour = positivity)) +
  geom_hline(yintercept=.125, lty=2, color="gray") +
  geom_line()+
  facet_grid(.~model) +
  xlab("utterance") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position="dodge") +
  ylim(0,.7)+
  scale_color_solarized(guide=FALSE)+
  ggthemes::theme_few(base_size = 15)+
  ylab("proportion chosen") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        legend.position="bottom") +
  guides(color=guide_legend(title=NULL))

plot.comp

ggsave("model_comparisons.png", plot = plot.comp, width = 11, height = 4,
       path = here::here("02_analysis/03_figs"))

```

```{r comparisonVar}
ms_var_comp <- ms_utt %>%
  select(-ci_lower, -ci_upper) %>%
  mutate(model = case_when(
    model == "NA" ~ "data", 
    TRUE ~ as.character(model)
  )) %>%
  select(-source) %>%
  gather(var, value, prob, -model, -true_state) %>%
  unite(new, model) %>%
  spread(new, value) %>%
  mutate(positivity = fct_recode(positivity, 
                               "It was ~" = "yes",
                               "It wasn't ~" = "not"),
         positivity = fct_relevel(positivity, "It was ~"))

cor2_inf = with(ms_var_comp, cor(data, inf))^2
cor2_soc = with(ms_var_comp, cor(data, soc))^2
cor2_pres = with(ms_var_comp, cor(data, pres))^2
cor2_socpres = with(ms_var_comp, cor(data, soc_pres))^2
cor2_infsoc = with(ms_var_comp, cor(data, inf_soc))^2
cor2_infpres = with(ms_var_comp, cor(data, inf_pres))^2
cor2_infsocpres = with(ms_var_comp, cor(data, full))^2

```

```{r comparisonML}
ml_infsocpres <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_self5_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_infpres <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_self6_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_infsoc <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_actual2_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_socpres <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_self7_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_inf <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_trueInf_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_soc <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_trueSoc_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]
ml_pres <- fromJSON(here("03_model/02_model_comparison/02_output/ais-s2_selfPres_3heart_step150000_sample4_chain3.json"), flatten = TRUE, simplifyDataFrame = TRUE)[,1]

bf_full_vs_infpres <- mean(ml_infsocpres) - mean(ml_infpres)
bf_full_vs_infsoc <- mean(ml_infsocpres) - mean(ml_infsoc)
bf_full_vs_socpres <- mean(ml_infsocpres) - mean(ml_socpres)
bf_full_vs_inf <- mean(ml_infsocpres) - mean(ml_inf)
bf_full_vs_soc <- mean(ml_infsocpres) - mean(ml_soc)
bf_full_vs_pres <- mean(ml_infsocpres) - mean(ml_pres)

bf_list <- list(bf_full_vs_inf, bf_full_vs_soc, bf_full_vs_pres,  bf_full_vs_socpres, bf_full_vs_infsoc, bf_full_vs_infpres, 1)
bf_list_rounded <- rapply(bf_list, function(x) round(x, digits=2))
```

```{r comparisonTable, results = 'asis'}
comp_tab <- data.frame("Model" = c("model: \ninformative only", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformative, \nsocial", "model: \ninformative, \npresentational", "model: \ninformative, \nsocial, \npresentational"), 
                       "Variance" = 
                         c(cor2_inf, cor2_soc, cor2_pres, cor2_socpres, 
                           cor2_infsoc, cor2_infpres, cor2_infsocpres), 
                       "logBF" = bf_list_rounded) %>%
  rename("Variance \nexplained" = "Variance",
         "log BF" = "logBF")

apa_table(comp_tab, caption = "Comparison of variance explained for each model variant and log Bayes Factors quantifying evidence in favor of the full model, in comparison to each of the alternatives.")
```

Predictions from the full polite speaker model showed a very strong fit to participants’ utterance choices ($r^2$(96) = `r cor2_mainMod`; Figure \@ref(fig:variance)).
We also compared the predictions of our model with model variants containing different subsets of the three utilities in the full model (Figure 3; see Supplemental Materials: Model Comparison).
Both the variance explained and the marginal likelihood of the observed data were the highest for the full model (see Table \@ref(tab:comparisonTable) and Figure \@ref(fig:comparison)).
In particular, only the full model captured the participants’ preference for negation in the condition in which the speaker had both goals to be informative and social about truly bad states, as hypothesized. 
The full model was superior to: the model with social and presentational utilities, which predicted outright false statements (“It was good”); the model with informational and social utilities, which predicted truthful statements “It was terrible” and “It wasn’t amazing” (that is semantically true when the poem was terrible); and to the model with informative and presentational utilities, which predicted that the speaker was equally likely to be truthful (“It was terrible”) or presentational ("It wasn't terrible").
Thus, all three utilities -- informational, social, and presentational -- were required to fully explain participants’ choices.

To better measure choice behavior, our experiment abstracted away from natural interactions in a number of ways. 
Real-life Anns will have access to a potentially infinite range of utterances to manage the same tradeoff (“It wasn't my cup of tea”, “It’s hard to write a good poem”, “That metaphor in the second stanza was so relatable!”). 
Under our framework, each utterance will have strengths and weaknesses relative to the speaker’s goals, though computation in an unbounded model presents technical challenges [see @goodman2016].

Managing listeners’ inferences is a fundamental task for a socially conscious speaker. 
Following @brown1987, cross-cultural differences in politeness could be a product of different weightings within the same utility structure. 
It is also possible, however, that culture affects the value function $V$ that maps states of the world onto subjective values for the listener (e.g., pointing out bad states could be considered prosocial in certain cultural contexts; more generally, the mapping from states to utilities may be more complex than we have considered).
Our formal modeling approach with systematic behavior measurements provides an avenue towards understanding the vast range of politeness practices found across languages.
Further, politeness is just one of the ways that language use deviates from pure information transfer.
When we flirt, insult, boast, and empathize, we balance information transmission with the goal to affect others’ feelings or present particular views of ourselves. 
A similar utility structure to the one we employed here could give insights into these behaviors as well. 

The formalization of the presentational utility is especially meaningful in that it begins to precisely define self-oriented motivations behind polite speech and other related behaviors. 
To the best of our knowledge, previous theories of politeness have not explained how the motivations of the other- vs. self-oriented concerns are related or how they trade off to inform the speaker’s utterance choices. 
In our current model, the self-oriented concern stems from an other-oriented concern, as the speaker wants to appear to care about the other person’s face or access to knowledge. 
The model then makes precise predictions about how the speaker considering both of these concerns will choose her utterances. 
This work then can be extended to not only other speech acts, but also a wide range of behaviors that can be modeled as utility-driven inference in a social context [@baker2017rational; @hamlin2013mentalistic] where agents need to take into account concerns about both self and others.

In sum, this work takes a concrete step toward quantitative models of the nuances of human speech. 
And it moves us closer to courteous computation – to computers that communicate with tact.

# Acknowledgments

This work was supported by NSERC PGS Doctoral scholarship PGSD3-454094-2014 to EJY, NSF Graduate Research Fellowship DGE-114747 to MHT, ONR grant N00014-13-1-0788 to NDG, and NSF grant BCS 1456077 to MCF.

\newpage

# Supplemental Materials

## Materials and Methods 

### Literal semantic task

We probed judgments of literal meanings of the target words assumed by our model and used in our main experiment. 
51 participants with IP addresses in the United States were recruited on Amazon’s Mechanical Turk. 
We used thirteen different context items in which a speaker evaluated a performance of some kind. 
For example, in one of the contexts, Ann saw a presentation, and Ann’s feelings toward the presentation (true state) were shown on a scale from zero to three hearts (e.g., two out of three hearts filled in red color; see Figure\ \@ref(fig:screenshot) for an example of the heart scale). 
The question of interest was "Do you think Ann thought the presentation was / wasn’t X?" and participants responded by choosing either “no” or “yes.” 
The target could be one of four possible words: *terrible*, *bad*, *good*, and *amazing*, giving rise to eight different possible utterances (with negation or no negation). 
Each participant read 32 scenarios, depicting every possible combination of states and utterances. 
The order of context items was randomized, and there were a maximum of four repeats of each context item per participant. 
For this and the speaker production experiment, we analyzed the data by collapsing across context items.
For each utterance-state pair, we computed the posterior distribution over the semantic weight (i.e., how consistent X utterance is with Y state) assuming a uniform prior over the weight (i.e., a standard Beta-Binomial model). 
Meanings of the words as judged by participants were as one would expect (Figure \ \@ref(fig:litsem)). 
<!-- We used the posterior distribution over the semantic weight of utterance $w$ for state $s$ to set informative priors to infer posterior credible values of the literal meanings from data in the speaker production experiment. -->

### Speaker production task

202 participants with IP addresses in the United States were recruited on Amazon’s Mechanical Turk. As in the literal semantic task above, we used scenarios in which a person (e.g., Bob) gave some performance and asked for another person (e.g., Ann)’s opinion on the performance (see Fig. 2). Additionally, we provided information on the speaker Ann’s goal – to make Bob feel good, or to give as accurate and informative feedback as possible, or both – and the true state – how Ann actually felt about Bob’s performance (e.g., two out of three hearts, on a scale from zero to three hearts; Figure\ \@ref(fig:screenshot)). 
Each participant read twelve scenarios, depicting every possible combination of the three goals and four states. 
The order of context items was randomized, and there were a maximum of two repeats of each context item per participant.
Each scenario was followed by a question that read, "If Ann wanted to make Bob feel good but not necessarily give informative feedback (or to give accurate and informative feedback but not necessarily make Bob feel good, or BOTH make Bob feel good AND give accurate and informative feedback), what would Ann be most likely to say?" 
Participants indicated their answer by choosing one of the options on the two dropdown menus, side-by-side, one for choosing between *It was* vs. *It wasn’t* and the other for choosing among *terrible*, *bad*, *good*, and *amazing.*

## Supplementary Text

### Data analysis
We used `r cite_r("politeness.bib")` for all our analyses.

### Full statistics on human data

```{r brmTab, results="asis"}
apa_table(brm.tab, caption= "Predictor mean estimates with standard deviation and 95% credible interval information for a Bayesian linear mixed-effects model predicting negation production based on true state and speaker goal (with both-goal as the reference level).")
```

We used Bayesian linear mixed-effects models [`brms` package in R; @R-brms] using crossed random effects of true state and goal with maximal random effects structure [@gelman2006data; @barr2013random].

### Polite RSA model fitting and inferred parameters

```{r phi, results = 'asis'}
load(here("03_model/01_posterior_predictives/03_output_processed/phi_summary.RData"))
load(here("03_model/01_posterior_predictives/03_output_processed/other_param_summary.RData"))

phi_tab <- d_phi_s %>%
  mutate_at(vars(informative:social), as.numeric) %>%
  mutate_if(is.numeric, function(x) round(x, digits=2)) %>%
  ungroup() %>%
    mutate(model = case_when(
    model == "inf" ~ "informative only", 
    model == "soc" ~ "social only", 
    model == "pres" ~ "presentational only", 
    model == "InfPres" ~ "informative, presentational", 
    model == "InfSoc" ~ "informative, social", 
    model == "SocPres" ~ "social, presentational", 
    model == "Full" ~ "informative, social, presentational" 
  )) %>%
  select(model, goal, informative, social, Selfpres, s1)

colnames(phi_tab) <- c("Model", "goal", "$\\phi_{inf}$", "$\\phi_{soc}$", "$\\phi_{pres}$", "$\\phi_{S_1}$")

apa_table(phi_tab, escape=FALSE, caption = "Inferred phi parameters from all model variants with more than one utility.")
```

```{r otherParams, results='asis'}
other_tab <- d_other_s %>%
    mutate(model = case_when(
    model == "inf" ~ "informative only", 
    model == "soc" ~ "social only", 
    model == "pres" ~ "presentational only", 
    model == "inf_pres" ~ "informative, presentational", 
    model == "inf_soc" ~ "informative, social", 
    model == "soc_pres" ~ "social, presentational", 
    model == "full" ~ "informative, social, presentational" 
  )) %>%
  mutate(param = round(param, digits=2)) %>%
  spread(parameter, param)

colnames(other_tab) <- c("Model", "Cost of negation", "Speaker optimality")

apa_table(other_tab, escape=FALSE, caption = "Inferred negation cost and speaker optimality parameters for all model variants.")
```

In the speaker production task, participants were told the speakers’ intentions (e.g., wanted to make Bob feel good). 
We assume that the intention descriptions conveyed some mixture of weights $\phi_{epi}$, $\phi_{soc}$, $\phi_{pres}$, and $\phi_{S_1}$ that the speaker was using. 
We put uninformative priors on the unnormalized mixture weights ($\phi$ ~ $Uniform(0,1)$) separately for each goal condition ("wanted to X"; *social*, *informative*, or *both*).
In addition, the full model has two global parameters: the speaker's soft-max parameter $\lambda_{S_2}$ and soft-max paramater of the hypothetical speaker that the pragmatic listener reasons about $\lambda_{S_1}$.
$\lambda_{S_1}$ was 1, and $\lambda_{S_2}$ was inferred from the data: 
We put a prior that was consistent with those used for similar models in this model class: $\lambda_{S_2}$ ~ $Uniform(0,20)$.
Finally, we incorporate the literal semantics data into the RSA model by maintaining uncertainty about the semantic weight of utterance $w$ for state $s$, for each of the states and utterances, and assuming a Beta-Binomial linking function between these weights and the literal semantics data (see *Literal semantics task* above).
We infer the posterior distribution over all of the model parameters and generate model predictions based on this posterior distribution using Bayesian data analysis [@lee2014]. 
We ran 4 MCMC chains for 80,000 iterations, discarding the first 40,000 for burnin. 
The inferred values of weight mixtures for each model variant (with different $\phi$ components) and other parameters are shown in Table \@ref(tab:phi) and Table \@ref(tab:otherParams), respectively.

\newpage

## Supplemental Figures 

```{r screenshot, fig.pos = "!h", fig.cap="Example of a trial in the speaker production task."}
knitr::include_graphics("fig/screenshot.png", dpi = 130)
```

```{r litsem, echo=FALSE, fig.width = 10, fig.height = 4, out.width = "\\textwidth", fig.pos = "!h", fig.cap = "Semantic measurement results. Proportion of acceptances of utterance types (shown in different colors) combined with target words (shown in different facets) given the true state represented on a scale of hearts. Error bars represent 95\\% confidence intervals."}
d <- read.csv(here("02_analysis/01_data/literal_semantics.csv")) %>%
  mutate(utterance = fct_relevel(utterance, "terrible", "bad", "good", "amazing"))

ms <- d %>%
  mutate(positivity = fct_recode(positivity,
                                "It was ~ " = "it was ___",
                                "It wasn't ~ " = "it wasn't ___"
                                ),
         positivity = fct_relevel(positivity, "It wasn't ~ ")) %>%
  group_by(positivity, state, utterance, subid) %>%
  summarize(
            judgment = mean(judgment, na.rm=TRUE)
          ) %>%
  group_by(positivity, state, utterance) %>%
  multi_boot_standard(col = "judgment") %>%
  mutate(judgment = mean)

qplot(state, judgment, 
      colour = positivity,
      data=ms) + 
  geom_line(aes(group=positivity)) +
  facet_grid(.~utterance) +
  xlab("state (0=worst)") +
  ylab("proportion of\n acceptances") +
  geom_errorbar(aes(ymin=ci_lower,ymax=ci_upper,width=.1)) +
  theme_few(base_size = 16) +
  scale_color_solarized() +
  theme(legend.position = "bottom", 
        legend.title = element_blank()) +
  geom_hline(yintercept = .5, lty=2)
```

```{r utterance, echo=FALSE, out.width = "\\textwidth", fig.pos = "!h", fig.height=6, fig.cap="Experimental results (solid lines) and fitted predictions from the full model (dashed lines) for speaker production. Proportion of utterances chosen (utterance type – direct vs. indirect – in different colors and words shown on x-axis) given the true states (columns) and speaker goals (rows). Error bars represent 95\\% confidence intervals for the data and 95\\% highest density intervals for the model. Black dotted line represents the chance level."}
plot.utt <- ggplot(data=ms_utt %>%
                     filter(source == "data" | model == "full") %>%
                     mutate(positivity = fct_relevel(positivity, "not")), 
       aes(x=utterance, y=prob, group = interaction(positivity, source), colour = positivity, linetype = source)) +
  geom_line()+
  facet_grid(goal~true_state, labeller = labeller(goal = label_both)) +
  xlab("utterance") +
  ylab("proportion chosen") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position="dodge") +
  geom_hline(yintercept=.1, lty=2) +
  ylim(0,1)+
  scale_color_solarized(labels = c("It wasn't~","It was~"))+
  ggthemes::theme_few()+
  theme(axis.text.x = element_text(angle = 45, vjust=0.5),
        legend.position = "bottom") +
  guides(colour=guide_legend(title="utterance type")) +
  scale_linetype_discrete(labels = c("data", "model"))

plot.utt

# ggsave("speaker_production_utt_wMod.png", plot = plot.utt, width = 7, height = 5,
#        path = here::here("02_analysis/03_figs"))
```

```{r comparisonAll, echo=FALSE, out.width = "\\textwidth", fig.pos = "!h", fig.width=11, fig.height=7, fig.cap="Comparison of predictions for proportion of utterances chosen by pragmatic speaker from possible model variants (left) and human data (rightmost) for average proportion of negation produced among all utterances, given true state of 0 heart and speaker with informative (top), social (middle), and both goals (bottom). Gray dotted line indicates chance level at 12.5\\%."}
plot.comp.all <- ms_utt %>%  
  mutate(model = case_when(
    model == "NA" ~ "Human data", 
    model == "inf" ~ "model: \ninformative only", 
    model == "soc" ~ "model: \nsocial only", 
    model == "pres" ~ "model: \npresentational \nonly", 
    model == "inf_pres" ~ "model: \ninformative, \npresentational", 
    model == "inf_soc" ~ "model: \ninformative, \nsocial", 
    model == "soc_pres" ~ "model: \nsocial, \npresentational", 
    model == "full" ~ "model: \ninformative, \nsocial, \npresentational" 
  ),
  model = fct_relevel(model, "model: \ninformative only", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformative, \nsocial", "model: \ninformative, \npresentational", "model: \ninformative, \nsocial, \npresentational")) %>%
  mutate(positivity = fct_recode(positivity,
                                 "It was ~" = "yes",
                                 "It wasn't ~" = "not"),
         positivity = fct_relevel(positivity, "It wasn't ~")) %>%
  filter(true_state == "0") %>%
  ggplot(., 
       aes(x=utterance, y=prob, fill=positivity, 
           # group = interaction(positive, source), linetype = forcats::fct_rev(positive),
           group = positivity,
           colour = positivity)) +
  geom_hline(yintercept=.125, lty=2, color="gray") +
  geom_line()+
  facet_grid(goal~model) +
  xlab("utterance") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position="dodge") +
  ylim(0,.7)+
  scale_color_solarized(guide=FALSE)+
  ggthemes::theme_few(base_size = 15)+
  ylab("proportion chosen") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        legend.position="bottom") +
  guides(color=guide_legend(title=NULL))

plot.comp.all

# ggsave("model_comparisons_all.png", plot = plot.comp.all, width = 11, height = 4,
#        path = here::here("02_analysis/03_figs"))

```

```{r negation, echo=FALSE, fig.width=11, fig.height=4, out.width = "\\textwidth", fig.pos = "!h", fig.cap="Experimental results (left) and fitted model predictions (right) for average proportion of negation produced among all utterances, given true states (x-axis) and goals (colors)."}
plot.neg <- ms_neg %>%  
  mutate(model = case_when(
    model == "NA" ~ "Human data", 
    model == "inf" ~ "model: \ninformative only", 
    model == "soc" ~ "model: \nsocial only", 
    model == "pres" ~ "model: \npresentational \nonly", 
    model == "inf_pres" ~ "model: \ninformative, \npresentational", 
    model == "inf_soc" ~ "model: \ninformative, \nsocial", 
    model == "soc_pres" ~ "model: \nsocial, \npresentational", 
    model == "full" ~ "model: \ninformative, \nsocial, \npresentational" 
  ),
  model = fct_relevel(model, "model: \ninformative only", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformative, \nsocial", "model: \ninformative, \npresentational", "model: \ninformative, \nsocial, \npresentational")) %>%
  # filter(positive == "not") %>%
  ggplot(., 
       aes(x=true_state, y=prob, color = goal, group=goal)) +
  geom_line(stat="identity", position=position_dodge()) +
  xlab("true state") +
  ylab("proportion negation") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position=position_dodge(width=.05)) +
  theme_few(base_size = 15)+
  scale_color_solarized() +
  facet_grid(.~model) +
  theme(legend.position="bottom")

plot.neg

ggsave("speaker_production_neg_wMod.png", plot = plot.neg, width = 7, height = 3,
       path = here::here("02_analysis/03_figs"))
```
.

\newpage
\newpage
\newpage
\pagebreak


# References
```{r create_r-references}
r_refs(file = "politeness.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

