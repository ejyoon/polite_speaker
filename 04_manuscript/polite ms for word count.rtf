{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 AppleSymbols;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww14200\viewh15500\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Polite speech emerges from competing pressures to be (and look) informative and kind\
Erica J. Yoon,1
\f1 \uc0\u8727 
\f0 \'86 Michael Henry Tessler,1
\f1 \uc0\u8727 
\f0  Noah D. Goodman,1 Michael C. Frank1\
1Department of Psychology, Stanford University,\
450 Serra Mall, Stanford, CA 94305.\

\f1 \uc0\u8727 
\f0 These authors contributed equally to this work.\
\'86To whom correspondence should be addressed; E-mail: ejyoon@stanford.edu.\
\
Being polite, or conveying information in a false or indirect manner in deference to someone else\'92s feelings, seemingly contradicts an important goal of a cooperative speaker: information transfer. In this work, we show that polite speech emerges from a set of competing goals: to be informative, to be kind, and to appear helpful or kind. We formalize this tradeoff between speaker\'92s competing goals using a utility-theoretic model, and show the model is able to predict people\'92s polite speech production judgments. Our extension of formal theories of language to account for speakers\'92 social goals represents an advance in understanding of human language use.\
\
We don\'92t always say what we\'92re thinking. Although \'93close the window!\'94 could be sufficient, we say \'93can you please...?\'94 or \'93would you mind...?\'94 Rather than telling an uncomfortable truth, we lie (\'93Your dress looks great!\'94) and prevaricate (\'93Your poem was so appropriate to the occasion\'94). Such utterances are puzzling for standard views of language use, which see communication as the transfer of information from a sender to a receiver (1\'964). Under information-based views, the transfer ought to be efficient and accurate: The speaker should choose a succinct utterance to convey what the speaker knows (5, 6), and the information transferred should be accurate and truthful to the extent of the speaker's knowledge. Polite speech \'96 like the examples above \'96 violates these basic expectations about the nature of communication: It is typically inefficient and underinformative, and sometimes even outright false. So why are we polite?\
\
Theories of politeness explain deviations from optimal information transfer in language by assuming that speakers take into account social, as well as informational, concerns. These concerns are sometimes expressed as sets of polite maxims (7) or social norms (8), but the most influential account of politeness relies on the notion of \'93face\'94 to motivate deviations (9, 10). On this theory, interactants seek to be approved and related to (\'93positive face\'94) as well as maintain their freedom to act (\'93negative face\'94). Both inefficient indirect speech and untruthful lies in communication are then the result of speakers\'92 strategic choices relative to possible face threats.\
\
The face-based framework for polite language use provides an intuitive and appealing explanation of many types of polite speech, but it does not precisely define the competing communicative goals trade off with one another. For example, it is unclear when the desire to save face will motivate statements that are outright false (\'93Your cake is delicious!\'94) versus indirect (\'93It could use a bit of salt\'94), and when face-saving should be prioritized over other concerns (e.g., helpful information transfer).\
Further, presentational goals related to face have not been formally addressed: Speakers may choose particular strategies not only to preserve the listener\'92s face genuinely, but also to be seen as doing so, hence appearing to be considerate and socially apt and saving their own face.\
\
\
\
\
\
\
\
To address these challenges, we develop a utility-theoretic quantitative model for understanding polite speech, in a unified framework to quantify tradeoffs between different goals that a speaker may have. In our model, speakers attempt to maximize a set of competing utilities: an informational utility, derived via classical, effective information transmission; a social utility, derived by being kind to provide positive affect to others, thereby saving the listener\'92s face; and a self-presentational utility, derived by appearing in a particular way to other agents and thus saving the speaker\'92s own face. Speakers then can choose between different utterances on the basis of their expected utility. \
\
The utilities are weighed within a Rational Speech Act (RSA) model that takes a probabilistic approach to pragmatic reasoning in language (4, 11): Speakers are modeled as agents who choose utterances by reasoning about their effects on a listener relative to their cost, while listeners are modeled as inferring interpretations by reasoning about speakers and their goals. This class of models has been effective in understanding a wide variety of complex linguistic behaviors, including vagueness (12), hyperbole (13), and irony (14), among others. More broadly, RSA models provide a instantiation for language of the idea that human social cognition can be approximated via reasoning about others as rational agents who act to maximize their subjective utility (15), a hypothesis which has found support in a wide variety of work with both adults and children (16, 17).\
\
RSA models are defined recursively such that speakers reason about listeners, and vice versa. By convention the level of this recursion is indexed such that a pragmatic listener L1 reasons about what intended meaning and goals would have led a speaker S1 to produce a particular utterance. Then S1 reasons about a \'93literal listener\'94 L0, modeled as attending only to the literal meanings of words (rather than their pragmatic implications), and hence grounds the recursion. The target of our current work is a model of a polite speaker S2: S2 reasons about what utterance to say to L1 by considering the set of utilities described above: namely, whether an utterance results in L1 gaining information, feeling positively, or judging S2 to be either informative or kind (Figure 1).\
\
 Figure 1: Diagram of the model: The pragmatic speaker observes the true state and determines her goal between three utilities (informational, social, and presentational), and produces an utterance.\
\
We evaluate our model by predicting human utterance choices in situations where polite language use is expected. Imagine Bob recited his poem and asks Ann how well he did. Ann (the pragmatic speaker S2) produces an utterance w based on the true state of the world s (i.e., the rating truly deserved by Bob\'92s recital) and a set of goal weights \uc0\u966 \'88, each of which determines how much speaker Ann prioritizes a particular goal compared to other possible goals. Speaker Ann\'92s production decision is softmax, which interpolates between maximizing and probability matching (via the parameter \u955 S2 ; (18)):\
\
PS2(w|s,\uc0\u966 \'88)
\f1 \uc0\u8733 
\f0 exp(\uc0\u955 S2 \'b7E[Utotal(w;s;\u966 \'88)])\
.\
\
What goals must the speaker consider to arrive at a polite utterance? We consider three utilities: informational, social, and presentational. The total utility of an utterance is the weighted combination of the three utilities minus the cost of the utterance C(w), approximated by the length of the utterance:\
Utotal(w; s; \uc0\u966 \'88) = \u966 inf \'b7 Uinf (w; s) + \u966 soc \'b7 Usoc(w; s) + \u966 pres \'b7 Upres(w; s) \u8722  C(w) .\
The first utility term is a standard informational utility (Uinf ), which represents the speaker\'92s desire to be epistemically helpful. The informational utility captures the amount of information a literal listener (L0) would still not know about the world state after hearing the speaker\'92s utterance: Uinf (w) = ln(PL1 (s|w)).\
For aspects of the world with affective consequences for the listener (e.g., Bob and his poem recital), we define the social utility (Usoc) as the value V (s), or expected subjective utility, to the listener of the state inferred given the utterance: Usoc(w) = EPL1 (s|w)[V (s)]. This value captures the idea that listeners want to hear that they are in a good state of the world (e.g., Bob would prefer that his poem recital was good). We use a positive linear value function (V) to map states to subjective values: better ratings are more positively valued.\
If listeners try to infer the goals that a speaker is entertaining (e.g., social vs. informational), speakers may choose utterances in order to convey that they had certain goals in mind. The third component, presentational utility (Upres), captures the extent to which the speaker appears to the listener to have a particular goal in mind (e.g., to be kind). The speaker gains presentational utility when her listener believes she has certain goals \'96 that she is trying to be informative or kind. Formally, \
The speaker considers the beliefs of listener L1, who hears an utterance and jointly infers\
both the speaker\'92s utilities and the true state of the world:\
PL1 (s, \uc0\u966 \'88|w) 
\f1 \uc0\u8733 
\f0  PS1 (w|s, \uc0\u966 \'88) \'b7 P (s) \'b7 p(\u966 \'88)\
.\
This presentational utility, which is the most novel aspect of our model, is higher-order in\
that it can only be defined for a speaker thinking about a listener who evaluates a speaker. (That is, it can be defined for S2, but not S1.)\
Finally, utterances that are more complex incur a greater cost, C(w) \'96 capturing the general pressure towards economy in speech. In our work, utterances with negation (e.g., \'93not terrible\'94) are assumed to be slightly more costly than their equivalents with no negation (given by a parameter inferred from data; see Supplemental Materials).\
Upres(w) = ln(PL1 (\uc0\u966 S1 | w)) = ln\
PL1 (s, \uc0\u966 S1 | w)\
\
Intuitively, if Bob\'92s performance was good, Ann\'92s utilities align to lead her to say something positive. By saying \'93[Your poem] was amazing,\'94 Ann is simultaneously being truthful, kind, and appearing both truthful and kind. If Bob\'92s performance was poor, however, Ann is in a bind: Ann could be kind and say "It was great", but she does so at the cost of conveying the wrong information to Bob if he believes her to be truthful. Or, worse yet, Bob could infer that Ann is \'93just being nice\'94, and think of her as a dishonest, unhelpful speaker. Alternatively, she could say the truth (\'93It was bad\'94), but then Bob would think Ann didn\'92t care about him. What is a socially-aware speaker to do? Our model predicts that indirect speech \'96 like \'93It wasn\'92t bad\'94 \'96 helps navigate Ann\'92s dilemma. It conveys some true information (e.g., literally it wasn't the worst it could have been) while being sufficiently open-ended to spare Bob\'92s feelings. Further, by incurring the slightly higher cost involved in producing another word (negation), Bob could reason that Ann had reasons for not saying a simpler alternative like \'93It was good\'94 and that she must have taken his feelings into account in her utterance.\
\
\
\
\
\
\
We made a direct test of our model by instantiating the example above in an online experiment (N = 202; see our pre-registered model, hypothesis, and procedure at https://github.com/ejyoon/polite_speaker). Participants read scenarios in which we provided information about the speaker\'92s (Ann\'92s, in our example) feelings toward some performance or product (e.g., poem recital; true state), which were shown on a scale from zero to three hearts. We manipulated the speaker\'92s goal across trials: to be informative (\'93give accurate and informative feedback\'94); to be kind (\'93to make the listener feel good\'94); or to be both informative and kind at the same time. We hypothesized that each of the three goals will represent a tradeoff between the three utilities in our model described above (see Supplementary Materials for their inferred values). In a single trial, each scenario was followed by a question that asked for the most likely utterance by Ann. Participants\
\
Figure 2: Full distribution of human responses vs. model predictions. Error bars represent 95% confidence intervals for the data (vertical) and 95% highest density intervals for the model (horizontal).\
\
selected one of eight possible utterances, by choosing between It was vs. It wasn\'92t and then among terrible, bad, good, and amazing.\
Our primary behavioral hypothesis was that speakers describing bad states (e.g., Bob\'92s performance was bad) with goals to be both informative and kind would produce more indirect, negative utterances (e.g., \'93It wasn\'92t terrible\'94). Such indirect speech acts serve to save the listener\'92s face while also conveying a vague estimate of the true state. This prediction was confirmed: a Bayesian mixed-effects model predicting negation as a function of true state and goal yielded an interaction such that a speaker with both goals to be informative and kind produced more negation in worse states compared to a speaker with only\
\
           Figure 3: Comparison of predictions for proportion of utterances chosen by pragmatic speaker from possible model variants (left) and human data (rightmost) for average proportion of negation produced among all utterances, given true state of 0 heart (on a scale of 0 to 3) and speaker with both goals. Gray dotted line indicates chance level at 12.5%.\
\
the goal to be informative (M = -1.33, [-1.69, -0.98]) and goal to be kind (M = -0.50, [-0.92, -0.07]).\
To connect these behavioral data more directly to our model, we separately obtained literal meaning judgments about the utterances and incorporated them into our model\'92s predictions. Using an independent sample of N=51 participants, we measured judgments of how well differ- ent utterances apply to each of the levels on the heart scale (e.g., to what extent is \'93terrible\'94 true of 2 out of 3 hearts?). These measurements were used in a Bayesian data analysis to approximate the semantics of the words as interpreted by the literal listener agent L0. Then we used a Bayesian analytic technique (19) to infer the parameters of the model (e.g., the speaker\'92s utility weights in each goal condition; see Supplementary Materials for literal semantic results and inferred parameters).\
\
Predictions from the full polite speaker model showed a very strong fit to participants\'92 utterance choices (r2(96) = 0.97; Figure 2). We also compared the predictions of our model with model variants containing different subsets of the three utilities in the full model (Figure 3; see Supplemental Materials: Model Comparison). Both the variance explained and the marginal likelihood of the observed data were the highest for the full model (see Table 1 and Figure 3). In particular, only the full model captured the participants\'92 preference for negation in the condition in which the speaker had both goals to be informative and kind about truly bad states, as hypothesized. The full model was superior to: the model with social and presentational utilities, which predicted outright false statements (\'93It was good\'94); the model with informational and social utilities, which predicted truthful statements \'93It was terrible\'94 and \'93It wasn\'92t amazing\'94 (that is semantically true when the poem was terrible); and to the model with informative and presentational utilities, which predicted that the speaker was equally likely to be truthful (\'93It was terrible\'94) or presentational (\'93It wasn\'92t terrible\'94). Thus, all three utilities \'96 informational, social, and presentational \'96 were required to fully explain participants\'92 choices.\
\
\
\
\
\
To better measure choice behavior, our experiment abstracted away from natural interactions in a number of ways. Real-life Anns will have access to a potentially infinite range of utterances to manage the same tradeoff (\'93It wasn\'92t my cup of tea\'94, \'93It\'92s hard to write a good poem\'94, \'93That metaphor in the second stanza was so relatable!\'94). Under our framework, each utterance will have strengths and weaknesses relative to the speaker\'92s goals, though computation in an unbounded model presents technical challenges (see (11)).\
\
Managing listeners\'92 inferences is a fundamental task for a socially conscious speaker. Following Brown and Levinson (1987), cross-cultural differences in politeness could be a product of different weightings within the same utility structure. It is also possible, however, that culture affects the value function V that maps states of the world onto subjective values for the listener (e.g., pointing out bad states could be considered prosocial in certain cultural contexts; more generally, the mapping from states to utilities may be more complex than we have considered). Our formal modeling approach with systematic behavior measurements provides an avenue towards understanding the vast range of politeness practices found across languages.\
\
Our work extends previous models of language beyond standard informational utilities to address social and self-presentational concerns. Previous theories of language use have not explained how informational versus social concerns trade off to inform the speaker\'92s utterance choices. Thus, this work represents a key theoretical advance exploring how Gricean informational cooperativity interacts with other social goals. The current work opens up important communicative behaviors to formal modeling. Politeness is just one of the ways that language use deviates from pure information transfer; When we flirt, insult, boast, and empathize, we balance information transmission with the goal to affect others\'92 feelings or present particular views of ourselves. A similar utility structure to our model could give insights into these speech acts and a wide range of behaviors that can be modeled as utility-driven inference in a social context (20, 21) where agents need to take into account concerns about both self and others.\
\
In sum, this work takes a concrete step toward quantitative models of the nuances of human speech. And it moves us closer to courteous computation \'96 to computers that communicate with tact.\
\
References\
1. K. Bu\uc0\u32 \u776 hler, Sprachtheorie (Oxford, England: Fischer, 1934). 11\
2. C. E. Shannon, Bell Syst. Tech. J. 27, 623 (1948).\
3. R. Jakobson, Style in language (MA: MIT Press, 1960), pp. 350\'96377.\
4. M. C. Frank, N. D. Goodman, Science 336, 998 (2012).\
5. H. P. Grice, Syntax and Semantics, P. Cole, J. L. Morgan, eds. (Academic Press, 1975), vol. 3, pp. 41\'9658.\
6. J. Searle, Syntax and Semantics, P. Cole, J. L. Morgan, eds. (Academic Press, 1975), vol. 3, pp. 59\'9682.\
7. G. Leech, Principles of pragmatics (London, New York: Longman Group Ltd., 1983).\
8. S. Ide, Multilingua-journal of cross-cultural and interlanguage communication 8, 223\
(1989).\
9. P. Brown, S. C. Levinson, Politeness: Some universals in language usage, vol. 4 (Cam- bridge university press, 1987).\
10. E. Goffman, Interaction ritual: essays on face-to-face interaction (Aldine, 1967).\
11. N. D. Goodman, M. C. Frank, Trends in Cognitive Sciences 20, 818 (2016).\
12. D. Lassiter, N. D. Goodman, Synthese 194, 3801 (2017).\
13. J. T. Kao, J. Y. Wu, L. Bergen, N. D. Goodman, Proceedings of the National Academy of Sciences 111, 12002 (2014).\
14. J. T. Kao, N. D. Goodman, Proceedings of the 37th Annual Conference of the Cognitive Science Society (2015).\
15. C. L. Baker, R. Saxe, J. B. Tenenbaum, Cognition 113, 329 (2009). 12\
16. J. Jara-Ettinger, H. Gweon, L. E. Schulz, J. B. Tenenbaum, Trends in cognitive sciences 20, 589 (2016).\
17. S. Liu, T. D. Ullman, J. B. Tenenbaum, E. S. Spelke, Science 358, 1038 (2017).\
18. N. D. Goodman, A. Stuhlmu\uc0\u32 \u776 ller, Topics in cognitive science 5, 173 (2013).\
19. M. D. Lee, E. J. Wagenmakers, Bayesian Cognitive Modeling: A Practical Course (Cambridge Univ. Press, 2014).\
20. C. L. Baker, J. Jara-Ettinger, R. Saxe, J. B. Tenenbaum, Nature Human Behaviour 1, 0064 (2017).\
21. K.J.Hamlin,T.D.Ullman,J.B.Tenenbaum,N.D.Goodman,C.L.Baker,Developmental science 16, 209 (2013).\
\
Acknowledgments\
Funding: This work was supported by NSERC PGS Doctoral scholarship PGSD3-454094-2014 to EJY, NSF Graduate Research Fellowship DGE-114747 to MHT, ONR grant N00014-13-1- 0788 to NDG, and NSF grant BCS 1456077 to MCF. Author contributions: E.J.Y., M.H.T., N.D.G., and M.C.F. designed research; E.J.Y. and M.H.T. performed research; E.J.Y. and M.H.T. analyzed data; and E.J.Y., M.H.T., N.D.G., and M.C.F. wrote the paper. Competing interests:\
13\
The authors declare no conflict of interest. Data and materials availability: Our pre-registered model, hypothesis, and procedure, as well as all of our data and analyses are available at https://github.com/ejyoon/polite_speaker.\
}