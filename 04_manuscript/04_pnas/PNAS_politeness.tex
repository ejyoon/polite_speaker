\documentclass[9pt,twocolumn,twoside,lineno]{main_class_file}
% Use the lineno option to display guide line numbers if required.


\usepackage[flushleft]{threeparttable}	% Allows for three part tables with a specified notes section
\usepackage{graphics}
\usepackage{amsmath}

\usepackage{tabularx}


\templatetype{main_style_file} % Choose template 
% {pnasresearcharticle} = Template for a two-column research article
% {pnasmathematics} %= Template for a one-column mathematics article
% {pnasinvited} %= Template for a PNAS invited submission

\title{Polite speech emerges from competing social goals}

% Use letters for affiliations, numbers to show equal authorship (if applicable) and to indicate the corresponding author
\author[a,1,2]{Erica J. Yoon}
\author[a,1]{ Michael Henry Tessler} 
\author[a]{Noah D. Goodman}
\author[a]{Michael C. Frank}

\affil[a]{Department of Psychology, Stanford University}

%\author{Erica J. Yoon\textsuperscript{1, *, †}, Michael Henry Tessler\textsuperscript{1, †}, Noah D. Goodman\textsuperscript{1}, \& Michael C. Frank\textsuperscript{1}}
%\affil{
%\vspace{0.5cm}
%      \textsuperscript{1} Department of Psychology, Stanford University\\
%      \textsuperscript{*} Corresponding author\\
%      \textsuperscript{†} These authors contributed equally to this work.  }

% Please give the surname of the lead author for the running footer
\leadauthor{Yoon, Tessler} 

% Please add here a significance statement to explain the relevance of your work
\significancestatement{Politeness violates the standard model of language use as a tool primarily devoted to information transfer. Here, we formalize how politeness emerges in language use through a balance between three potentially conflicting goals: an informational goal, a social goal (\emph{be nice}), and a self-presentational goal (\emph{look nice}).  We present a pre-registered, quantitative test of our model, finding all three speech production goals are necessary to explain the nuances of the utterance choices of our participants. This formal work introduces a quantitative understanding of social language use more broadly, and presents a computational perspective on courtesy, to machines that talk with tact.}

% Please include corresponding author, author contribution and author declaration information
\authorcontributions{Please provide details of author contributions here.}
\authordeclaration{Please declare any conflict of interest here.}
\equalauthors{\textsuperscript{1}E.J.Y. and M.H.T. contributed equally to this work.}
\correspondingauthor{\textsuperscript{2}To whom correspondence should be addressed. E-mail: ejyoon@stanford.edu}

% Keywords are not mandatory, but authors are strongly encouraged to provide them. If provided, please include two to five keywords, separated by the pipe symbol, e.g:
  \keywords{politeness $|$ computational modeling $|$ communicative goals$|$ pragmatics}

\begin{abstract}
Language is a remarkably efficient tool for transmitting information. 
Yet human speakers make statements that are inefficient, imprecise, or even contrary to their beliefs, all in the service of being polite.
What rational machinery underlies polite language use?
Here, we show that polite speech emerges from the competition of informational, social, and self-presentational (i.e., \emph{appearing} informational or social) goals.
We formalize this tradeoff using a probabilistic model of utterance production, which predicts human choices with high
quantitative accuracy.
This utility-theoretic approach to speech acts takes a step towards explaining the richness and subtlety of social language use.

\end{abstract}

\dates{This manuscript was compiled on \today}
\doi{\url{www.pnas.org/cgi/doi/10.1073/pnas.XXXXXXXXXX}}

\begin{document}

\maketitle
\thispagestyle{firststyle}
\ifthenelse{\boolean{shortarticle}}{\ifthenelse{\boolean{singlecolumn}}{\abscontentformatted}{\abscontent}}{}


\dropcap{W}e rarely say exactly what's on our mind. 
Although \emph{close the window!} could be effective message, we dawdle by adding \emph{can you please\ldots{}?}
or \emph{would you mind\ldots{}?} 
Rather than tell an uncomfortable truth, socially-aware speakers lie (\emph{Your dress looks great!}) and
prevaricate (\emph{Your poem was so appropriate to the occasion}).
Such language use is puzzling for classical views of language as information transfer (Bühler, 1934; Frank \& Goodman, 2012; Jakobson, 1960; Shannon,
1948). On these views, transfer ought to be efficient and accurate: The
speaker chooses a succinct utterance to convey their beliefs
knows (Grice, 1975; Searle, 1975), and the information transferred
is ideally accurate and truthful to the extent of the speaker's
knowledge. Polite speech violates these
basic expectations about the nature of communication: It is typically
inefficient and underinformative, and sometimes even outright false. Yet even young speakers of a language spontaneously produce
requests in polite forms (Axia \& Baroni, 1985; e.g., Clark \& Schunk,
1980), and adults use politeness strategies while arguing,
preventing unnecessary offense to their interactants (Holtgraves, 1997).

If politeness only gets in the way of effective information transfer, why be polite?
Clearly, we have social concerns, and most linguistic theories assume such a mechanism of action, couched as either polite maxims (Leech, 1983), social norms (Ide, 1989), or aspects of a speaker and/or listener's identity referred as \emph{face} (Brown \& Levinson, 1987; Goffman, 1967).
This latter theory predicts that when a speaker's intended meaning contains a threat to the listener's self-image (and potentially the speaker's image), her messages will be less direct, less efficient, and possibly untruthful. 
But how does a speaker decide to be indirect (\emph{Your pie could use a bit of salt}) vs. false (\emph{It's delicious!}), and when should they tell the truth?
Additionally, how does the possibility of a speaker maintaining their own image in the mind of the listener enter into the calculation?

We propose a utility-theoretic solution to the problem of polite language production by quantifying the tradeoff between 
competing communicative goals.
In our model, speakers attempt to maximize informational utility---derived via classical, effective
information transmission, social utility---derived by being kind and
saving the listener's face, and a self-presentational utility---derived
by appearing in a particular way to save the speaker's own face.
Speakers then produce an utterance on the basis of
its expected utility (including their cost to utter, approximated by
the length of the utterance).
The lie that a pie was delicious provides social utility by making the baker feel good, but does not provide information about the true state of the world. 
Further, if the baker suspects that it was in fact terrible, the speaker runs the risk of being seen as uncooperative.

%The face-based framework for polite language use provides an intuitive
%and appealing explanation of many types of polite speech, but it does
%not precisely define how competing communicative goals trade off with
%one another. For example, it is unclear when face-saving should be
%prioritized over helpful information transfer, and when the desire to
%save face will motivate statements that are outright false
%(\emph{Your cake is delicious!}) versus indirect . Concretely, such theorizing does not constrain how
%an artificial agent like a robot should go about making polite requests,
%conveying negative evaluations, or delivering bad news. Further, a
%mutually-understood notion of face introduces additional complexity:
%Speakers sometimes may not want to preserve the listener's face
%genuinely but only to be \emph{seen as} doing so, hence appearing to be
%socially apt and saving their own face, which may lead to a different
%decision from that based on genuine desires to be kind or informative.
%What is needed is a precise theory of these goals and how they trade
%off.

%This latter theory predicts that when a speaker's intended meaning contains no threat to the listener's self-image, then the speaker will choose explicit and efficient messages.
%(putting it \emph{on the record}). 
%A speaker will choose to be more indirect utterance when the possibility of becoming face-threatening increases. 
%The face-based framework predicts inefficient indirect speech and untruthful lies in communication as the result of speakers' strategic choices relative to possible face threats.
%
%Theories of politeness explain deviations from optimal information
%transfer in language by assuming that speakers take into account social,
%as well as informational, concerns. These concerns are sometimes
%expressed as sets of polite maxims (Leech, 1983) or social norms  but the most influential account of politeness relies on the
%notion of \emph{face} to motivate deviations . 
%
%On this theory, interactants seek to be liked,
%approved, and related to (\emph{positive face}) as well as maintain
%their freedom to act (\emph{negative face}). If the 

The speaker's utilities are weighed within a probabilistic model of pragmatic reasoning within the Rational Speech Act (RSA) framework (Frank \& Goodman, 2012; Goodman \& Frank, 2016): Speakers are modeled as
agents who choose utterances by reasoning about their effects on a
listener relative to their cost, while listeners infer the meaning of an utterance by reasoning about speakers and their goals.
This model class has provided a quantitative understanding of a wide variety of complex linguistic behaviors, including vagueness (Lassiter \& Goodman, 2017), hyperbole (Kao, Wu, Bergen, \& Goodman, 2014), and irony
(Kao \& Goodman, 2015), among others. 
In this framework, language use builds on the idea that human social cognition can
be approximated via reasoning about others as rational agents who act to
maximize their subjective utility (Baker, Saxe, \& Tenenbaum, 2009), a
hypothesis which has found empirical support in a wide variety of work with both
adults and children (e.g., Jara-Ettinger, Gweon, Schulz, \& Tenenbaum,
2016; Liu, Ullman, Tenenbaum, \& Spelke, 2017).
 
\begin{figure*}[!h]
\includegraphics[width=0.6\textwidth]{fig/model} \centering \caption{Diagram of the model: The pragmatic speaker observes the true state and determines her goal between three utilities (informational, social, and presentational), and produces an utterance.}\label{fig:model}
\end{figure*}

RSA models are defined recursively such that speakers reason about
listeners, and vice versa. We use convention in indexing and say a pragmatic listener \(L_1\) reasons about what intended meaning
and goals would have led a speaker \(S_1\) to produce a particular
utterance. Then \(S_1\) reasons about a \emph{literal listener}
\(L_0\), modeled as attending only to the literal meanings of words
(rather than their pragmatic implications), and hence grounds the
recursion. 
The target of our current work is a model of a polite speaker
\(S_2\): \(S_2\) reasons about what utterance to say to \(L_1\) by
considering the set of utilities described above (Figure
\ref{fig:model}).

We evaluate our model on its ability to predict human utterance choices
in situations where polite language use is expected to varying degrees. 
Let's say Bob baked his pie and asks Ann how good was the pie.
Ann (\(S_2\)) produces an utterance \(w\) based on the true state of the world \(s\) (i.e., the
rating, in her mind, truly deserved by Bob's pie) and a set of goal weights
\(\hat{\phi}\), that determines how much Ann prioritizes each of the three possible goals.
Ann's production decision is softmax, which interpolates between
maximizing and probability matching (via \(\lambda_{S_2}\); Goodman \&
Stuhlmüller, 2013):

\begin{equation}
P_{S_2}(w | s, \hat{\phi}) \propto \exp(\lambda_{S_2} \cdot \mathop{\mathbb{E}}[U_{total}(w; s; \hat{\phi})]).
\end{equation} 

We posit that a speaker's utility contains three distinct components: informational, social, and presentational. The
total utility of an utterance is the weighted combination of the three component utilities minus the utterance cost \(C(w)\):

\[U_{total}(w; s; \hat{\phi}) = \phi_{info} \cdot U_{info}(w; s) + \phi_{soc} \cdot U_{soc}(w; s) + \phi_{pres} \cdot U_{pres}(w; s) - C(w)\].

%Aspects of the world with affective consequences for the listener (e.g., Bob and his pie) influence the social utilities in the model. 
Foremost, we define \emph{social utility} as the expected subjective utility \(V(s)\) of the state implied to the
listener by the utterance: \(U_{soc}(w) = \mathbb{E}_{P_{L_1}(s \mid w)}[V(s)]\). 
The subjective utility function \(V(s)\) could vary by culture and context; we test our model when states are explicit ratings (e.g., on a 4-pt scale) and we assume a positive linear value relationship between states and values \(V\) to model a listener's preference to be in a highly rated state (e.g., Bob would prefer to have made a 4-star pie rather than a 1-star pie).
At the same time, a speaker may desire to be epistemically helpful, modeled as standard \emph{informational utility} (\(U_{info}\)).
The informational utility indexes the amount of information a literal listener (\(L_0\)) would still not know about the state of the world \(s\) after hearing the speaker's utterance \(w\) (i.e., surprisal; e.g., how likely is Bob to guess Ann's actual opinion of the pie): \(U_{inf}(w) = \ln(P_{L_1}(s | w))\).
Speakers who optimize for informational utility produce accurate and informative utterances while those who optimize for social utility produce utterances that make the listener feel good.

If a listener is uncertain how their particular speaker is weighing the competing goals to be honest vs. kind, they might try to infer the weighting (e.g., ``was she just being nice?''). 
But then a sophisticated speakers can produce utterances in order to appear as if they had certain goals in mind (i.e., a self-presentational goal). 
The extent to which the speaker \emph{appears} to the listener to have a particular goal in mind (e.g., to be kind) is the utterance's \emph{presentational utility} (\(U_{pres}\)) and is the most novel component of our model.
The speaker gains presentational utility when her listener believes she
has particular goals -- that she is trying to be informative or kind.
Formally,

\begin{equation}
U_{pres}(w) = \ln(P_{L_1}(\phi_{S_1} \mid w)) = \ln \int_s P_{L_1}(s, \phi_{S_1} \mid w).
\end{equation}

The speaker conveys a weighting of informational
vs.~social goals (\(\phi_{S_1}\)) by considering the
beliefs of listener L1, who hears an utterance and jointly infers
the speaker's utilities and the true state of the world:

\begin{equation}
P_{L_1}(s, \hat{\phi} | w) \propto P_{S_1}(w | s, \hat{\phi}) \cdot P(s) \cdot p(\hat{\phi}).
\end{equation}

This presentational utility is the highest-order term of the model, defined only for a speaker thinking about a listener who evaluates a speaker
(i.e., defined for \(S_2\), but not \(S_1\)).

Finally, more complex utterances incur a greater cost, \(C(w)\) --
capturing the general pressure towards economy in speech. In our work,
utterances with negation (e.g., \emph{not terrible}) are assumed to
be slightly costlier than their equivalents with no negation (inferred
from data; see Supplementary Information).

Within our experimental domain, we assume there are four possible states
of the world corresponding to the value placed on a particular referent
(e.g., the presentation the speaker is commenting on):
\(S = {s_1,...,s_4}\). Since the rating scale is relatively abstract, we assume a uniform prior distribution
over possible states of the world. The set of utterances is
\{\emph{terrible}, \emph{bad}, \emph{good}, \emph{amazing}, \emph{not
terrible}, \emph{not bad}, \emph{not good}, and \emph{not amazing}\}. We
implemented this model using the probabilistic programming language
WebPPL \cite{dippl}.

The model exhibits and explains interpretable behavior.
If Bob's pie was good, Ann's utilities align to produce a positive utterance. 
Saying \emph{{[}Your pie{]} was amazing} simultaneously is truthful, kind, and appears as both. 
If Bob's pie was poor, however, the speaker is in a bind: Ann could be kind and say \emph{It was great}, but at the cost of conveying the wrong information to Bob if he believes her to be truthful. 
If he does not, he might infer Ann is \emph{just being
nice}, but is uninformative. Alternatively, she could say the truth
(\emph{It was bad}), but then Bob would think Ann didn't care about
him. 
What is a socially-aware speaker to do? Our quantitative model predicts that
indirect speech -- like \emph{It wasn't bad} -- best navigates Ann's
dilemma. Her statement is sufficiently open-ended to include the
possibility that the poem was good, but her avoidance of the simpler and
less costly \emph{It was good} provides both an inference available to Bob that the
pie was mediocre and that Ann cares about his feelings.

\section*{Results}

We made a direct, pre-registered test of our model by instantiating our running
example in an online experiment (\emph{N} = 202). Participants
read scenarios with information on the speaker's (Ann's,
in our example) feelings toward some performance or product (e.g., poem
recital; \emph{true state}), on a scale from zero to three hearts (e.g.,
one out of three hearts). For example, one trial read: \emph{Imagine
that Bob gave a poem recital, but he didn't know how good it was. Bob
approached Ann, who knows a lot about poems, and asked}How was my poem?"
We also manipulated the speaker's \emph{goal} across trials: to be
\emph{informative} (\emph{give accurate and informative feedback});
to be \emph{kind} (\emph{make the listener feel good}); or to be
\emph{both} informative and kind simultaneously. We hypothesized that
each of the three experimentally-induced goals will represent a tradeoff between the three
utilities in our model (see Supplementary Information). In a single
trial, each scenario was followed by a question asking for the most
likely produced utterance by Ann. Participants selected one of eight possible
utterances, by choosing between \emph{It was} vs. \emph{It wasn't} and
then among \emph{terrible}, \emph{bad}, \emph{good}, and \emph{amazing.}

\begin{figure}[!h]
\includegraphics[width=0.5\textwidth]{fig/variance-1} \caption{Full distribution of human responses vs. model predictions. Error bars represent 95\% confidence intervals for the data (vertical) and 95\% highest density intervals for the model (horizontal).}\label{fig:variance}
\end{figure}

Our primary behavioral hypothesis was that speakers describing bad
states (e.g., Bob's pie deserved 0 hearts) with goals to be both
informative and kind would produce more indirect, negative utterances
(e.g., \emph{It wasn't terrible}). Such indirect speech acts both
save the listener's face and providing a little information about the
true state, and thus, are the kind of thing that a socially-conscious speaker would say. 
This prediction was confirmed: a Bayesian mixed-effects
model predicts more negation as a function of true state and goal via
an interaction such that a speaker with both goals to be informative and
kind produced more negation in worse states compared to a speaker with
only the goal to be informative (\emph{M} = -1.33, {[}-1.69, -0.98{]})
and goal to be kind (\emph{M} = -0.50, {[}-0.92, -0.07{]}). Rather than
eschewing one of their goals to increase utility along a single
dimension, participants chose utterances that jointly satisfied their
conflicting goals by producing indirect, polite speech.

\begin{figure*}[!h]
\includegraphics[width=\textwidth]{fig/comparison-1} \caption{Comparison of predictions for proportion of utterances chosen by pragmatic speaker from possible model variants (left) and human data (rightmost) for average proportion of negation produced among all utterances, given true state of 0 heart (on a scale of 0 to 3) and speaker with both goals to be informative and kind. Gray dotted line indicates chance level at 12.5\%.}\label{fig:comparison}
\end{figure*}

\begin{table}[tbp]
\begin{center}
\begin{threeparttable}
\caption{\label{tab:comparisonTable}Comparison of variance explained for each model variant and log Bayes Factors quantifying evidence in favor of alternative model in comparison.}
\begin{tabular}{lll}
\toprule
Model & \multicolumn{1}{c}{Variance 
explained} & \multicolumn{1}{c}{log BF}\\
\midrule
model: 
informational, 
social, 
presentational & 0.97 & --\\
model: 
informational, 
presentational & 0.96 & -11.14\\
model: 
informational, 
social & 0.92 & -25.06\\
model: 
social, 
presentational & 0.23 & -864\\
model: 
presentational 
only & 0.23 & -873.83\\
model: 
social only & 0.22 & -885.52\\
model: 
informational 
only & 0.83 & -274.89\\
\bottomrule
\end{tabular}
\end{threeparttable}
\end{center}
\end{table}
The model parameters (softmax parameters and each goal condition's utility weights) can be inferred from the behavioral data using a Bayesian data analysis model (M. D. Lee \& Wagenmakers, 2014; see Supplementary Information)
To approximate the literal meanings (i.e., the semantics) of the words as interpreted by the literal listener \(L_0\), we obtained literal meaning judgments from an independent group of participants
(\emph{N}=51). 
The posterior predictions from the the three-utility polite speaker model (informational, social, presentational) showed a very strong fit to participants' actual utterance choices (\(r^2\)(96) = 0.97; Figure \ref{fig:variance}).
We compared these to six model variants containing
subsets of the three utilities in the full model.
Both the variance explained and the marginal likelihood of the observed data were the
highest for the full model (Table \ref{tab:comparisonTable}). Only the
full model captured participants' preference for negation when the speaker wanted to be informative and kind
about truly bad states, as hypothesized (Figure \ref{fig:comparison}).
In sum, the full collection of informational, social, and presentational were
required to fully explain participants' utterance choices.



\begin{table}[tbp]
%\resizebox{\columnwidth}{!}{
\begin{center}
\begin{threeparttable}
%\centering
\caption{\label{tab:phi}Inferred phi parameters from all model variants with more than one utility.}
%\begin{tabular}{llllll}
\begin{tabularx}{\columnwidth}{llllll}
\toprule
Model (utilities) & \multicolumn{1}{l}{goal} & \multicolumn{1}{c}{$\phi_{inf}$} & \multicolumn{1}{c}{$\phi_{soc}$} & \multicolumn{1}{c}{$\phi_{pres}$} & \multicolumn{1}{c}{$\phi_{S_1}$}\\
\midrule
inf, soc, pres & both & 0.36 & 0.11 & 0.54 & 0.36\\
inf, soc, pres & informative & 0.36 & 0.02 & 0.62 & 0.49\\
inf, soc, pres & social & 0.25 & 0.31 & 0.44 & 0.37\\
inf, pres & both & 0.64 & -- & 0.36 & 0.17\\
inf, pres & informative & 0.77 & -- & 0.23 & 0.33\\
inf, pres & social & 0.66 & -- & 0.34 & 0.04\\
inf, soc & both & 0.54 & 0.46 & -- & --\\
inf, soc & informative & 0.82 & 0.18 & -- & --\\
inf, soc & social & 0.39 & 0.61 & -- & --\\
soc, pres & both & -- & 0.38 & 0.62 & 0.55\\
soc, pres & informative & -- & 0.35 & 0.65 & 0.75\\
soc, pres & social & -- & 0.48 & 0.52 & 0.66\\
\bottomrule
\end{tabularx}
\end{threeparttable}
\end{center}
%}
\end{table}


The utility weights inferred for the three-utility model (Table \ref{tab:phi})
provide additional insight into how polite language use operates:
\emph{Being kind} requires equal weights on all three utilities,
indicating that Gricean informativity needs to be part of language use
even when it is explicitly not the goal. 
\emph{Being informative} pushes
the weight on social utility close to zero, but the weight on
\emph{appearing kind} stays high, suggesting that speakers are expected
to manage their own face even when they are not considering others'.
\emph{Kind and informative} speakers emphasize informativity slightly
more than kindness. In all cases, however, the presentational utilities
have greatest weight, which may suggest that appearing honest and kind
is more important than actually being so! Overall then, our condition
manipulation altered the balance between these weights, but all
utilities played a role in all conditions.

\section*{Discussion}

Politeness is puzzling from an information-theoretic perspective.
Incorporating social motivations adds a level of explanation, but so far such intuitions and observations have resisted both formalization and precise testing.
% intuitions have been resistant to formalization or
We present a utility-theoretic model of language use that captures the interplay between competing
informational, social, and presentational goals, and provide preregistered
experimental evidence that confirmed its ability to capture human
judgments, unlike comparison models that used only a subset of the full
utility structure.

Precisely estimate choice behavior in the experiment required abstracting away 
from natural interactions in a number of ways. 
Human speakers have access
to a potentially infinite set of utterances to select from in order manage the three-utility tradeoff (\emph{It's hard to write a good poem}, \emph{That
metaphor in the second stanza was so relatable!}). In theory,
each utterance will have strengths and weaknesses relative to the
speaker's goals, though computation in an unbounded model presents
technical challenges (perhaps paralleling the difficulty human speakers
feel in finding the right thing to say in a difficult situation; see \cite{goodman2016}).

For a socially-conscious speaker, managing listeners' inferences is a
fundamental task. Our model builds upon the theory of politeness as face
management (Brown \& Levinson, 1987) and takes a step towards
understanding it more fully. Our work extends previous models of language beyond
standard informational utilities to address social and
self-presentational concerns. Previous theories of language use have not
explained how informational versus social concerns trade off to inform
the speaker's utterance choices. This work breaks through to exploring how informational cooperativity interacts
with other social goals, and our approach can provide insight into a wide range of social behaviors beyond speech by considering utility-driven inferences in a
social context (Baker, Jara-Ettinger, Saxe, \& Tenenbaum, 2017; Hamlin,
Ullman, Tenenbaum, Goodman, \& Baker, 2013) where agents need to take
into account concerns about both self and others.

Previous game-theoretic analyses of politeness have either required some social cost to an utterance (e.g., by reducing one's social status or incurring social debt to one's conversational partner; Van Rooy, 2003) or a separate notion of plausible deniability (Pinker, Nowak, and Lee, 2008).
The necessary kind of utterance cost would involve higher-order reasoning about others, and may be able to be defined in terms the more basic social and self-presentational goals we formalize here. 
A separate notion of plausible deniability may not be need either.
Maintaining plausible deniability is in one's own self-interest (e.g., for controversial viewpoints or covert deception) and; goes against the interest of the addressee.
A joint cooperative and conflicting relationship was thought necessary for indirect speech(Pinker, Nowak, and Lee, 2008), but here we show indirectness arising from purely cooperative goals, which address different aspects of a general utility structure. 

%balance cooperation and conflict between interlocutors (e.g., in deception), which characterized human politeness intuitions 
%Here we show indirectness arising from purely cooperative goals, which address different aspects of a general utility structure.

% to indirect speech but here we show indirectness arising from (Pinker, Nowak, and Lee, 2008) 
%In such a model, utterance cost requires a component derived from the social world (e.g., an utterance may be costly by reducing one's social status or incurring social debt to one's conversational partner; , but it's not clear how cost should be determined nor how it generalizes to other politeness behavior (e.g., evaluative statements like those made in our experiment). 
%Our model derives its predictions by construing the speaker utility as a collection of possible goals (here, epistemic,
%social, and presentational goals); utterance cost may strengthen the inferences, but it is not a fundamental necessity.
%The speech-acts themselves are not costly.
%
%Pinker, Nowak, and Lee (2008) model game-theoretic communication as involving a mixture of cooperation
%\emph{and} conflict: indirect speech allows for plausible deniability, which is in one's own self-interest but goes against the interest of the addressee. 
%Our work sees polite speech as fundamentally cooperative, building on classic theories of pragmatic language use (Brown \& Levinson, 1987;
%Grice, 1975). 
%A separate notion of plausible deniability may not be needed: 
%Indirect speech in our case study comes from both a goal to be
%helpful and a desire to look good. 



%Van Rooy (2003)'s analysis relies on the notion that polite language is costly (in a social way
%e.g., by reducing one's social status or incurring social debt to one's
%conversational partner) but it's not clear how the polite behaviors
%explored in our experiments (not polite requests) would incur any cost
%to speaker or listener.
%
%pragmatics has offered 
%
%. Van Rooy (2003) argues the
%purpose of polite language is to align the preferences of interlocutors.
%Our notion of social utility \(U_{soc}\) and presentational utility
%\(U_{pres}\) is similar in that they motivate speakers to signal worlds
%that make the listener feel good. 

Utility weights and value functions in our model could provide a framework for understanding systematic
cross-cultural differences in what counts as polite. Cross-cultural differences in politeness could be a product of different weightings within the same
utility structure. Alternatively, culture could affect
the value function \(V\) that maps states of the world onto subjective
values for the listener (e.g., the mapping from states to utilities may
be nonlinear and involve reasoning about the future). 
Our formal modeling approach with systematic behavior measurements provides an avenue towards understanding the vast range of politeness practices found across languages.

Politeness is but one of the ways that language use deviates from purely
informational transmission. We flirt, insult, boast, and empathize by balancing informative transmissions with goals to affect others' feelings or
present particular views of ourselves. Our work shows how social and
self-presentational motives are integrated with informational concerns more
generally, opening up the possibility for a broader theory of social
language. 
Finally, a formal formal account of politeness moves us closer to
courteous computation -- to machines that can talk with tact.

\matmethods{

\subsection*{Literal semantic task}\label{literal-semantic-task}

We probed judgments of literal meanings of the target words assumed by
our model and used in our main experiment. 51 participants with IP
addresses in the United States were recruited on Amazon's Mechanical
Turk. We used thirteen different context items in which a speaker
evaluated a performance of some kind. For example, in one of the
contexts, Ann saw a presentation, and Ann's feelings toward the
presentation (true state) were shown on a scale from zero to three
hearts (e.g., two out of three hearts filled in red color; see
Figure~\ref{fig:screenshot} for an example of the heart scale). The
question of interest was \emph{Do you think Ann thought the
presentation was / wasn't X?} and participants responded by choosing
either \emph{no} or \emph{yes.} The target could be one of four
possible words: \emph{terrible}, \emph{bad}, \emph{good}, and
\emph{amazing}, giving rise to eight different possible utterances (with
negation or no negation). Each participant read 32 scenarios, depicting
every possible combination of states and utterances. The order of
context items was randomized, and there were a maximum of four repeats
of each context item per participant. For this and the speaker
production experiment, we analyzed the data by collapsing across context
items. For each utterance-state pair, we computed the posterior
distribution over the semantic weight (i.e., how consistent X utterance
is with Y state) assuming a uniform prior over the weight (i.e., a
standard Beta-Binomial model). Meanings of the words as judged by
participants were as one would expect (Figure ~\ref{fig:litsem}).

\begin{figure}[!h]
\includegraphics[width=\columnwidth]{fig/litsem-1}
\centering \caption{Semantic measurement results. Proportion of acceptances of utterance types (shown in different colors) combined with target words (shown in different facets) given the true state represented on a scale of hearts. Error bars represent 95\% confidence intervals.}\label{fig:litsem}
\end{figure}

\subsection*{Speaker production task}\label{speaker-production-task}

\begin{figure}[!h]
\includegraphics[width=\columnwidth]{fig/screenshot} 
\caption{Example of a trial in the speaker production task.}\label{fig:screenshot}
\end{figure}

202 participants with IP addresses in the United States were recruited
on Amazon's Mechanical Turk. As in the literal semantic task above, we
used scenarios in which a person (e.g., Bob) gave some performance and
asked for another person (e.g., Ann)'s opinion on the performance
(Figure ~\ref{fig:screenshot}). Additionally, we provided information on
the speaker Ann's goal -- to make Bob feel good, or to give as accurate
and informative feedback as possible, or both -- and the true state --
how Ann actually felt about Bob's performance (e.g., two out of three
hearts, on a scale from zero to three hearts;
Figure~\ref{fig:screenshot}). Each participant read twelve scenarios,
depicting every possible combination of the three goals and four states.
The order of context items was randomized, and there were a maximum of
two repeats of each context item per participant. Each scenario was
followed by a question that read, \emph{If Ann wanted to make Bob
feel good but not necessarily give informative feedback (or to give
accurate and informative feedback but not necessarily make Bob feel
good, or BOTH make Bob feel good AND give accurate and informative
feedback), what would Ann be most likely to say?} Participants indicated
their answer by choosing one of the options on the two dropdown menus,
side-by-side, one for choosing between \emph{It was} vs. \emph{It
wasn't} and the other for choosing among \emph{terrible}, \emph{bad},
\emph{good}, and \emph{amazing.}

\subsection*{Data availability}\label{data-availability}

Our model, preregistration of hypotheses, procedure, data, and analyses
are available at \url{https://github.com/ejyoon/polite_speaker}.

}

\showmatmethods{} % Display the Materials and Methods section


\acknow{
This work was supported by NSERC PGS Doctoral scholarship
PGSD3-454094-2014 to EJY, NSF Graduate Research Fellowship DGE-114747 to
MHT, ONR grant N00014-13-1-0788 to NDG, and NSF grant BCS 1456077 to
MCF.
}

\showacknow{} % Display the acknowledgments section

% Bibliography
\bibliography{politeness}

\end{document}